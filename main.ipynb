{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nic/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# from settings import *\n",
    "# import analyze_cascade\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from random import choices\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = 'metadata_anon.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read meta data \n",
    "fin = open(metadata_file,'r')\n",
    "lines = fin.readlines()\n",
    "fin.close()\n",
    "cascade_id2metadata={}\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    item = eval(line)\n",
    "    cascade_id2metadata[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives of dynamic measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10703</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>11</td>\n",
       "      <td>25.799399</td>\n",
       "      <td>186.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>23228</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11783</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>9</td>\n",
       "      <td>10.811974</td>\n",
       "      <td>313.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14827</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>2.535338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6504</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>13</td>\n",
       "      <td>15.395237</td>\n",
       "      <td>518.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>14129</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.019705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5772</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>8</td>\n",
       "      <td>3.140842</td>\n",
       "      <td>189.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>9972</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.271008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6041</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>8</td>\n",
       "      <td>5.160261</td>\n",
       "      <td>174.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9526</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.115942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breadth                            category  depth  engangement  \\\n",
       "0    10703  Viral Photos/Stories/Urban Legends     11    25.799399   \n",
       "1    11783     Science/Nature/Tech/Food/Health      9    10.811974   \n",
       "2     6504  Viral Photos/Stories/Urban Legends     13    15.395237   \n",
       "3     5772  Viral Photos/Stories/Urban Legends      8     3.140842   \n",
       "4     6041  Viral Photos/Stories/Urban Legends      8     5.160261   \n",
       "\n",
       "   nfollowees  nfollowers   size veracity verified  virality  \n",
       "0       186.0       672.0  23228    MIXED    False  4.003857  \n",
       "1       313.0       380.0  14827    MIXED    False  2.535338  \n",
       "2       518.0       504.0  14129    MIXED    False  4.019705  \n",
       "3       189.0       228.0   9972    MIXED    False  3.271008  \n",
       "4       174.0       110.0   9526    MIXED    False  3.115942  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get static measures\n",
    "veracity = []\n",
    "virality = []\n",
    "depth = []\n",
    "breadth = []\n",
    "size = []\n",
    "verified = []\n",
    "nfollowers = []\n",
    "nfollowees = []\n",
    "engagement = []\n",
    "category = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        veracity.append(metadata['veracity'])\n",
    "        virality.append(metadata['virality'])\n",
    "        depth.append(metadata['depth'])\n",
    "        breadth.append(metadata['max_breadth'])\n",
    "        size.append(metadata['size'])\n",
    "        verified.append(metadata['verified_list'][0])\n",
    "        nfollowers.append(metadata['num_followers_list'][0])\n",
    "        nfollowees.append(metadata['num_followees_list'][0])\n",
    "        engagement.append(metadata['engagement_list'][0])\n",
    "        category.append(metadata['rumor_category'])\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({'veracity': veracity, 'virality': virality, 'depth': depth, 'breadth': breadth, 'size': size, 'verified': verified, 'nfollowers': nfollowers, \n",
    "                   'nfollowees': nfollowees, 'engangement': engagement, 'category': category})\n",
    "\n",
    "# Inspect\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth2breadth</th>\n",
       "      <th>depth2time</th>\n",
       "      <th>depth2uu</th>\n",
       "      <th>num_followees_list</th>\n",
       "      <th>uu2time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.707707</td>\n",
       "      <td>1.707707</td>\n",
       "      <td>1.707707</td>\n",
       "      <td>93.878829</td>\n",
       "      <td>93.878829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.319555</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>950.694376</td>\n",
       "      <td>950.694376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth2breadth   depth2time       depth2uu  num_followees_list  \\\n",
       "count   42081.000000  42081.000000  42081.000000        42081.000000   \n",
       "mean        1.707707      1.707707      1.707707           93.878829   \n",
       "std         1.319555      1.319555      1.319555          950.694376   \n",
       "min         1.000000      1.000000      1.000000            2.000000   \n",
       "25%         1.000000      1.000000      1.000000            2.000000   \n",
       "50%         1.000000      1.000000      1.000000            4.000000   \n",
       "75%         2.000000      2.000000      2.000000            9.000000   \n",
       "100%       24.000000     24.000000     24.000000        46895.000000   \n",
       "max        24.000000     24.000000     24.000000        46895.000000   \n",
       "\n",
       "            uu2time  \n",
       "count  42081.000000  \n",
       "mean      93.878829  \n",
       "std      950.694376  \n",
       "min        2.000000  \n",
       "25%        2.000000  \n",
       "50%        4.000000  \n",
       "75%        9.000000  \n",
       "100%   46895.000000  \n",
       "max    46895.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_depth2time = []\n",
    "len_num_followees_list = []\n",
    "len_depth2uu = []\n",
    "len_uu2time = []\n",
    "len_depth2breadth = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        len_depth2time.append(len(metadata['depth2time'].keys()))\n",
    "        len_num_followees_list.append(len(metadata['num_followees_list']))\n",
    "        len_depth2uu.append(len(metadata['depth2uu'].keys()))\n",
    "        len_uu2time.append(len(metadata['uu2time'].keys()))\n",
    "        len_depth2breadth.append(len(metadata['depth2breadth'].keys()))\n",
    "    \n",
    "# Convert to data frame\n",
    "df_len = pd.DataFrame({'depth2time ': len_depth2time, \n",
    "                       'num_followees_list': len_num_followees_list, \n",
    "                       'depth2uu': len_depth2uu, \n",
    "                       'uu2time': len_uu2time, \n",
    "                       'depth2breadth': len_depth2breadth})\n",
    "\n",
    "# # Get summary\n",
    "df_len.describe(percentiles = [0.25, 0.5, 0.75, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get expression of each item in a dictionary entry\n",
    "def get_expression_list(entry):\n",
    "    expression = []\n",
    "    for i in entry.keys():\n",
    "        expression.append(float(entry[i]))\n",
    "    return expression\n",
    "\n",
    "# Convert y to classification\n",
    "def veracity_to_categorical(v):\n",
    "    if v == 'FALSE':\n",
    "        vbin = [1,0,0]\n",
    "    elif v == 'MIXED':\n",
    "        vbin = [0,1,0]\n",
    "    elif v == 'TRUE':\n",
    "        vbin = [0,0,1]\n",
    "    return vbin\n",
    "\n",
    "# Get data in list format\n",
    "data = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None:       \n",
    "        # Get depth\n",
    "        depth2time = get_expression_list(metadata['depth2time'])\n",
    "        depth2uu = get_expression_list(metadata['depth2uu'])\n",
    "        depth2breadth = get_expression_list(metadata['depth2breadth']) \n",
    "        veracity = veracity_to_categorical(metadata['veracity'])\n",
    "        data_id = []\n",
    "        for time, uu, breadth in zip(depth2time, depth2uu, depth2breadth):\n",
    "            data_t = [cascade, \n",
    "                      veracity,\n",
    "                      time, uu, breadth]\n",
    "            data_id.append(data_t)\n",
    "        data.extend([data_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Create training and test set\n",
    "def split_list(lst, train_size): # train_size is a proportion\n",
    "    split = len(lst) * train_size\n",
    "    if split.is_integer():\n",
    "        split = int(split)\n",
    "        return lst[:split], lst[split:]\n",
    "    else:\n",
    "        split = math.floor(split) + 1\n",
    "        return lst[:split], lst[split:]\n",
    "    \n",
    "# Function: Padding for groups of equal batches\n",
    "def padding(lst, bsize):\n",
    "    if len(lst) % bsize != 0:\n",
    "        psize = bsize - (len(lst) % 5)\n",
    "        samples = choices(lst, k=psize)\n",
    "        lst.extend(samples)\n",
    "    return lst\n",
    "\n",
    "# Get sublist\n",
    "def get_sublist(list_in_list, start, stop):\n",
    "    x = []\n",
    "    for lst in list_in_list:\n",
    "        x_id = []\n",
    "        for sublist in lst:\n",
    "            if stop is None:\n",
    "                x_id.append(sublist[start:])\n",
    "            elif start is None:\n",
    "                x_id.append(sublist[:stop])\n",
    "            else:\n",
    "                x_id.append(sublist[start:stop])\n",
    "        x.extend([x_id])\n",
    "    return x\n",
    "\n",
    "# Separate id, x and y\n",
    "def separate(list_in_list):\n",
    "    cid = []\n",
    "    y = []\n",
    "    for lst in list_in_list:\n",
    "        cid.append(lst[0][0]) # only one id is needed\n",
    "#         veracity_id = []\n",
    "#         for sublist in lst:\n",
    "#             veracity_id.extend([sublist[1]])\n",
    "#         veracity.append(veracity_id)\n",
    "        y.append(lst[0][1])\n",
    "    x = get_sublist(list_in_list,2,None)\n",
    "    return cid, y, x\n",
    "\n",
    "# # Group by sequence length and append to have batches of 5 for both training and test\n",
    "data.sort(key=len)   # Randomly reshuffle before? random.shuffle(...)\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "cid_train = []\n",
    "cid_test = []\n",
    "for k, g in groupby(data, len):\n",
    "    group = list(g)\n",
    "    if len(group) > 2: # This omits too small groups\n",
    "        shuffle(group)\n",
    "        # Create train and test bucket\n",
    "        train_group, test_group = split_list(group, 0.5)\n",
    "        # Padd for equal batch size\n",
    "        train_group_padded = padding(train_group, 5)\n",
    "        test_group_padded = padding(test_group, 5)\n",
    "        # Separate list\n",
    "        cid_train_group, y_train_group, x_train_group = separate(train_group)\n",
    "        cid_test_group, y_test_group, x_test_group = separate(test_group)\n",
    "        # Append:  convert y and x into numpy array\n",
    "        x_train.append(np.array(x_train_group))\n",
    "        x_test.append(np.array(x_test_group))\n",
    "        y_train.append(np.array(y_train_group))\n",
    "        y_test.append(np.array(y_test_group))\n",
    "        cid_train.append(cid_train_group)\n",
    "        cid_test.append(cid_test_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize the list\n",
    "def standardization(lst, index, mean, std):\n",
    "    for array3d in lst:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                vector[index] = (vector[index] - mean) / std\n",
    "    return lst\n",
    "\n",
    "# Function to compute mean and std of variable and then standardizes this variable in list\n",
    "def standardize_data(a_list, b_list, index):\n",
    "    var = []\n",
    "    # Compute mean and std from train data variable\n",
    "    for array3d in a_list:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                var.append(vector[index])\n",
    "    var = np.array(var)\n",
    "    var_mean = var.mean()\n",
    "    var_std = var.std()\n",
    "    # Standardize a\n",
    "    a_list_std = standardization(a_list, index, var_mean, var_std)\n",
    "    b_list_std = standardization(b_list, index, var_mean, var_std)\n",
    "    return a_list_std, b_list_std\n",
    "\n",
    "# Standardize all variables\n",
    "def standardize_all(a_list, b_list):\n",
    "    length = len(a_list[0][0][0])\n",
    "    indices = list(range(length))\n",
    "    for i in indices:\n",
    "        std_a, std_b = standardize_data(a_list, b_list, i)\n",
    "    return std_a, std_b\n",
    "\n",
    "x_train, x_test = standardize_all(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM train data descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  1   Observations:  12960  Sequence length 1\n",
      "Group:  2   Observations:  4790  Sequence length 2\n",
      "Group:  3   Observations:  1790  Sequence length 3\n",
      "Group:  4   Observations:  760  Sequence length 4\n",
      "Group:  5   Observations:  320  Sequence length 5\n",
      "Group:  6   Observations:  170  Sequence length 6\n",
      "Group:  7   Observations:  95  Sequence length 7\n",
      "Group:  8   Observations:  65  Sequence length 8\n",
      "Group:  9   Observations:  35  Sequence length 9\n",
      "Group:  10   Observations:  25  Sequence length 10\n",
      "Group:  11   Observations:  20  Sequence length 11\n",
      "Group:  12   Observations:  15  Sequence length 12\n",
      "Group:  13   Observations:  10  Sequence length 13\n",
      "Group:  14   Observations:  10  Sequence length 14\n",
      "Group:  15   Observations:  5  Sequence length 15\n",
      "Group:  16   Observations:  5  Sequence length 16\n",
      "Group:  17   Observations:  5  Sequence length 17\n",
      "Group:  18   Observations:  5  Sequence length 19\n"
     ]
    }
   ],
   "source": [
    "# Group size and sequence length\n",
    "i = 1\n",
    "for g in x_train:\n",
    "    print('Group: ', i, ' ', 'Observations: ', len(g), ' ' 'Sequence length', len(g[0]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  1 Counter({'FALSE': 9665, 'TRUE': 2010, 'MIXED': 1285})\n",
      "Group:  2 Counter({'FALSE': 3669, 'TRUE': 675, 'MIXED': 446})\n",
      "Group:  3 Counter({'FALSE': 1375, 'TRUE': 248, 'MIXED': 167})\n",
      "Group:  4 Counter({'FALSE': 608, 'TRUE': 90, 'MIXED': 62})\n",
      "Group:  5 Counter({'FALSE': 245, 'TRUE': 50, 'MIXED': 25})\n",
      "Group:  6 Counter({'FALSE': 127, 'TRUE': 24, 'MIXED': 19})\n",
      "Group:  7 Counter({'FALSE': 81, 'MIXED': 7, 'TRUE': 7})\n",
      "Group:  8 Counter({'FALSE': 52, 'MIXED': 8, 'TRUE': 5})\n",
      "Group:  9 Counter({'FALSE': 30, 'TRUE': 4, 'MIXED': 1})\n",
      "Group:  10 Counter({'FALSE': 21, 'TRUE': 2, 'MIXED': 2})\n",
      "Group:  11 Counter({'FALSE': 20})\n",
      "Group:  12 Counter({'FALSE': 14, 'TRUE': 1})\n",
      "Group:  13 Counter({'FALSE': 7, 'MIXED': 3})\n",
      "Group:  14 Counter({'FALSE': 9, 'MIXED': 1})\n",
      "Group:  15 Counter({'FALSE': 5})\n",
      "Group:  16 Counter({'FALSE': 5})\n",
      "Group:  17 Counter({'FALSE': 5})\n",
      "Group:  18 Counter({'FALSE': 3, 'MIXED': 2})\n"
     ]
    }
   ],
   "source": [
    "# Convert y to classification\n",
    "def reverse_veracity_to_categorical(vbin):\n",
    "    if vbin[0] == 1:\n",
    "        v = 'FALSE'\n",
    "    elif vbin[1] == 1:\n",
    "        v = 'MIXED'\n",
    "    elif vbin[2] == 1:\n",
    "        v = 'TRUE'\n",
    "    return v\n",
    "\n",
    "# Outcome distribution\n",
    "i = 1\n",
    "for g in y_train:\n",
    "    ver = []\n",
    "    for y in g:\n",
    "        ver.append(reverse_veracity_to_categorical(y))\n",
    "    print('Group: ', i, Counter(ver))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM on dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12960/12960 [==============================] - 14s 1ms/step - loss: 0.7598 - acc: 0.7485\n",
      "Epoch 2/2\n",
      "12960/12960 [==============================] - 12s 941us/step - loss: 0.7329 - acc: 0.7485\n",
      "Epoch 1/2\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.6999 - acc: 0.7693\n",
      "Epoch 2/2\n",
      "4790/4790 [==============================] - 6s 1ms/step - loss: 0.6975 - acc: 0.7693\n",
      "Epoch 1/2\n",
      "1790/1790 [==============================] - 3s 2ms/step - loss: 0.7204 - acc: 0.7581\n",
      "Epoch 2/2\n",
      "1790/1790 [==============================] - 3s 1ms/step - loss: 0.7197 - acc: 0.7587\n",
      "Epoch 1/2\n",
      "760/760 [==============================] - 2s 2ms/step - loss: 0.6841 - acc: 0.7776\n",
      "Epoch 2/2\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.6777 - acc: 0.7776\n",
      "Epoch 1/2\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6809 - acc: 0.7844\n",
      "Epoch 2/2\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6759 - acc: 0.7844\n",
      "Epoch 1/2\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.7857 - acc: 0.7353\n",
      "Epoch 2/2\n",
      "170/170 [==============================] - 0s 3ms/step - loss: 0.7784 - acc: 0.7353\n",
      "Epoch 1/2\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.4861 - acc: 0.8947\n",
      "Epoch 2/2\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.4662 - acc: 0.8947\n",
      "Epoch 1/2\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.5651 - acc: 0.8308\n",
      "Epoch 2/2\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5552 - acc: 0.8308\n",
      "Epoch 1/2\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3953 - acc: 0.9143\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3906 - acc: 0.9143\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3438 - acc: 0.9200\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3386 - acc: 0.9200\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3759 - acc: 0.9000\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3748 - acc: 0.9000\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1409 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1364 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4165 - acc: 0.9000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4142 - acc: 0.9000\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4487 - acc: 0.9000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4485 - acc: 0.9000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1418 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1408 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1701 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1686 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2238 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2210 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7660 - acc: 0.8000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7639 - acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (None, 3),  return_sequences = False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and get train predictions\n",
    "train_pred = []\n",
    "for X,Y in zip(x_train, y_train):\n",
    "    hist = model.fit(X, Y, epochs=2, batch_size=5)\n",
    "    pred = model.predict(X, batch_size=5)\n",
    "    train_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          cid        y1        y2        y3\n",
      "0       67863  0.742731  0.099418  0.157852\n",
      "1       55164  0.744828  0.098442  0.156730\n",
      "2       57868  0.744828  0.098442  0.156730\n",
      "3       79351  0.707033  0.116352  0.176615\n",
      "4      110652  0.744828  0.098442  0.156730\n",
      "5      108784  0.743257  0.099173  0.157571\n",
      "6       62670  0.744305  0.098685  0.157010\n",
      "7       58840  0.744828  0.098442  0.156730\n",
      "8       88434  0.744828  0.098442  0.156730\n",
      "9       50899  0.744828  0.098442  0.156730\n",
      "10     108705  0.742731  0.099418  0.157852\n",
      "11      62551  0.744305  0.098685  0.157010\n",
      "12      68657  0.742204  0.099663  0.158133\n",
      "13      85498  0.743781  0.098929  0.157290\n",
      "14      86713  0.744828  0.098442  0.156730\n",
      "15      68138  0.742731  0.099418  0.157852\n",
      "16      51048  0.744828  0.098442  0.156730\n",
      "17      54770  0.744828  0.098442  0.156730\n",
      "18      65326  0.743781  0.098929  0.157290\n",
      "19      64362  0.743781  0.098929  0.157290\n",
      "20      63413  0.744305  0.098685  0.157010\n",
      "21      59624  0.744828  0.098442  0.156730\n",
      "22      67388  0.743257  0.099173  0.157571\n",
      "23      55113  0.744828  0.098442  0.156730\n",
      "24      64229  0.743781  0.098929  0.157290\n",
      "25      68618  0.742204  0.099663  0.158133\n",
      "26      66249  0.743257  0.099173  0.157571\n",
      "27      84549  0.739554  0.100900  0.159546\n",
      "28      88201  0.744828  0.098442  0.156730\n",
      "29      87790  0.744828  0.098442  0.156730\n",
      "...       ...       ...       ...       ...\n",
      "21038   82539  0.857445  0.070729  0.071825\n",
      "21039   82536  0.835306  0.083953  0.080741\n",
      "21040   82085  0.857919  0.057523  0.084558\n",
      "21045   82528  0.872319  0.062480  0.065201\n",
      "21046   82307  0.892033  0.046359  0.061609\n",
      "21047   82055  0.853972  0.058800  0.087227\n",
      "21048   82560  0.821519  0.093095  0.085387\n",
      "21049   81992  0.840410  0.064322  0.095268\n",
      "21050  107009  0.863721  0.061922  0.074357\n",
      "21055  107004  0.896359  0.049235  0.054406\n",
      "21056   82492  0.899010  0.047823  0.053167\n",
      "21057   82570  0.794420  0.110873  0.094706\n",
      "21058   82467  0.904482  0.044592  0.050927\n",
      "21059   82445  0.900167  0.046093  0.053740\n",
      "21060   82558  0.827218  0.090321  0.082461\n",
      "21061   82559  0.825966  0.091096  0.082938\n",
      "21062   82054  0.857635  0.057407  0.084958\n",
      "21065   82380  0.900856  0.043684  0.055460\n",
      "21066   82119  0.870420  0.052917  0.076663\n",
      "21067   82554  0.837412  0.084394  0.078193\n",
      "21068   82472  0.904609  0.044779  0.050612\n",
      "21070   82562  0.827595  0.090800  0.081605\n",
      "21071   82578  0.795902  0.110727  0.093372\n",
      "21072   82532  0.879361  0.059482  0.061157\n",
      "21073   82552  0.852119  0.075733  0.072148\n",
      "21075   82574  0.808232  0.103257  0.088511\n",
      "21076   82580  0.798548  0.109406  0.092047\n",
      "21080   82549  0.862849  0.069858  0.067293\n",
      "21081  107026  0.879432  0.050563  0.070005\n",
      "21082   82584  0.768900  0.128985  0.102115\n",
      "\n",
      "[21042 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert predictions to data frame with ID\n",
    "cid = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "for pred_group in train_pred:\n",
    "    for pred in pred_group:\n",
    "        y1.append(pred[0])\n",
    "        y2.append(pred[1])\n",
    "        y3.append(pred[2])\n",
    "        \n",
    "for cid_group in cid_train:\n",
    "    for i in cid_group:\n",
    "        cid.append(i)\n",
    "\n",
    "ytrain_pred = pd.DataFrame({'cid': cid, 'y1': y1, 'y2': y2, 'y3': y3})\n",
    "ytrain_pred = ytrain_pred.drop_duplicates('cid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
