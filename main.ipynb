{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# from settings import *\n",
    "# import analyze_cascade\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import random\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_file = 'metadata_anon.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read meta data \n",
    "fin = open(metadata_file,'r')\n",
    "lines = fin.readlines()\n",
    "fin.close()\n",
    "cascade_id2metadata={}\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    item = eval(line)\n",
    "    cascade_id2metadata[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives of dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_depth2time = []\n",
    "len_num_followees_list = []\n",
    "len_depth2uu = []\n",
    "len_uu2time = []\n",
    "len_depth2breadth = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    len_depth2time.append(len(metadata['depth2time'].keys()))\n",
    "    len_num_followees_list.append(len(metadata['num_followees_list']))\n",
    "    len_depth2uu.append(len(metadata['depth2uu'].keys()))\n",
    "    len_uu2time.append(len(metadata['uu2time'].keys()))\n",
    "    len_depth2breadth.append(len(metadata['depth2breadth'].keys()))\n",
    "    \n",
    "# Convert to data frame\n",
    "df_len = pd.DataFrame({'depth2time ': len_depth2time, 'num_followees_list': len_num_followees_list, 'depth2uu': len_depth2uu, \n",
    "                       'uu2time': len_uu2time, 'depth2breadth': len_depth2breadth})\n",
    "\n",
    "# # Get summary\n",
    "df_len.describe(percentiles = [0.25, 0.5, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Measure data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to get expression of each item in a dictionary entry\n",
    "def get_expression_list(entry):\n",
    "    expression = []\n",
    "    for i in entry.keys():\n",
    "        expression.append(float(entry[i]))\n",
    "    return expression\n",
    "\n",
    "# Convert y to classification\n",
    "def veracity_to_categorical(v):\n",
    "    if v == 'FALSE':\n",
    "        vbin = [1,0,0]\n",
    "    elif v == 'MIXED':\n",
    "        vbin = [0,1,0]\n",
    "    elif v == 'TRUE':\n",
    "        vbin = [0,0,1]\n",
    "    return vbin\n",
    "\n",
    "# Get data in list format\n",
    "data = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None:       \n",
    "        # Get depth\n",
    "        depth2time = get_expression_list(metadata['depth2time'])\n",
    "        depth2uu = get_expression_list(metadata['depth2uu'])\n",
    "        depth2breadth = get_expression_list(metadata['depth2breadth']) \n",
    "        veracity = veracity_to_categorical(metadata['veracity'])\n",
    "        data_id = []\n",
    "        for time, uu, breadth in zip(depth2time, depth2uu, depth2breadth):\n",
    "            data_t = [cascade, veracity, time, uu, breadth]\n",
    "            data_id.append(data_t)\n",
    "        data.extend([data_id])\n",
    "        \n",
    "# Function: Create training and test set\n",
    "def split_list(lst, train_size): # train_size is a proportion\n",
    "    split = len(lst) * train_size\n",
    "    if split.is_integer():\n",
    "        split = int(split)\n",
    "        return lst[:split], lst[split:]\n",
    "    else:\n",
    "        split = math.floor(split) + 1\n",
    "        return lst[:split], lst[split:]\n",
    "    \n",
    "# Function: Padding for groups of equal batches\n",
    "def padding(lst, bsize):\n",
    "    if len(lst) % bsize != 0:\n",
    "        psize = bsize - (len(lst) % 5)\n",
    "        samples = random.choices(lst, k=psize)\n",
    "        lst.extend(samples)\n",
    "    return lst\n",
    "\n",
    "# # # Separate id, x and y\n",
    "def separate(list_in_list):\n",
    "    cid = []\n",
    "    y = []\n",
    "    for lst in list_in_list:\n",
    "        cid.append(lst[0][0]) # only one id is needed\n",
    "#         veracity_id = []\n",
    "#         for sublist in lst:\n",
    "#             veracity_id.extend([sublist[1]])\n",
    "#         veracity.append(veracity_id)\n",
    "        y.append(lst[0][1])\n",
    "    x = []\n",
    "    for lst in list_in_list:\n",
    "        x_id = []\n",
    "        for sublist in lst:\n",
    "            x_id.append(sublist[2:])\n",
    "        x.extend([x_id])\n",
    "    return cid, y, x\n",
    "\n",
    "# # Group by sequence length and append to have batches of 5 for both training and test\n",
    "data.sort(key=len)   # Randomly reshuffle before? random.shuffle(data_train_padded)\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "cid_train = []\n",
    "cid_test = []\n",
    "for k, g in groupby(data, len):\n",
    "    group = list(g)\n",
    "    if len(group) > 2: # This omits too small groups\n",
    "        # Create train and test bucket\n",
    "        split_list(group, 0.5)\n",
    "        train_group, test_group = split_list(group, 0.5)\n",
    "        # Padd for equal batch size\n",
    "        train_group_padded = padding(train_group, 5)\n",
    "        test_group_padded = padding(test_group, 5)\n",
    "        # Separate list\n",
    "        cid_train_group, y_train_group, x_train_group = separate(train_group_padded)\n",
    "        cid_test_group, y_test_group, x_test_group = separate(test_group_padded)\n",
    "        # Append:  convert y and x into numpy array\n",
    "        x_train.append(np.array(x_train_group))\n",
    "        x_test.append(np.array(x_test_group))\n",
    "        y_train.append(np.array(y_train_group))\n",
    "        y_test.append(np.array(y_test_group))\n",
    "        cid_train.append(cid_train_group)\n",
    "        cid_test.append(cid_test_group)\n",
    "        \n",
    "# # Function to standardize the list\n",
    "# def standardization(lst, index, mean, std):\n",
    "#     for array3d in lst:\n",
    "#         for array2d in array3d:\n",
    "#             for vector in array2d:\n",
    "#                 vector[index] = (vector[index] - mean) / std\n",
    "#     return lst\n",
    "\n",
    "# # Function to compute mean and std of variable and then standardizes this variable in list\n",
    "# def standardize_data(a_list, b_list, index):\n",
    "#     var = []\n",
    "#     # Compute mean and std from train data variable\n",
    "#     for array3d in a_list:\n",
    "#         for array2d in array3d:\n",
    "#             for vector in array2d:\n",
    "#                 var.append(vector[index])\n",
    "#     var = np.array(var)\n",
    "#     var_mean = var.mean()\n",
    "#     var_std = var.std()\n",
    "#     # Standardize a\n",
    "#     a_list_std = standardization(a_list, index, var_mean, var_std)\n",
    "#     b_list_std = standardization(b_list, index, var_mean, var_std)\n",
    "#     return a_list_std, b_list_std\n",
    "\n",
    "# # Standardize all variables\n",
    "# def standardize_all(a_list, b_list):\n",
    "#     length = len(a_list[0][0][0])\n",
    "#     indices = list(range(length))\n",
    "#     for i in indices:\n",
    "#         std_a, std_b = standardize_data(a_list, b_list, i)\n",
    "#     return std_a, std_b\n",
    "\n",
    "# x_train, x_test = standardize_all(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM on dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12960/12960 [==============================] - 12s 917us/step - loss: 0.5275 - acc: 0.7897\n",
      "Epoch 2/10\n",
      "12960/12960 [==============================] - 10s 788us/step - loss: 0.4584 - acc: 0.8108\n",
      "Epoch 3/10\n",
      "12960/12960 [==============================] - 10s 789us/step - loss: 0.4499 - acc: 0.8368\n",
      "Epoch 4/10\n",
      "12960/12960 [==============================] - 10s 778us/step - loss: 0.4456 - acc: 0.8424\n",
      "Epoch 5/10\n",
      "12960/12960 [==============================] - 10s 796us/step - loss: 0.4429 - acc: 0.8424\n",
      "Epoch 6/10\n",
      "12960/12960 [==============================] - 10s 792us/step - loss: 0.4409 - acc: 0.8425\n",
      "Epoch 7/10\n",
      "12960/12960 [==============================] - 11s 832us/step - loss: 0.4400 - acc: 0.8425\n",
      "Epoch 8/10\n",
      "12960/12960 [==============================] - 11s 842us/step - loss: 0.4393 - acc: 0.8425\n",
      "Epoch 9/10\n",
      "12960/12960 [==============================] - 11s 845us/step - loss: 0.4386 - acc: 0.8425\n",
      "Epoch 10/10\n",
      "12960/12960 [==============================] - 11s 844us/step - loss: 0.4380 - acc: 0.8425\n",
      "Epoch 1/10\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.4656 - acc: 0.8219\n",
      "Epoch 2/10\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.4410 - acc: 0.8290\n",
      "Epoch 3/10\n",
      "4790/4790 [==============================] - 7s 1ms/step - loss: 0.4575 - acc: 0.7885\n",
      "Epoch 4/10\n",
      "4790/4790 [==============================] - 6s 1ms/step - loss: 0.4769 - acc: 0.8332\n",
      "Epoch 5/10\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.4099 - acc: 0.8670\n",
      "Epoch 6/10\n",
      "4790/4790 [==============================] - 6s 1ms/step - loss: 0.3882 - acc: 0.8722\n",
      "Epoch 7/10\n",
      "4790/4790 [==============================] - 6s 1ms/step - loss: 0.3841 - acc: 0.8727\n",
      "Epoch 8/10\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.3822 - acc: 0.8727\n",
      "Epoch 9/10\n",
      "4790/4790 [==============================] - 6s 1ms/step - loss: 0.3804 - acc: 0.8706\n",
      "Epoch 10/10\n",
      "4790/4790 [==============================] - 6s 1ms/step - loss: 0.3853 - acc: 0.8722\n",
      "Epoch 1/10\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.3920 - acc: 0.8648\n",
      "Epoch 2/10\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.3615 - acc: 0.8760\n",
      "Epoch 3/10\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.3575 - acc: 0.8804\n",
      "Epoch 4/10\n",
      "1790/1790 [==============================] - 3s 1ms/step - loss: 0.3569 - acc: 0.8810\n",
      "Epoch 5/10\n",
      "1790/1790 [==============================] - 3s 1ms/step - loss: 0.3542 - acc: 0.8855\n",
      "Epoch 6/10\n",
      "1790/1790 [==============================] - 3s 2ms/step - loss: 0.3531 - acc: 0.8827\n",
      "Epoch 7/10\n",
      "1790/1790 [==============================] - 3s 2ms/step - loss: 0.3521 - acc: 0.8872\n",
      "Epoch 8/10\n",
      "1790/1790 [==============================] - 3s 2ms/step - loss: 0.3522 - acc: 0.8849\n",
      "Epoch 9/10\n",
      "1790/1790 [==============================] - 4s 2ms/step - loss: 0.3536 - acc: 0.8832\n",
      "Epoch 10/10\n",
      "1790/1790 [==============================] - 4s 2ms/step - loss: 0.3517 - acc: 0.8849\n",
      "Epoch 1/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.4661 - acc: 0.8342\n",
      "Epoch 2/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.4134 - acc: 0.8579\n",
      "Epoch 3/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.4092 - acc: 0.8618\n",
      "Epoch 4/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.3961 - acc: 0.8684\n",
      "Epoch 5/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.4064 - acc: 0.8645\n",
      "Epoch 6/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.4085 - acc: 0.8618\n",
      "Epoch 7/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.4015 - acc: 0.8684\n",
      "Epoch 8/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.3982 - acc: 0.8724\n",
      "Epoch 9/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.3929 - acc: 0.8684\n",
      "Epoch 10/10\n",
      "760/760 [==============================] - 1s 2ms/step - loss: 0.3925 - acc: 0.8724\n",
      "Epoch 1/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4459 - acc: 0.8219\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4158 - acc: 0.8375\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.4145 - acc: 0.8344\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4300 - acc: 0.8250\n",
      "Epoch 5/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4111 - acc: 0.8531\n",
      "Epoch 6/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3968 - acc: 0.8594\n",
      "Epoch 7/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3852 - acc: 0.8719\n",
      "Epoch 8/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4181 - acc: 0.8813\n",
      "Epoch 9/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4091 - acc: 0.8625\n",
      "Epoch 10/10\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.3919 - acc: 0.8500\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.6794 - acc: 0.7647\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.6903 - acc: 0.7706\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.5997 - acc: 0.7824\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.5990 - acc: 0.7824\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.6362 - acc: 0.7706\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.6066 - acc: 0.7765\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 0s 3ms/step - loss: 0.5965 - acc: 0.7824\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.5854 - acc: 0.7765\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 0s 3ms/step - loss: 0.5773 - acc: 0.7824\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.5727 - acc: 0.7706\n",
      "Epoch 1/10\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.6110 - acc: 0.7368\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.3750 - acc: 0.8737\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.3718 - acc: 0.8737\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.3669 - acc: 0.8737\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.3521 - acc: 0.8737\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.3381 - acc: 0.8842\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3670 - acc: 0.8737\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.3662 - acc: 0.8737\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.3657 - acc: 0.8737\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 0.3651 - acc: 0.8737\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7224 - acc: 0.7692\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6574 - acc: 0.7385\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6365 - acc: 0.7692\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5935 - acc: 0.8000\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5837 - acc: 0.8000\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5641 - acc: 0.8154\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5810 - acc: 0.7846\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5729 - acc: 0.7692\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5659 - acc: 0.7692\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5611 - acc: 0.7538\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5743 - acc: 0.7714\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5405 - acc: 0.8000\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5239 - acc: 0.8000\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5222 - acc: 0.8000\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5210 - acc: 0.8000\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5177 - acc: 0.8000\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4865 - acc: 0.8000\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4051 - acc: 0.8571\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3564 - acc: 0.8857\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.3283 - acc: 0.8857\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7062 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7058 - acc: 0.8000\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7052 - acc: 0.8000\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7038 - acc: 0.8000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7030 - acc: 0.8000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7022 - acc: 0.8000\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7008 - acc: 0.8000\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6997 - acc: 0.8000\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6987 - acc: 0.8000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6976 - acc: 0.8000\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3253 - acc: 0.9500\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3226 - acc: 0.9500\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3222 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3190 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2966 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2953 - acc: 0.9500\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2948 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2919 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2909 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2908 - acc: 0.9500\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0516 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0501 - acc: 1.0000\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1207 - acc: 0.6000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1199 - acc: 0.6000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - acc: 0.6000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1130 - acc: 0.6000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1076 - acc: 0.6000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1000 - acc: 0.6000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0940 - acc: 0.6000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0876 - acc: 0.6000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0795 - acc: 0.6000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0712 - acc: 0.6000\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2771 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2761 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2753 - acc: 0.9000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2739 - acc: 0.9000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2735 - acc: 0.9000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2731 - acc: 0.9000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2731 - acc: 0.9000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2728 - acc: 0.9000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2721 - acc: 0.9000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2719 - acc: 0.9000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0761 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0763 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0765 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0767 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0767 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0765 - acc: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4486 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4483 - acc: 0.8000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4479 - acc: 0.8000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4473 - acc: 0.8000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4467 - acc: 0.8000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4459 - acc: 0.8000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4451 - acc: 0.8000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4441 - acc: 0.8000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4431 - acc: 0.8000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4421 - acc: 0.8000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4637 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4638 - acc: 0.8000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4638 - acc: 0.8000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4637 - acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4634 - acc: 0.8000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4631 - acc: 0.8000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4627 - acc: 0.8000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4622 - acc: 0.8000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4617 - acc: 0.8000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4610 - acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (None, 3),  return_sequences = False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# model = M.Model(inputs=model_input, outputs=model_output)\n",
    "# model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "for X,Y in zip(x_train, y_train):\n",
    "    hist = model.fit(X, Y, epochs=5, batch_size=5)\n",
    "    \n",
    "# model.fit(std_depth_train, cat_veracity_train, epochs=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frame of static measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get static measures\n",
    "veracity = []\n",
    "virality = []\n",
    "depth = []\n",
    "breadth = []\n",
    "size = []\n",
    "verified = []\n",
    "nfollowers = []\n",
    "nfollowees = []\n",
    "engagement = []\n",
    "category = []\n",
    "day = []\n",
    "hour = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    veracity.append(metadata['veracity'])\n",
    "    virality.append(metadata['virality'])\n",
    "    depth.append(metadata['depth'])\n",
    "    breadth.append(metadata['max_breadth'])\n",
    "    size.append(metadata['size'])\n",
    "    verified.append(metadata['verified_list'][0])\n",
    "    nfollowers.append(metadata['num_followers_list'][0])\n",
    "    nfollowees.append(metadata['num_followees_list'][0])\n",
    "    engagement.append(metadata['engagement_list'][0])\n",
    "    category.append(metadata['rumor_category'])\n",
    "    day.append(metadata['start_date'].day)\n",
    "    hour.append(metadata['start_date'].hour)\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({'veracity': veracity, 'virality': virality, 'depth': depth, 'breadth': breadth, 'size': size, 'verified': verified, 'nfollowers': nfollowers, \n",
    "                   'nfollowees': nfollowees, 'engangement': engagement, 'category': category, 'day': day, 'hour': hour})\n",
    "\n",
    "# Inspect\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
