{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nic/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# from settings import *\n",
    "# import analyze_cascade\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from random import choices\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = 'metadata_anon.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read meta data \n",
    "fin = open(metadata_file,'r')\n",
    "lines = fin.readlines()\n",
    "fin.close()\n",
    "cascade_id2metadata={}\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    item = eval(line)\n",
    "    cascade_id2metadata[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives of dynamic measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>cid</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10703</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>106998</td>\n",
       "      <td>11</td>\n",
       "      <td>25.799399</td>\n",
       "      <td>186.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>23228</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11783</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>106999</td>\n",
       "      <td>9</td>\n",
       "      <td>10.811974</td>\n",
       "      <td>313.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14827</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>2.535338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6504</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107000</td>\n",
       "      <td>13</td>\n",
       "      <td>15.395237</td>\n",
       "      <td>518.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>14129</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.019705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5772</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107001</td>\n",
       "      <td>8</td>\n",
       "      <td>3.140842</td>\n",
       "      <td>189.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>9972</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.271008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6041</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107002</td>\n",
       "      <td>8</td>\n",
       "      <td>5.160261</td>\n",
       "      <td>174.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9526</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.115942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breadth                            category     cid  depth  engangement  \\\n",
       "0    10703  Viral Photos/Stories/Urban Legends  106998     11    25.799399   \n",
       "1    11783     Science/Nature/Tech/Food/Health  106999      9    10.811974   \n",
       "2     6504  Viral Photos/Stories/Urban Legends  107000     13    15.395237   \n",
       "3     5772  Viral Photos/Stories/Urban Legends  107001      8     3.140842   \n",
       "4     6041  Viral Photos/Stories/Urban Legends  107002      8     5.160261   \n",
       "\n",
       "   nfollowees  nfollowers   size veracity verified  virality  \n",
       "0       186.0       672.0  23228    MIXED    False  4.003857  \n",
       "1       313.0       380.0  14827    MIXED    False  2.535338  \n",
       "2       518.0       504.0  14129    MIXED    False  4.019705  \n",
       "3       189.0       228.0   9972    MIXED    False  3.271008  \n",
       "4       174.0       110.0   9526    MIXED    False  3.115942  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get static measures\n",
    "cid = []\n",
    "veracity = []\n",
    "virality = []\n",
    "depth = []\n",
    "breadth = []\n",
    "size = []\n",
    "verified = []\n",
    "nfollowers = []\n",
    "nfollowees = []\n",
    "engagement = []\n",
    "category = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        cid.append(cascade)\n",
    "        veracity.append(metadata['veracity'])\n",
    "        virality.append(metadata['virality'])\n",
    "        depth.append(metadata['depth'])\n",
    "        breadth.append(metadata['max_breadth'])\n",
    "        size.append(metadata['size'])\n",
    "        verified.append(metadata['verified_list'][0])\n",
    "        nfollowers.append(metadata['num_followers_list'][0])\n",
    "        nfollowees.append(metadata['num_followees_list'][0])\n",
    "        engagement.append(metadata['engagement_list'][0])\n",
    "        category.append(metadata['rumor_category'])\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({'cid': cid,\n",
    "                   'veracity': veracity,\n",
    "                   'virality': virality,\n",
    "                   'depth': depth,\n",
    "                   'breadth': breadth,\n",
    "                   'size': size,\n",
    "                   'verified': verified,\n",
    "                   'nfollowers': nfollowers,\n",
    "                   'nfollowees': nfollowees,\n",
    "                   'engangement': engagement,\n",
    "                   'category': category})\n",
    "\n",
    "# Inspect\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth2breadth</th>\n",
       "      <th>depth2time</th>\n",
       "      <th>depth2uu</th>\n",
       "      <th>num_followees_list</th>\n",
       "      <th>uu2time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.707707</td>\n",
       "      <td>1.707707</td>\n",
       "      <td>1.707707</td>\n",
       "      <td>93.878829</td>\n",
       "      <td>93.878829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.319555</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>950.694376</td>\n",
       "      <td>950.694376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth2breadth   depth2time       depth2uu  num_followees_list  \\\n",
       "count   42081.000000  42081.000000  42081.000000        42081.000000   \n",
       "mean        1.707707      1.707707      1.707707           93.878829   \n",
       "std         1.319555      1.319555      1.319555          950.694376   \n",
       "min         1.000000      1.000000      1.000000            2.000000   \n",
       "25%         1.000000      1.000000      1.000000            2.000000   \n",
       "50%         1.000000      1.000000      1.000000            4.000000   \n",
       "75%         2.000000      2.000000      2.000000            9.000000   \n",
       "100%       24.000000     24.000000     24.000000        46895.000000   \n",
       "max        24.000000     24.000000     24.000000        46895.000000   \n",
       "\n",
       "            uu2time  \n",
       "count  42081.000000  \n",
       "mean      93.878829  \n",
       "std      950.694376  \n",
       "min        2.000000  \n",
       "25%        2.000000  \n",
       "50%        4.000000  \n",
       "75%        9.000000  \n",
       "100%   46895.000000  \n",
       "max    46895.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_depth2time = []\n",
    "len_num_followees_list = []\n",
    "len_depth2uu = []\n",
    "len_uu2time = []\n",
    "len_depth2breadth = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        len_depth2time.append(len(metadata['depth2time'].keys()))\n",
    "        len_num_followees_list.append(len(metadata['num_followees_list']))\n",
    "        len_depth2uu.append(len(metadata['depth2uu'].keys()))\n",
    "        len_uu2time.append(len(metadata['uu2time'].keys()))\n",
    "        len_depth2breadth.append(len(metadata['depth2breadth'].keys()))\n",
    "    \n",
    "# Convert to data frame\n",
    "df_len = pd.DataFrame({'depth2time ': len_depth2time, \n",
    "                       'num_followees_list': len_num_followees_list, \n",
    "                       'depth2uu': len_depth2uu, \n",
    "                       'uu2time': len_uu2time, \n",
    "                       'depth2breadth': len_depth2breadth})\n",
    "\n",
    "# # Get summary\n",
    "df_len.describe(percentiles = [0.25, 0.5, 0.75, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get expression of each item in a dictionary entry\n",
    "def get_expression_list(entry):\n",
    "    expression = []\n",
    "    for i in entry.keys():\n",
    "        expression.append(float(entry[i]))\n",
    "    return expression\n",
    "\n",
    "# Convert y to classification\n",
    "def veracity_to_categorical(v):\n",
    "    if v == 'FALSE':\n",
    "        vbin = [1,0,0]\n",
    "    elif v == 'MIXED':\n",
    "        vbin = [0,1,0]\n",
    "    elif v == 'TRUE':\n",
    "        vbin = [0,0,1]\n",
    "    return vbin\n",
    "\n",
    "# Get data in list format\n",
    "data = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None:       \n",
    "        # Get depth\n",
    "        depth2time = get_expression_list(metadata['depth2time'])\n",
    "        depth2uu = get_expression_list(metadata['depth2uu'])\n",
    "        depth2breadth = get_expression_list(metadata['depth2breadth']) \n",
    "        veracity = veracity_to_categorical(metadata['veracity'])\n",
    "        data_id = []\n",
    "        for time, uu, breadth in zip(depth2time, depth2uu, depth2breadth):\n",
    "            data_t = [cascade, \n",
    "                      veracity,\n",
    "                      time, uu, breadth]\n",
    "            data_id.append(data_t)\n",
    "        data.extend([data_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Create training and test set\n",
    "def split_list(lst, train_size): # train_size is a proportion\n",
    "    split = len(lst) * train_size\n",
    "    if split.is_integer():\n",
    "        split = int(split)\n",
    "        return lst[:split], lst[split:]\n",
    "    else:\n",
    "        split = math.floor(split) + 1\n",
    "        return lst[:split], lst[split:]\n",
    "    \n",
    "# Function: Padding for groups of equal batches\n",
    "def padding(lst, bsize):\n",
    "    if len(lst) % bsize != 0:\n",
    "        psize = bsize - (len(lst) % 5)\n",
    "        samples = choices(lst, k=psize)\n",
    "        lst.extend(samples)\n",
    "    return lst\n",
    "\n",
    "# Get sublist\n",
    "def get_sublist(list_in_list, start, stop):\n",
    "    x = []\n",
    "    for lst in list_in_list:\n",
    "        x_id = []\n",
    "        for sublist in lst:\n",
    "            if stop is None:\n",
    "                x_id.append(sublist[start:])\n",
    "            elif start is None:\n",
    "                x_id.append(sublist[:stop])\n",
    "            else:\n",
    "                x_id.append(sublist[start:stop])\n",
    "        x.extend([x_id])\n",
    "    return x\n",
    "\n",
    "# Separate id, x and y\n",
    "def separate(list_in_list):\n",
    "    cid = []\n",
    "    y = []\n",
    "    for lst in list_in_list:\n",
    "        cid.append(lst[0][0]) # only one id is needed\n",
    "        # The following code would assume target replication in the model\n",
    "#         veracity_id = []\n",
    "#         for sublist in lst:\n",
    "#             veracity_id.extend([sublist[1]])\n",
    "#         veracity.append(veracity_id)\n",
    "        y.append(lst[0][1])\n",
    "    x = get_sublist(list_in_list,2,None)\n",
    "    return cid, y, x\n",
    "\n",
    "# # Group by sequence length and append to have batches of 5 for both training and test\n",
    "data.sort(key=len)   # Randomly reshuffle before? random.shuffle(...)\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "cid_train = []\n",
    "cid_test = []\n",
    "for k, g in groupby(data, len):\n",
    "    group = list(g)\n",
    "    if len(group) > 2: # This omits too small groups\n",
    "        shuffle(group)\n",
    "        # Create train and test bucket\n",
    "        train_group, test_group = split_list(group, 0.5)\n",
    "        # Padd for equal batch size\n",
    "        train_group_padded = padding(train_group, 5)\n",
    "        test_group_padded = padding(test_group, 5)\n",
    "        # Separate list\n",
    "        cid_train_group, y_train_group, x_train_group = separate(train_group)\n",
    "        cid_test_group, y_test_group, x_test_group = separate(test_group)\n",
    "        # Append:  convert y and x into numpy arrays for nn models\n",
    "        x_train.append(np.array(x_train_group))\n",
    "        x_test.append(np.array(x_test_group))\n",
    "        y_train.append(np.array(y_train_group))\n",
    "        y_test.append(np.array(y_test_group))\n",
    "        cid_train.append(cid_train_group)\n",
    "        cid_test.append(cid_test_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize the list\n",
    "def standardization(lst, index, mean, std):\n",
    "    for array3d in lst:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                vector[index] = (vector[index] - mean) / std\n",
    "    return lst\n",
    "\n",
    "# Function to compute mean and std of variable and then standardizes this variable in list\n",
    "def standardize_data(a_list, b_list, index):\n",
    "    var = []\n",
    "    # Compute mean and std from train data variable\n",
    "    for array3d in a_list:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                var.append(vector[index])\n",
    "    var = np.array(var)\n",
    "    var_mean = var.mean()\n",
    "    var_std = var.std()\n",
    "    # Standardize a\n",
    "    a_list_std = standardization(a_list, index, var_mean, var_std)\n",
    "    b_list_std = standardization(b_list, index, var_mean, var_std)\n",
    "    return a_list_std, b_list_std\n",
    "\n",
    "# Standardize all variables\n",
    "def standardize_all(a_list, b_list):\n",
    "    length = len(a_list[0][0][0])\n",
    "    indices = list(range(length))\n",
    "    for i in indices:\n",
    "        std_a, std_b = standardize_data(a_list, b_list, i)\n",
    "    return std_a, std_b\n",
    "\n",
    "x_train, x_test = standardize_all(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM train data descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  1   Observations:  12960  Sequence length 1\n",
      "Group:  2   Observations:  4790  Sequence length 2\n",
      "Group:  3   Observations:  1790  Sequence length 3\n",
      "Group:  4   Observations:  760  Sequence length 4\n",
      "Group:  5   Observations:  320  Sequence length 5\n",
      "Group:  6   Observations:  170  Sequence length 6\n",
      "Group:  7   Observations:  95  Sequence length 7\n",
      "Group:  8   Observations:  65  Sequence length 8\n",
      "Group:  9   Observations:  35  Sequence length 9\n",
      "Group:  10   Observations:  25  Sequence length 10\n",
      "Group:  11   Observations:  20  Sequence length 11\n",
      "Group:  12   Observations:  15  Sequence length 12\n",
      "Group:  13   Observations:  10  Sequence length 13\n",
      "Group:  14   Observations:  10  Sequence length 14\n",
      "Group:  15   Observations:  5  Sequence length 15\n",
      "Group:  16   Observations:  5  Sequence length 16\n",
      "Group:  17   Observations:  5  Sequence length 17\n",
      "Group:  18   Observations:  5  Sequence length 19\n"
     ]
    }
   ],
   "source": [
    "# Group size and sequence length\n",
    "i = 1\n",
    "for g in x_train:\n",
    "    print('Group: ', i, ' ', 'Observations: ', len(g), ' ' 'Sequence length', len(g[0]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  1 Counter({'FALSE': 9665, 'TRUE': 2010, 'MIXED': 1285})\n",
      "Group:  2 Counter({'FALSE': 3669, 'TRUE': 675, 'MIXED': 446})\n",
      "Group:  3 Counter({'FALSE': 1375, 'TRUE': 248, 'MIXED': 167})\n",
      "Group:  4 Counter({'FALSE': 608, 'TRUE': 90, 'MIXED': 62})\n",
      "Group:  5 Counter({'FALSE': 245, 'TRUE': 50, 'MIXED': 25})\n",
      "Group:  6 Counter({'FALSE': 127, 'TRUE': 24, 'MIXED': 19})\n",
      "Group:  7 Counter({'FALSE': 81, 'MIXED': 7, 'TRUE': 7})\n",
      "Group:  8 Counter({'FALSE': 52, 'MIXED': 8, 'TRUE': 5})\n",
      "Group:  9 Counter({'FALSE': 30, 'TRUE': 4, 'MIXED': 1})\n",
      "Group:  10 Counter({'FALSE': 21, 'TRUE': 2, 'MIXED': 2})\n",
      "Group:  11 Counter({'FALSE': 20})\n",
      "Group:  12 Counter({'FALSE': 14, 'TRUE': 1})\n",
      "Group:  13 Counter({'FALSE': 7, 'MIXED': 3})\n",
      "Group:  14 Counter({'FALSE': 9, 'MIXED': 1})\n",
      "Group:  15 Counter({'FALSE': 5})\n",
      "Group:  16 Counter({'FALSE': 5})\n",
      "Group:  17 Counter({'FALSE': 5})\n",
      "Group:  18 Counter({'FALSE': 3, 'MIXED': 2})\n"
     ]
    }
   ],
   "source": [
    "# Convert y to classification\n",
    "def reverse_veracity_to_categorical(vbin):\n",
    "    if vbin[0] == 1:\n",
    "        v = 'FALSE'\n",
    "    elif vbin[1] == 1:\n",
    "        v = 'MIXED'\n",
    "    elif vbin[2] == 1:\n",
    "        v = 'TRUE'\n",
    "    return v\n",
    "\n",
    "# Outcome distribution\n",
    "i = 1\n",
    "for g in y_train:\n",
    "    ver = []\n",
    "    for y in g:\n",
    "        ver.append(reverse_veracity_to_categorical(y))\n",
    "    print('Group: ', i, Counter(ver))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM for depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (None, 3),  return_sequences = False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12960/12960 [==============================] - 11s 823us/step - loss: 0.7604 - acc: 0.7478\n",
      "Epoch 2/2\n",
      "12960/12960 [==============================] - 10s 744us/step - loss: 0.7351 - acc: 0.7483\n",
      "Epoch 1/2\n",
      "4790/4790 [==============================] - 5s 947us/step - loss: 0.7043 - acc: 0.7658\n",
      "Epoch 2/2\n",
      "4790/4790 [==============================] - 5s 949us/step - loss: 0.7031 - acc: 0.7658\n",
      "Epoch 1/2\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.7153 - acc: 0.7592\n",
      "Epoch 2/2\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.7136 - acc: 0.7592\n",
      "Epoch 1/2\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.6975 - acc: 0.7763\n",
      "Epoch 2/2\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.6931 - acc: 0.7763\n",
      "Epoch 1/2\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7087 - acc: 0.7719\n",
      "Epoch 2/2\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.7036 - acc: 0.7719\n",
      "Epoch 1/2\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.6582 - acc: 0.7941\n",
      "Epoch 2/2\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.6520 - acc: 0.7941\n",
      "Epoch 1/2\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5317 - acc: 0.8737\n",
      "Epoch 2/2\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5104 - acc: 0.8737\n",
      "Epoch 1/2\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5754 - acc: 0.8308\n",
      "Epoch 2/2\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5637 - acc: 0.8308\n",
      "Epoch 1/2\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5834 - acc: 0.8286\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5814 - acc: 0.8286\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5994 - acc: 0.8000\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5943 - acc: 0.8000\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3236 - acc: 0.9500\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3200 - acc: 0.9500\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3343 - acc: 0.9333\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3310 - acc: 0.9333\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9891 - acc: 0.7000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9858 - acc: 0.7000\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7290 - acc: 0.8000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7268 - acc: 0.8000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1258 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1260 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1109 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1104 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1199 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1190 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1647 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1611 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit model and get train predictions\n",
    "train_pred = []\n",
    "test_pred = []\n",
    "for X,Y,Z in zip(x_train, y_train, x_test):\n",
    "    hist = model.fit(X, Y, epochs=2, batch_size=5)\n",
    "    pred1 = model.predict(X, batch_size=5)\n",
    "    pred2 = model.predict(Z, batch_size=5)\n",
    "    train_pred.append(pred1)\n",
    "    test_pred.append(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>train</th>\n",
       "      <th>ydepth0</th>\n",
       "      <th>ydepth1</th>\n",
       "      <th>ydepth2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66469</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67449</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64041</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66573</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68528</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733321</td>\n",
       "      <td>0.112525</td>\n",
       "      <td>0.154154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86372</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54685</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86903</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66568</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>87921</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>87241</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57821</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64102</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63518</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85356</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>66562</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51306</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68303</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>71477</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731536</td>\n",
       "      <td>0.113297</td>\n",
       "      <td>0.155167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85891</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>67879</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>66008</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55552</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64149</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>108926</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59838</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>68001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65574</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64799</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21031</th>\n",
       "      <td>81969</td>\n",
       "      <td>False</td>\n",
       "      <td>0.819308</td>\n",
       "      <td>0.080743</td>\n",
       "      <td>0.099950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21032</th>\n",
       "      <td>81962</td>\n",
       "      <td>False</td>\n",
       "      <td>0.822832</td>\n",
       "      <td>0.079245</td>\n",
       "      <td>0.097923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21033</th>\n",
       "      <td>81556</td>\n",
       "      <td>False</td>\n",
       "      <td>0.821558</td>\n",
       "      <td>0.074339</td>\n",
       "      <td>0.104103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21034</th>\n",
       "      <td>82405</td>\n",
       "      <td>False</td>\n",
       "      <td>0.861004</td>\n",
       "      <td>0.076362</td>\n",
       "      <td>0.062634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21035</th>\n",
       "      <td>82493</td>\n",
       "      <td>False</td>\n",
       "      <td>0.888622</td>\n",
       "      <td>0.061704</td>\n",
       "      <td>0.049673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21036</th>\n",
       "      <td>82521</td>\n",
       "      <td>False</td>\n",
       "      <td>0.909609</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.046592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21037</th>\n",
       "      <td>82528</td>\n",
       "      <td>False</td>\n",
       "      <td>0.906628</td>\n",
       "      <td>0.044332</td>\n",
       "      <td>0.049040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21038</th>\n",
       "      <td>82400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.865034</td>\n",
       "      <td>0.075318</td>\n",
       "      <td>0.059648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21039</th>\n",
       "      <td>81992</td>\n",
       "      <td>False</td>\n",
       "      <td>0.812872</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.103612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21040</th>\n",
       "      <td>82560</td>\n",
       "      <td>False</td>\n",
       "      <td>0.882482</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.074632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21045</th>\n",
       "      <td>82570</td>\n",
       "      <td>False</td>\n",
       "      <td>0.803512</td>\n",
       "      <td>0.062746</td>\n",
       "      <td>0.133742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21046</th>\n",
       "      <td>82550</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889333</td>\n",
       "      <td>0.046357</td>\n",
       "      <td>0.064310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21047</th>\n",
       "      <td>82324</td>\n",
       "      <td>False</td>\n",
       "      <td>0.849464</td>\n",
       "      <td>0.083868</td>\n",
       "      <td>0.066668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21048</th>\n",
       "      <td>82420</td>\n",
       "      <td>False</td>\n",
       "      <td>0.869430</td>\n",
       "      <td>0.073439</td>\n",
       "      <td>0.057131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21049</th>\n",
       "      <td>82332</td>\n",
       "      <td>False</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>0.083658</td>\n",
       "      <td>0.066245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>82579</td>\n",
       "      <td>False</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>0.098921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21051</th>\n",
       "      <td>82467</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903319</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.044904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21052</th>\n",
       "      <td>82342</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840066</td>\n",
       "      <td>0.086897</td>\n",
       "      <td>0.073038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21055</th>\n",
       "      <td>82531</td>\n",
       "      <td>False</td>\n",
       "      <td>0.905506</td>\n",
       "      <td>0.045712</td>\n",
       "      <td>0.048782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21056</th>\n",
       "      <td>82380</td>\n",
       "      <td>False</td>\n",
       "      <td>0.855872</td>\n",
       "      <td>0.081989</td>\n",
       "      <td>0.062139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21057</th>\n",
       "      <td>82472</td>\n",
       "      <td>False</td>\n",
       "      <td>0.905202</td>\n",
       "      <td>0.050737</td>\n",
       "      <td>0.044061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21058</th>\n",
       "      <td>82119</td>\n",
       "      <td>False</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>0.082612</td>\n",
       "      <td>0.090743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21060</th>\n",
       "      <td>82567</td>\n",
       "      <td>False</td>\n",
       "      <td>0.880054</td>\n",
       "      <td>0.043496</td>\n",
       "      <td>0.076449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21061</th>\n",
       "      <td>82578</td>\n",
       "      <td>False</td>\n",
       "      <td>0.863062</td>\n",
       "      <td>0.043237</td>\n",
       "      <td>0.093701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21062</th>\n",
       "      <td>82532</td>\n",
       "      <td>False</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>0.046360</td>\n",
       "      <td>0.047560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21065</th>\n",
       "      <td>82587</td>\n",
       "      <td>False</td>\n",
       "      <td>0.799986</td>\n",
       "      <td>0.050729</td>\n",
       "      <td>0.149284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21066</th>\n",
       "      <td>82580</td>\n",
       "      <td>False</td>\n",
       "      <td>0.864621</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>0.092260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21070</th>\n",
       "      <td>82435</td>\n",
       "      <td>False</td>\n",
       "      <td>0.886284</td>\n",
       "      <td>0.068048</td>\n",
       "      <td>0.045669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21071</th>\n",
       "      <td>82586</td>\n",
       "      <td>False</td>\n",
       "      <td>0.823218</td>\n",
       "      <td>0.048390</td>\n",
       "      <td>0.128392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21072</th>\n",
       "      <td>107026</td>\n",
       "      <td>False</td>\n",
       "      <td>0.831208</td>\n",
       "      <td>0.083387</td>\n",
       "      <td>0.085405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42078 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cid  train   ydepth0   ydepth1   ydepth2\n",
       "0       66469   True  0.734211  0.112140  0.153649\n",
       "1       67449   True  0.734211  0.112140  0.153649\n",
       "2       64041   True  0.735100  0.111755  0.153145\n",
       "3       66573   True  0.734211  0.112140  0.153649\n",
       "4       68528   True  0.733321  0.112525  0.154154\n",
       "5       86372   True  0.735544  0.111563  0.152893\n",
       "6       54685   True  0.735544  0.111563  0.152893\n",
       "7       64647   True  0.734656  0.111948  0.153397\n",
       "8       86903   True  0.735544  0.111563  0.152893\n",
       "9       66568   True  0.734211  0.112140  0.153649\n",
       "10      87921   True  0.735544  0.111563  0.152893\n",
       "11      87241   True  0.735544  0.111563  0.152893\n",
       "12      57821   True  0.735544  0.111563  0.152893\n",
       "13      64102   True  0.734656  0.111948  0.153397\n",
       "14      63518   True  0.735100  0.111755  0.153145\n",
       "15      85356   True  0.734211  0.112140  0.153649\n",
       "16      66562   True  0.734211  0.112140  0.153649\n",
       "17      51306   True  0.735544  0.111563  0.152893\n",
       "18      68303   True  0.733766  0.112332  0.153902\n",
       "19      71477   True  0.731536  0.113297  0.155167\n",
       "20      85891   True  0.735100  0.111755  0.153145\n",
       "21      67879   True  0.733766  0.112332  0.153902\n",
       "22      66008   True  0.734656  0.111948  0.153397\n",
       "23      55552   True  0.735544  0.111563  0.152893\n",
       "24      64149   True  0.734656  0.111948  0.153397\n",
       "25     108926   True  0.734656  0.111948  0.153397\n",
       "26      59838   True  0.735100  0.111755  0.153145\n",
       "27      68001   True  0.733766  0.112332  0.153902\n",
       "28      65574   True  0.734656  0.111948  0.153397\n",
       "29      64799   True  0.734656  0.111948  0.153397\n",
       "...       ...    ...       ...       ...       ...\n",
       "21031   81969  False  0.819308  0.080743  0.099950\n",
       "21032   81962  False  0.822832  0.079245  0.097923\n",
       "21033   81556  False  0.821558  0.074339  0.104103\n",
       "21034   82405  False  0.861004  0.076362  0.062634\n",
       "21035   82493  False  0.888622  0.061704  0.049673\n",
       "21036   82521  False  0.909609  0.043799  0.046592\n",
       "21037   82528  False  0.906628  0.044332  0.049040\n",
       "21038   82400  False  0.865034  0.075318  0.059648\n",
       "21039   81992  False  0.812872  0.083516  0.103612\n",
       "21040   82560  False  0.882482  0.042886  0.074632\n",
       "21045   82570  False  0.803512  0.062746  0.133742\n",
       "21046   82550  False  0.889333  0.046357  0.064310\n",
       "21047   82324  False  0.849464  0.083868  0.066668\n",
       "21048   82420  False  0.869430  0.073439  0.057131\n",
       "21049   82332  False  0.850098  0.083658  0.066245\n",
       "21050   82579  False  0.857472  0.043607  0.098921\n",
       "21051   82467  False  0.903319  0.051777  0.044904\n",
       "21052   82342  False  0.840066  0.086897  0.073038\n",
       "21055   82531  False  0.905506  0.045712  0.048782\n",
       "21056   82380  False  0.855872  0.081989  0.062139\n",
       "21057   82472  False  0.905202  0.050737  0.044061\n",
       "21058   82119  False  0.826644  0.082612  0.090743\n",
       "21060   82567  False  0.880054  0.043496  0.076449\n",
       "21061   82578  False  0.863062  0.043237  0.093701\n",
       "21062   82532  False  0.906080  0.046360  0.047560\n",
       "21065   82587  False  0.799986  0.050729  0.149284\n",
       "21066   82580  False  0.864621  0.043119  0.092260\n",
       "21070   82435  False  0.886284  0.068048  0.045669\n",
       "21071   82586  False  0.823218  0.048390  0.128392\n",
       "21072  107026  False  0.831208  0.083387  0.085405\n",
       "\n",
       "[42078 rows x 5 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predictions to data frame with ID\n",
    "def pred_to_df(ids, pred, var_name, train):\n",
    "    # Create data frame of predictions\n",
    "    n = len(pred[0][0])\n",
    "    cols = ['cid']\n",
    "    cols.extend([var_name + str(i) for i in range(n)])\n",
    "    init = 0\n",
    "    for id_gr,p_gr in zip(ids,pred):\n",
    "        for i,p in zip(id_gr, p_gr):\n",
    "            if init == 0:\n",
    "                matrix = [np.append([i],p)]\n",
    "                init = 1\n",
    "            else:\n",
    "                matrix = np.concatenate((matrix, [np.append([i],p)]), axis=0)\n",
    "    df = pd.DataFrame(matrix, columns=cols)\n",
    "    # Make id column integer\n",
    "    df.cid = df.cid.astype(int)\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates('cid')\n",
    "    # Combine train and test predictions and input ID\n",
    "    df.insert(1, 'train', train)\n",
    "    return df\n",
    "\n",
    "# Get train and test predictions\n",
    "ydepth = pred_to_df(cid_train, train_pred, 'ydepth', True)\n",
    "y_test_test = pred_to_df(cid_test, test_pred, 'ydepth', False)\n",
    "# Combine\n",
    "ydepth.append(y_test_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM for users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_comb = pd.merge(df, ydepth, how='left', on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>train</th>\n",
       "      <th>ydepth0</th>\n",
       "      <th>ydepth1</th>\n",
       "      <th>ydepth2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66469</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67449</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64041</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66573</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68528</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733321</td>\n",
       "      <td>0.112525</td>\n",
       "      <td>0.154154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86372</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54685</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86903</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66568</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>87921</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>87241</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57821</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64102</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63518</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85356</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>66562</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.112140</td>\n",
       "      <td>0.153649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51306</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68303</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>71477</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731536</td>\n",
       "      <td>0.113297</td>\n",
       "      <td>0.155167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85891</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>67879</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>66008</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55552</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735544</td>\n",
       "      <td>0.111563</td>\n",
       "      <td>0.152893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64149</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>108926</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59838</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.153145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>68001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65574</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64799</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.153397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21038</th>\n",
       "      <td>81636</td>\n",
       "      <td>True</td>\n",
       "      <td>0.747384</td>\n",
       "      <td>0.101676</td>\n",
       "      <td>0.150940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21039</th>\n",
       "      <td>82353</td>\n",
       "      <td>True</td>\n",
       "      <td>0.850910</td>\n",
       "      <td>0.083398</td>\n",
       "      <td>0.065691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21040</th>\n",
       "      <td>82601</td>\n",
       "      <td>True</td>\n",
       "      <td>0.822363</td>\n",
       "      <td>0.085376</td>\n",
       "      <td>0.092262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21045</th>\n",
       "      <td>82448</td>\n",
       "      <td>True</td>\n",
       "      <td>0.890027</td>\n",
       "      <td>0.059276</td>\n",
       "      <td>0.050697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21046</th>\n",
       "      <td>82442</td>\n",
       "      <td>True</td>\n",
       "      <td>0.884252</td>\n",
       "      <td>0.063229</td>\n",
       "      <td>0.052519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21047</th>\n",
       "      <td>82055</td>\n",
       "      <td>True</td>\n",
       "      <td>0.824796</td>\n",
       "      <td>0.081014</td>\n",
       "      <td>0.094190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21048</th>\n",
       "      <td>107000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.882201</td>\n",
       "      <td>0.043156</td>\n",
       "      <td>0.074643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21049</th>\n",
       "      <td>107009</td>\n",
       "      <td>True</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.091678</td>\n",
       "      <td>0.084458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>82307</td>\n",
       "      <td>True</td>\n",
       "      <td>0.842771</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.072145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21055</th>\n",
       "      <td>82054</td>\n",
       "      <td>True</td>\n",
       "      <td>0.827906</td>\n",
       "      <td>0.079833</td>\n",
       "      <td>0.092261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21056</th>\n",
       "      <td>82559</td>\n",
       "      <td>True</td>\n",
       "      <td>0.878623</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>0.075552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21057</th>\n",
       "      <td>82492</td>\n",
       "      <td>True</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>0.048652</td>\n",
       "      <td>0.044465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21058</th>\n",
       "      <td>82514</td>\n",
       "      <td>True</td>\n",
       "      <td>0.882800</td>\n",
       "      <td>0.064149</td>\n",
       "      <td>0.053051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21059</th>\n",
       "      <td>107004</td>\n",
       "      <td>True</td>\n",
       "      <td>0.910300</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.043267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21060</th>\n",
       "      <td>82558</td>\n",
       "      <td>True</td>\n",
       "      <td>0.880668</td>\n",
       "      <td>0.045354</td>\n",
       "      <td>0.073978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21061</th>\n",
       "      <td>82445</td>\n",
       "      <td>True</td>\n",
       "      <td>0.882418</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.053129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21062</th>\n",
       "      <td>82582</td>\n",
       "      <td>True</td>\n",
       "      <td>0.833710</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.119661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21065</th>\n",
       "      <td>82554</td>\n",
       "      <td>True</td>\n",
       "      <td>0.876731</td>\n",
       "      <td>0.048709</td>\n",
       "      <td>0.074560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21066</th>\n",
       "      <td>82440</td>\n",
       "      <td>True</td>\n",
       "      <td>0.869137</td>\n",
       "      <td>0.072517</td>\n",
       "      <td>0.058346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21067</th>\n",
       "      <td>82482</td>\n",
       "      <td>True</td>\n",
       "      <td>0.907215</td>\n",
       "      <td>0.048819</td>\n",
       "      <td>0.043966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21068</th>\n",
       "      <td>82556</td>\n",
       "      <td>True</td>\n",
       "      <td>0.879403</td>\n",
       "      <td>0.047171</td>\n",
       "      <td>0.073425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21070</th>\n",
       "      <td>82520</td>\n",
       "      <td>True</td>\n",
       "      <td>0.913743</td>\n",
       "      <td>0.045749</td>\n",
       "      <td>0.040508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21071</th>\n",
       "      <td>82537</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902308</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.049514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21072</th>\n",
       "      <td>82552</td>\n",
       "      <td>True</td>\n",
       "      <td>0.893274</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>0.060833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21073</th>\n",
       "      <td>82562</td>\n",
       "      <td>True</td>\n",
       "      <td>0.878645</td>\n",
       "      <td>0.045756</td>\n",
       "      <td>0.075599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21075</th>\n",
       "      <td>82469</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902609</td>\n",
       "      <td>0.053320</td>\n",
       "      <td>0.044071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21076</th>\n",
       "      <td>82574</td>\n",
       "      <td>True</td>\n",
       "      <td>0.868490</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.088956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21080</th>\n",
       "      <td>82584</td>\n",
       "      <td>True</td>\n",
       "      <td>0.834156</td>\n",
       "      <td>0.047141</td>\n",
       "      <td>0.118703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21081</th>\n",
       "      <td>82588</td>\n",
       "      <td>True</td>\n",
       "      <td>0.805873</td>\n",
       "      <td>0.050207</td>\n",
       "      <td>0.143920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21082</th>\n",
       "      <td>82549</td>\n",
       "      <td>True</td>\n",
       "      <td>0.902333</td>\n",
       "      <td>0.044465</td>\n",
       "      <td>0.053202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21042 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cid  train   ydepth0   ydepth1   ydepth2\n",
       "0       66469   True  0.734211  0.112140  0.153649\n",
       "1       67449   True  0.734211  0.112140  0.153649\n",
       "2       64041   True  0.735100  0.111755  0.153145\n",
       "3       66573   True  0.734211  0.112140  0.153649\n",
       "4       68528   True  0.733321  0.112525  0.154154\n",
       "5       86372   True  0.735544  0.111563  0.152893\n",
       "6       54685   True  0.735544  0.111563  0.152893\n",
       "7       64647   True  0.734656  0.111948  0.153397\n",
       "8       86903   True  0.735544  0.111563  0.152893\n",
       "9       66568   True  0.734211  0.112140  0.153649\n",
       "10      87921   True  0.735544  0.111563  0.152893\n",
       "11      87241   True  0.735544  0.111563  0.152893\n",
       "12      57821   True  0.735544  0.111563  0.152893\n",
       "13      64102   True  0.734656  0.111948  0.153397\n",
       "14      63518   True  0.735100  0.111755  0.153145\n",
       "15      85356   True  0.734211  0.112140  0.153649\n",
       "16      66562   True  0.734211  0.112140  0.153649\n",
       "17      51306   True  0.735544  0.111563  0.152893\n",
       "18      68303   True  0.733766  0.112332  0.153902\n",
       "19      71477   True  0.731536  0.113297  0.155167\n",
       "20      85891   True  0.735100  0.111755  0.153145\n",
       "21      67879   True  0.733766  0.112332  0.153902\n",
       "22      66008   True  0.734656  0.111948  0.153397\n",
       "23      55552   True  0.735544  0.111563  0.152893\n",
       "24      64149   True  0.734656  0.111948  0.153397\n",
       "25     108926   True  0.734656  0.111948  0.153397\n",
       "26      59838   True  0.735100  0.111755  0.153145\n",
       "27      68001   True  0.733766  0.112332  0.153902\n",
       "28      65574   True  0.734656  0.111948  0.153397\n",
       "29      64799   True  0.734656  0.111948  0.153397\n",
       "...       ...    ...       ...       ...       ...\n",
       "21038   81636   True  0.747384  0.101676  0.150940\n",
       "21039   82353   True  0.850910  0.083398  0.065691\n",
       "21040   82601   True  0.822363  0.085376  0.092262\n",
       "21045   82448   True  0.890027  0.059276  0.050697\n",
       "21046   82442   True  0.884252  0.063229  0.052519\n",
       "21047   82055   True  0.824796  0.081014  0.094190\n",
       "21048  107000   True  0.882201  0.043156  0.074643\n",
       "21049  107009   True  0.823864  0.091678  0.084458\n",
       "21050   82307   True  0.842771  0.085084  0.072145\n",
       "21055   82054   True  0.827906  0.079833  0.092261\n",
       "21056   82559   True  0.878623  0.045825  0.075552\n",
       "21057   82492   True  0.906882  0.048652  0.044465\n",
       "21058   82514   True  0.882800  0.064149  0.053051\n",
       "21059  107004   True  0.910300  0.046433  0.043267\n",
       "21060   82558   True  0.880668  0.045354  0.073978\n",
       "21061   82445   True  0.882418  0.064453  0.053129\n",
       "21062   82582   True  0.833710  0.046629  0.119661\n",
       "21065   82554   True  0.876731  0.048709  0.074560\n",
       "21066   82440   True  0.869137  0.072517  0.058346\n",
       "21067   82482   True  0.907215  0.048819  0.043966\n",
       "21068   82556   True  0.879403  0.047171  0.073425\n",
       "21070   82520   True  0.913743  0.045749  0.040508\n",
       "21071   82537   True  0.902308  0.048178  0.049514\n",
       "21072   82552   True  0.893274  0.045892  0.060833\n",
       "21073   82562   True  0.878645  0.045756  0.075599\n",
       "21075   82469   True  0.902609  0.053320  0.044071\n",
       "21076   82574   True  0.868490  0.042554  0.088956\n",
       "21080   82584   True  0.834156  0.047141  0.118703\n",
       "21081   82588   True  0.805873  0.050207  0.143920\n",
       "21082   82549   True  0.902333  0.044465  0.053202\n",
       "\n",
       "[21042 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       breadth                            category     cid  depth  \\\n",
      "0        10703  Viral Photos/Stories/Urban Legends  106998     11   \n",
      "1        11783     Science/Nature/Tech/Food/Health  106999      9   \n",
      "2         6504  Viral Photos/Stories/Urban Legends  107000     13   \n",
      "3         5772  Viral Photos/Stories/Urban Legends  107001      8   \n",
      "4         6041  Viral Photos/Stories/Urban Legends  107002      8   \n",
      "5         6160                       Entertainment  107003      8   \n",
      "6         2110  Viral Photos/Stories/Urban Legends  107004     14   \n",
      "7         3092  Viral Photos/Stories/Urban Legends  107005     10   \n",
      "8         4971                            Politics  107006      3   \n",
      "9         3374  Viral Photos/Stories/Urban Legends  107007      5   \n",
      "10        3906                            Politics  107008      4   \n",
      "11        1484  Viral Photos/Stories/Urban Legends  107009     13   \n",
      "12        3451                            Politics  107010      4   \n",
      "13        1477     Science/Nature/Tech/Food/Health  107011     10   \n",
      "14        2659     Science/Nature/Tech/Food/Health  107012      6   \n",
      "15        2465  Viral Photos/Stories/Urban Legends  107013      6   \n",
      "16        2324  Viral Photos/Stories/Urban Legends  107014      5   \n",
      "17        2224                            Politics  107015      6   \n",
      "18        1659  Viral Photos/Stories/Urban Legends  107016      7   \n",
      "19        1265  Viral Photos/Stories/Urban Legends  107017      9   \n",
      "20        2064             War/Terrorism/Shootings  107018      4   \n",
      "21        1974                            Politics  107019      4   \n",
      "22        1969     Science/Nature/Tech/Food/Health  107020      4   \n",
      "23        1604  Viral Photos/Stories/Urban Legends  107021      5   \n",
      "24        1498                            Politics  107022      8   \n",
      "25        1898     Science/Nature/Tech/Food/Health  107023      4   \n",
      "26        1470  Viral Photos/Stories/Urban Legends  107024      6   \n",
      "27        1781     Science/Nature/Tech/Food/Health  107025      4   \n",
      "28         238     Science/Nature/Tech/Food/Health  107026     19   \n",
      "29        1841     Science/Nature/Tech/Food/Health  107027      3   \n",
      "...        ...                                 ...     ...    ...   \n",
      "42051        2  Viral Photos/Stories/Urban Legends   88708      1   \n",
      "42052        2  Viral Photos/Stories/Urban Legends   88709      1   \n",
      "42053        2                            Politics   88710      1   \n",
      "42054        2                            Politics   88711      1   \n",
      "42055        2  Viral Photos/Stories/Urban Legends   88712      1   \n",
      "42056        2  Viral Photos/Stories/Urban Legends   88713      1   \n",
      "42057        2  Viral Photos/Stories/Urban Legends   88714      1   \n",
      "42058        2                            Politics   88715      1   \n",
      "42059        2  Viral Photos/Stories/Urban Legends   88716      1   \n",
      "42060        2                            Politics   88717      1   \n",
      "42061        2  Viral Photos/Stories/Urban Legends   88718      1   \n",
      "42062        2  Viral Photos/Stories/Urban Legends   88719      1   \n",
      "42063        2  Viral Photos/Stories/Urban Legends   88720      1   \n",
      "42064        2  Viral Photos/Stories/Urban Legends   88721      1   \n",
      "42065        2             War/Terrorism/Shootings   88722      1   \n",
      "42066        2             War/Terrorism/Shootings   88723      1   \n",
      "42067        2                            Politics   88724      1   \n",
      "42068        2  Viral Photos/Stories/Urban Legends   88725      1   \n",
      "42069        2                            Politics   88726      1   \n",
      "42070        2                            Politics   88727      1   \n",
      "42071        2  Viral Photos/Stories/Urban Legends   88728      1   \n",
      "42072        2             War/Terrorism/Shootings   88729      1   \n",
      "42073        2                            Politics   88730      1   \n",
      "42074        2                            Politics   88731      1   \n",
      "42075        2                            Politics   88732      1   \n",
      "42076        2             War/Terrorism/Shootings   88733      1   \n",
      "42077        2                            Politics   88734      1   \n",
      "42078        2                            Politics   88735      1   \n",
      "42079        2                            Politics   88736      1   \n",
      "42080        2  Viral Photos/Stories/Urban Legends   88737      1   \n",
      "\n",
      "       engangement  nfollowees  nfollowers   size veracity verified   virality  \n",
      "0        25.799399       186.0       672.0  23228    MIXED    False   4.003857  \n",
      "1        10.811974       313.0       380.0  14827    MIXED    False   2.535338  \n",
      "2        15.395237       518.0       504.0  14129    MIXED    False   4.019705  \n",
      "3         3.140842       189.0       228.0   9972    MIXED    False   3.271008  \n",
      "4         5.160261       174.0       110.0   9526    MIXED    False   3.115942  \n",
      "5        11.310233       846.0       842.0   9124    MIXED    False   2.971147  \n",
      "6        20.554899       542.0       716.0   6203    MIXED    False   5.110521  \n",
      "7         4.256828       364.0       179.0   5882    MIXED    False   3.633757  \n",
      "8         4.325858       417.0       637.0   5075    MIXED    False   2.041730  \n",
      "9        29.216077       910.0      1140.0   4305    MIXED    False   2.584301  \n",
      "10       15.414751       448.0       378.0   4055    MIXED    False   2.080313  \n",
      "11        3.146312       239.0     91836.0   3464    MIXED    False   4.428582  \n",
      "12        9.134362       431.0      9796.0   3603    MIXED    False   2.094225  \n",
      "13       80.530170       719.0      2718.0   3380    MIXED    False   3.987231  \n",
      "14        9.658417      1446.0       629.0   3429    MIXED    False   2.589997  \n",
      "15        8.321108      5712.0    774681.0   3063    MIXED    False   2.489869  \n",
      "16        5.212945         9.0    504357.0   3087    MIXED    False   2.636815  \n",
      "17        3.086224       666.0    828090.0   2852    MIXED    False   2.632665  \n",
      "18        1.806776       424.0       253.0   2351    MIXED    False   2.840743  \n",
      "19        2.122039       498.0       336.0   2210    MIXED    False   3.515614  \n",
      "20        2.791231       895.0       450.0   2299    MIXED    False   2.237198  \n",
      "21        4.767968       113.0     68867.0   2285    MIXED     True   2.285653  \n",
      "22        0.213356        41.0        23.0   2225    MIXED    False   2.261177  \n",
      "23        6.463371       402.0       135.0   2074    MIXED    False   2.493155  \n",
      "24        1.418634       735.0       142.0   1968    MIXED    False   2.684184  \n",
      "25       77.244572      2533.0      4004.0   2006    MIXED    False   2.126414  \n",
      "26       22.658920       161.0       171.0   1933    MIXED    False   2.628921  \n",
      "27        1.031317       559.0    924057.0   1975    MIXED    False   2.239955  \n",
      "28       21.730338      1556.0     20870.0   1049    MIXED    False  10.068822  \n",
      "29        3.720912       743.0       469.0   1905    MIXED    False   2.069208  \n",
      "...            ...         ...         ...    ...      ...      ...        ...  \n",
      "42051     3.650982       361.0       405.0      2     TRUE    False   1.000000  \n",
      "42052   148.703404       717.0      2125.0      2     TRUE    False   1.000000  \n",
      "42053     0.026014        27.0        14.0      2     TRUE    False   1.000000  \n",
      "42054    58.876277      3654.0      2709.0      2     TRUE    False   1.000000  \n",
      "42055     9.675505       605.0       572.0      2     TRUE    False   1.000000  \n",
      "42056   164.406240      1437.0      2798.0      2     TRUE    False   1.000000  \n",
      "42057    92.251521      1027.0      3978.0      2     TRUE    False   1.000000  \n",
      "42058    61.138527      4750.0      5637.0      2     TRUE    False   1.000000  \n",
      "42059    43.690789      6227.0      5662.0      2     TRUE    False   1.000000  \n",
      "42060     1.958008      3487.0      2165.0      2     TRUE    False   1.000000  \n",
      "42061    29.533856       772.0       413.0      2     TRUE    False   1.000000  \n",
      "42062    40.782877       174.0       294.0      2     TRUE    False   1.000000  \n",
      "42063     1.815892       775.0       331.0      2     TRUE    False   1.000000  \n",
      "42064    39.743739      2467.0      1607.0      2     TRUE    False   1.000000  \n",
      "42065     4.453690       851.0       485.0      2     TRUE    False   1.000000  \n",
      "42066    10.132830      6793.0      8278.0      2     TRUE    False   1.000000  \n",
      "42067    89.275604      4319.0      5156.0      2     TRUE    False   1.000000  \n",
      "42068    18.813645       125.0       630.0      2     TRUE    False   1.000000  \n",
      "42069    83.414304     35388.0     66915.0      2     TRUE    False   1.000000  \n",
      "42070    61.138527      4750.0      5637.0      2     TRUE    False   1.000000  \n",
      "42071     0.982309       120.0        68.0      2     TRUE    False   1.000000  \n",
      "42072     7.329452         NaN         NaN      2     TRUE     None   1.000000  \n",
      "42073     7.871515      1045.0      1299.0      2     TRUE    False   1.000000  \n",
      "42074    12.317670      2589.0      2578.0      2     TRUE    False   1.000000  \n",
      "42075    25.215137       675.0      2345.0      2     TRUE    False   1.000000  \n",
      "42076    27.590200      1364.0     19971.0      2     TRUE     True   1.000000  \n",
      "42077    84.561141      4979.0      4183.0      2     TRUE    False   1.000000  \n",
      "42078     2.201701        66.0        44.0      2     TRUE    False   1.000000  \n",
      "42079     4.112290       803.0       946.0      2     TRUE    False   1.000000  \n",
      "42080    33.946515       227.0       946.0      2     TRUE    False   1.000000  \n",
      "\n",
      "[42081 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
