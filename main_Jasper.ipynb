{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# from settings import *\n",
    "# import analyze_cascade\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from random import choices\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#metadata_file = 'metadata_anon.txt' for Nic\n",
    "metadata_file = '/Users/jaspermeijering/Google Drive/a Study/EPA Study Abroad - Carnegie Mellon University/Courses/CMU - 95845 - Applied Analytics The Machine Learning Pipeline/Machine Learning Pipeline Final Project/Data/FalseNews_Code_Data/data/metadata_anon.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read meta data \n",
    "fin = open(metadata_file,'r')\n",
    "lines = fin.readlines()\n",
    "fin.close()\n",
    "cascade_id2metadata={}\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    item = eval(line)\n",
    "    cascade_id2metadata[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives of dynamic measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>cid</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10703</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>106998</td>\n",
       "      <td>11</td>\n",
       "      <td>25.799399</td>\n",
       "      <td>186.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>23228</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11783</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>106999</td>\n",
       "      <td>9</td>\n",
       "      <td>10.811974</td>\n",
       "      <td>313.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14827</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>2.535338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6504</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107000</td>\n",
       "      <td>13</td>\n",
       "      <td>15.395237</td>\n",
       "      <td>518.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>14129</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.019705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5772</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107001</td>\n",
       "      <td>8</td>\n",
       "      <td>3.140842</td>\n",
       "      <td>189.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>9972</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.271008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6041</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107002</td>\n",
       "      <td>8</td>\n",
       "      <td>5.160261</td>\n",
       "      <td>174.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9526</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.115942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breadth                            category     cid  depth  engangement  \\\n",
       "0    10703  Viral Photos/Stories/Urban Legends  106998     11    25.799399   \n",
       "1    11783     Science/Nature/Tech/Food/Health  106999      9    10.811974   \n",
       "2     6504  Viral Photos/Stories/Urban Legends  107000     13    15.395237   \n",
       "3     5772  Viral Photos/Stories/Urban Legends  107001      8     3.140842   \n",
       "4     6041  Viral Photos/Stories/Urban Legends  107002      8     5.160261   \n",
       "\n",
       "   nfollowees  nfollowers   size veracity verified  virality  \n",
       "0       186.0       672.0  23228    MIXED    False  4.003857  \n",
       "1       313.0       380.0  14827    MIXED    False  2.535338  \n",
       "2       518.0       504.0  14129    MIXED    False  4.019705  \n",
       "3       189.0       228.0   9972    MIXED    False  3.271008  \n",
       "4       174.0       110.0   9526    MIXED    False  3.115942  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get static measures\n",
    "veracity = []\n",
    "virality = []\n",
    "depth = []\n",
    "breadth = []\n",
    "size = []\n",
    "verified = []\n",
    "nfollowers = []\n",
    "nfollowees = []\n",
    "engagement = []\n",
    "category = []\n",
    "cascadeID= []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        veracity.append(metadata['veracity'])\n",
    "        virality.append(metadata['virality'])\n",
    "        depth.append(metadata['depth'])\n",
    "        breadth.append(metadata['max_breadth'])\n",
    "        size.append(metadata['size'])\n",
    "        verified.append(metadata['verified_list'][0])\n",
    "        nfollowers.append(metadata['num_followers_list'][0])\n",
    "        nfollowees.append(metadata['num_followees_list'][0])\n",
    "        engagement.append(metadata['engagement_list'][0])\n",
    "        category.append(metadata['rumor_category'])\n",
    "        cascadeID.append(cascade) # for merging models\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({'cid':cascadeID,'veracity': veracity, 'virality': virality, 'depth': depth, 'breadth': breadth, 'size': size, 'verified': verified, 'nfollowers': nfollowers, \n",
    "                   'nfollowees': nfollowees, 'engangement': engagement, 'category': category})\n",
    "\n",
    "# Inspect\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth2breadth</th>\n",
       "      <th>depth2time</th>\n",
       "      <th>depth2uu</th>\n",
       "      <th>num_followees_list</th>\n",
       "      <th>uu2time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "      <td>42081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.707707</td>\n",
       "      <td>1.707707</td>\n",
       "      <td>1.707707</td>\n",
       "      <td>93.878829</td>\n",
       "      <td>93.878829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.319555</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>1.319555</td>\n",
       "      <td>950.694376</td>\n",
       "      <td>950.694376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "      <td>46895.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       depth2breadth   depth2time       depth2uu  num_followees_list  \\\n",
       "count   42081.000000  42081.000000  42081.000000        42081.000000   \n",
       "mean        1.707707      1.707707      1.707707           93.878829   \n",
       "std         1.319555      1.319555      1.319555          950.694376   \n",
       "min         1.000000      1.000000      1.000000            2.000000   \n",
       "25%         1.000000      1.000000      1.000000            2.000000   \n",
       "50%         1.000000      1.000000      1.000000            4.000000   \n",
       "75%         2.000000      2.000000      2.000000            9.000000   \n",
       "100%       24.000000     24.000000     24.000000        46895.000000   \n",
       "max        24.000000     24.000000     24.000000        46895.000000   \n",
       "\n",
       "            uu2time  \n",
       "count  42081.000000  \n",
       "mean      93.878829  \n",
       "std      950.694376  \n",
       "min        2.000000  \n",
       "25%        2.000000  \n",
       "50%        4.000000  \n",
       "75%        9.000000  \n",
       "100%   46895.000000  \n",
       "max    46895.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_depth2time = []\n",
    "len_num_followees_list = []\n",
    "len_depth2uu = []\n",
    "len_uu2time = []\n",
    "len_depth2breadth = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        len_depth2time.append(len(metadata['depth2time'].keys()))\n",
    "        len_num_followees_list.append(len(metadata['num_followees_list']))\n",
    "        len_depth2uu.append(len(metadata['depth2uu'].keys()))\n",
    "        len_uu2time.append(len(metadata['uu2time'].keys()))\n",
    "        len_depth2breadth.append(len(metadata['depth2breadth'].keys()))\n",
    "    \n",
    "# Convert to data frame\n",
    "df_len = pd.DataFrame({'depth2time ': len_depth2time, \n",
    "                       'num_followees_list': len_num_followees_list, \n",
    "                       'depth2uu': len_depth2uu, \n",
    "                       'uu2time': len_uu2time, \n",
    "                       'depth2breadth': len_depth2breadth})\n",
    "\n",
    "# # Get summary\n",
    "df_len.describe(percentiles = [0.25, 0.5, 0.75, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to get expression of each item in a dictionary entry\n",
    "def get_expression_list(entry):\n",
    "    expression = []\n",
    "    for i in entry.keys():\n",
    "        expression.append(float(entry[i]))\n",
    "    return expression\n",
    "\n",
    "# Convert y to classification\n",
    "def veracity_to_categorical(v):\n",
    "    if v == 'FALSE':\n",
    "        vbin = [1,0,0]\n",
    "    elif v == 'MIXED':\n",
    "        vbin = [0,1,0]\n",
    "    elif v == 'TRUE':\n",
    "        vbin = [0,0,1]\n",
    "    return vbin\n",
    "\n",
    "# Get data in list format\n",
    "data = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None:       \n",
    "        # Get depth\n",
    "        depth2time = get_expression_list(metadata['depth2time'])\n",
    "        depth2uu = get_expression_list(metadata['depth2uu'])\n",
    "        depth2breadth = get_expression_list(metadata['depth2breadth']) \n",
    "        veracity = veracity_to_categorical(metadata['veracity'])\n",
    "        data_id = []\n",
    "        for time, uu, breadth in zip(depth2time, depth2uu, depth2breadth):\n",
    "            data_t = [cascade, \n",
    "                      veracity,\n",
    "                      time, uu, breadth]\n",
    "            data_id.append(data_t)\n",
    "        data.extend([data_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: Create training and test set\n",
    "def split_list(lst, train_size): # train_size is a proportion\n",
    "    split = len(lst) * train_size\n",
    "    if split.is_integer():\n",
    "        split = int(split)\n",
    "        return lst[:split], lst[split:]\n",
    "    else:\n",
    "        split = math.floor(split) + 1\n",
    "        return lst[:split], lst[split:]\n",
    "    \n",
    "# Function: Padding for groups of equal batches\n",
    "def padding(lst, bsize):\n",
    "    if len(lst) % bsize != 0:\n",
    "        psize = bsize - (len(lst) % 5)\n",
    "        samples = choices(lst, k=psize)\n",
    "        lst.extend(samples)\n",
    "    return lst\n",
    "\n",
    "# Get sublist\n",
    "def get_sublist(list_in_list, start, stop):\n",
    "    x = []\n",
    "    for lst in list_in_list:\n",
    "        x_id = []\n",
    "        for sublist in lst:\n",
    "            if stop is None:\n",
    "                x_id.append(sublist[start:])\n",
    "            elif start is None:\n",
    "                x_id.append(sublist[:stop])\n",
    "            else:\n",
    "                x_id.append(sublist[start:stop])\n",
    "        x.extend([x_id])\n",
    "    return x\n",
    "\n",
    "# Separate id, x and y\n",
    "def separate(list_in_list):\n",
    "    cid = []\n",
    "    y = []\n",
    "    for lst in list_in_list:\n",
    "        cid.append(lst[0][0]) # only one id is needed\n",
    "#         veracity_id = []\n",
    "#         for sublist in lst:\n",
    "#             veracity_id.extend([sublist[1]])\n",
    "#         veracity.append(veracity_id)\n",
    "        y.append(lst[0][1])\n",
    "    x = get_sublist(list_in_list,2,None)\n",
    "    return cid, y, x\n",
    "\n",
    "# # Group by sequence length and append to have batches of 5 for both training and test\n",
    "data.sort(key=len)   # Randomly reshuffle before? random.shuffle(...)\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "cid_train = []\n",
    "cid_test = []\n",
    "for k, g in groupby(data, len):\n",
    "    group = list(g)\n",
    "    if len(group) > 2: # This omits too small groups\n",
    "        shuffle(group)\n",
    "        # Create train and test bucket\n",
    "        train_group, test_group = split_list(group, 0.5)\n",
    "        # Padd for equal batch size\n",
    "        train_group_padded = padding(train_group, 5)\n",
    "        test_group_padded = padding(test_group, 5)\n",
    "        # Separate list\n",
    "        cid_train_group, y_train_group, x_train_group = separate(train_group)\n",
    "        cid_test_group, y_test_group, x_test_group = separate(test_group)\n",
    "        # Append:  convert y and x into numpy array\n",
    "        x_train.append(np.array(x_train_group))\n",
    "        x_test.append(np.array(x_test_group))\n",
    "        y_train.append(np.array(y_train_group))\n",
    "        y_test.append(np.array(y_test_group))\n",
    "        cid_train.append(cid_train_group)\n",
    "        cid_test.append(cid_test_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to standardize the list\n",
    "def standardization(lst, index, mean, std):\n",
    "    for array3d in lst:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                vector[index] = (vector[index] - mean) / std\n",
    "    return lst\n",
    "\n",
    "# Function to compute mean and std of variable and then standardizes this variable in list\n",
    "def standardize_data(a_list, b_list, index):\n",
    "    var = []\n",
    "    # Compute mean and std from train data variable\n",
    "    for array3d in a_list:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                var.append(vector[index])\n",
    "    var = np.array(var)\n",
    "    var_mean = var.mean()\n",
    "    var_std = var.std()\n",
    "    # Standardize a\n",
    "    a_list_std = standardization(a_list, index, var_mean, var_std)\n",
    "    b_list_std = standardization(b_list, index, var_mean, var_std)\n",
    "    return a_list_std, b_list_std\n",
    "\n",
    "# Standardize all variables\n",
    "def standardize_all(a_list, b_list):\n",
    "    length = len(a_list[0][0][0])\n",
    "    indices = list(range(length))\n",
    "    for i in indices:\n",
    "        std_a, std_b = standardize_data(a_list, b_list, i)\n",
    "    return std_a, std_b\n",
    "\n",
    "x_train, x_test = standardize_all(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM train data descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  1   Observations:  12960  Sequence length 1\n",
      "Group:  2   Observations:  4790  Sequence length 2\n",
      "Group:  3   Observations:  1790  Sequence length 3\n",
      "Group:  4   Observations:  760  Sequence length 4\n",
      "Group:  5   Observations:  320  Sequence length 5\n",
      "Group:  6   Observations:  170  Sequence length 6\n",
      "Group:  7   Observations:  95  Sequence length 7\n",
      "Group:  8   Observations:  65  Sequence length 8\n",
      "Group:  9   Observations:  35  Sequence length 9\n",
      "Group:  10   Observations:  25  Sequence length 10\n",
      "Group:  11   Observations:  20  Sequence length 11\n",
      "Group:  12   Observations:  15  Sequence length 12\n",
      "Group:  13   Observations:  10  Sequence length 13\n",
      "Group:  14   Observations:  10  Sequence length 14\n",
      "Group:  15   Observations:  5  Sequence length 15\n",
      "Group:  16   Observations:  5  Sequence length 16\n",
      "Group:  17   Observations:  5  Sequence length 17\n",
      "Group:  18   Observations:  5  Sequence length 19\n"
     ]
    }
   ],
   "source": [
    "# Group size and sequence length\n",
    "i = 1\n",
    "for g in x_train:\n",
    "    print('Group: ', i, ' ', 'Observations: ', len(g), ' ' 'Sequence length', len(g[0]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:  1 Counter({'FALSE': 9726, 'TRUE': 1965, 'MIXED': 1269})\n",
      "Group:  2 Counter({'FALSE': 3672, 'TRUE': 669, 'MIXED': 449})\n",
      "Group:  3 Counter({'FALSE': 1378, 'TRUE': 247, 'MIXED': 165})\n",
      "Group:  4 Counter({'FALSE': 581, 'TRUE': 107, 'MIXED': 72})\n",
      "Group:  5 Counter({'FALSE': 251, 'TRUE': 41, 'MIXED': 28})\n",
      "Group:  6 Counter({'FALSE': 130, 'TRUE': 21, 'MIXED': 19})\n",
      "Group:  7 Counter({'FALSE': 81, 'MIXED': 8, 'TRUE': 6})\n",
      "Group:  8 Counter({'FALSE': 56, 'MIXED': 6, 'TRUE': 3})\n",
      "Group:  9 Counter({'FALSE': 29, 'TRUE': 3, 'MIXED': 3})\n",
      "Group:  10 Counter({'FALSE': 22, 'MIXED': 2, 'TRUE': 1})\n",
      "Group:  11 Counter({'FALSE': 19, 'TRUE': 1})\n",
      "Group:  12 Counter({'FALSE': 14, 'TRUE': 1})\n",
      "Group:  13 Counter({'FALSE': 10})\n",
      "Group:  14 Counter({'FALSE': 10})\n",
      "Group:  15 Counter({'FALSE': 5})\n",
      "Group:  16 Counter({'FALSE': 5})\n",
      "Group:  17 Counter({'FALSE': 5})\n",
      "Group:  18 Counter({'FALSE': 4, 'MIXED': 1})\n"
     ]
    }
   ],
   "source": [
    "# Convert y to classification\n",
    "def reverse_veracity_to_categorical(vbin):\n",
    "    if vbin[0] == 1:\n",
    "        v = 'FALSE'\n",
    "    elif vbin[1] == 1:\n",
    "        v = 'MIXED'\n",
    "    elif vbin[2] == 1:\n",
    "        v = 'TRUE'\n",
    "    return v\n",
    "\n",
    "# Outcome distribution\n",
    "i = 1\n",
    "for g in y_train:\n",
    "    ver = []\n",
    "    for y in g:\n",
    "        ver.append(reverse_veracity_to_categorical(y))\n",
    "    print('Group: ', i, Counter(ver))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM on dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (None, 3),  return_sequences = False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ..., \n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        ..., \n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ..., \n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        ..., \n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12960/12960 [==============================] - 9s 733us/step - loss: 0.7595 - acc: 0.7482\n",
      "Epoch 2/2\n",
      "12960/12960 [==============================] - 9s 721us/step - loss: 0.7298 - acc: 0.7505\n",
      "Epoch 1/2\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.7048 - acc: 0.7666\n",
      "Epoch 2/2\n",
      "4790/4790 [==============================] - 5s 1ms/step - loss: 0.7029 - acc: 0.7666\n",
      "Epoch 1/2\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.6952 - acc: 0.7698\n",
      "Epoch 2/2\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.6952 - acc: 0.7698\n",
      "Epoch 1/2\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.7096 - acc: 0.7645\n",
      "Epoch 2/2\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.7081 - acc: 0.7645\n",
      "Epoch 1/2\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6832 - acc: 0.7844\n",
      "Epoch 2/2\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6767 - acc: 0.7844\n",
      "Epoch 1/2\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.7115 - acc: 0.7647\n",
      "Epoch 2/2\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.7101 - acc: 0.7647\n",
      "Epoch 1/2\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5449 - acc: 0.8526\n",
      "Epoch 2/2\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5300 - acc: 0.8526\n",
      "Epoch 1/2\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5264 - acc: 0.8615\n",
      "Epoch 2/2\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5154 - acc: 0.8615\n",
      "Epoch 1/2\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5410 - acc: 0.8286\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5389 - acc: 0.8286\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4914 - acc: 0.8800\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4901 - acc: 0.8800\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2614 - acc: 0.9500\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2605 - acc: 0.9500\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2933 - acc: 0.9333\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2917 - acc: 0.9333\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1309 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1296 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1118 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1094 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1282 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1270 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0910 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0944 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0937 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5776 - acc: 0.8000\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5775 - acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Fit model and get train predictions\n",
    "train_pred = []\n",
    "for X,Y in zip(x_train, y_train):\n",
    "    hist = model.fit(X, Y, epochs=2, batch_size=5)\n",
    "    pred = model.predict(X, batch_size=5)\n",
    "    train_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert predictions to data frame with ID\n",
    "cid = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "for pred_group in train_pred:\n",
    "    for pred in pred_group:\n",
    "        y1.append(pred[0])\n",
    "        y2.append(pred[1])\n",
    "        y3.append(pred[2])\n",
    "        \n",
    "for cid_group in cid_train:\n",
    "    for i in cid_group:\n",
    "        cid.append(i)\n",
    "\n",
    "ytrain_pred = pd.DataFrame({'cid': cid, 'y1': y1, 'y2': y2, 'y3': y3})\n",
    "ytrain_pred = ytrain_pred.drop_duplicates('cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21042"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytrain_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_old = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.merge(ytrain_pred, df_old, how = 'left',on = 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60024</td>\n",
       "      <td>0.75583</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>9.053365</td>\n",
       "      <td>897.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64755</td>\n",
       "      <td>0.75541</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>4</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62012</td>\n",
       "      <td>0.75583</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>15.567919</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86269</td>\n",
       "      <td>0.75583</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>5.825498</td>\n",
       "      <td>531.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64725</td>\n",
       "      <td>0.75541</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>4</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cid       y1        y2        y3  breadth  category  depth  engangement  \\\n",
       "0  60024  0.75583  0.093593  0.150577        3  Politics      1     9.053365   \n",
       "1  64755  0.75541  0.093782  0.150808        4  Politics      1   325.577912   \n",
       "2  62012  0.75583  0.093593  0.150577        3  Politics      1    15.567919   \n",
       "3  86269  0.75583  0.093593  0.150577        3  Politics      1     5.825498   \n",
       "4  64725  0.75541  0.093782  0.150808        4  Politics      1   325.577912   \n",
       "\n",
       "   nfollowees  nfollowers  size veracity verified  virality  \n",
       "0       897.0       906.0     3    FALSE    False  1.333333  \n",
       "1     20670.0     41239.0     4    FALSE    False  1.500000  \n",
       "2      1119.0      1460.0     3    FALSE    False  1.333333  \n",
       "3       531.0      3198.0     3     TRUE    False  1.333333  \n",
       "4     20670.0     41239.0     4    FALSE    False  1.500000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical and Continious model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "      <th>train_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60024</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>9.053365</td>\n",
       "      <td>897.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64755</td>\n",
       "      <td>0.755410</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>4</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62012</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>15.567919</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86269</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>5.825498</td>\n",
       "      <td>531.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64725</td>\n",
       "      <td>0.755410</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>4</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63521</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>1</td>\n",
       "      <td>47.682066</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55006</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>53.632710</td>\n",
       "      <td>842.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>109934</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>1</td>\n",
       "      <td>3.682158</td>\n",
       "      <td>65.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58804</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>1</td>\n",
       "      <td>17.310279</td>\n",
       "      <td>947.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70267</td>\n",
       "      <td>0.753305</td>\n",
       "      <td>0.094729</td>\n",
       "      <td>0.151966</td>\n",
       "      <td>9</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>126.061518</td>\n",
       "      <td>36857.0</td>\n",
       "      <td>37019.0</td>\n",
       "      <td>9</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53525</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>54.915811</td>\n",
       "      <td>4951.0</td>\n",
       "      <td>4139.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60357</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>23.146818</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>3871.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54525</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710527</td>\n",
       "      <td>980.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61194</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>109776</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>1</td>\n",
       "      <td>4.528703</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>2</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68711</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.094349</td>\n",
       "      <td>0.151502</td>\n",
       "      <td>7</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>7</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57057</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>1</td>\n",
       "      <td>6.453572</td>\n",
       "      <td>842.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55551</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Natural Disasters</td>\n",
       "      <td>1</td>\n",
       "      <td>2.727532</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>3172.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>56552</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>32.243176</td>\n",
       "      <td>792.0</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53433</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>10.695619</td>\n",
       "      <td>707.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>58998</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>3.644581</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>68741</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.094349</td>\n",
       "      <td>0.151502</td>\n",
       "      <td>7</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>7</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>86062</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>1</td>\n",
       "      <td>51.269381</td>\n",
       "      <td>966.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>57979</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>1</td>\n",
       "      <td>7.657301</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2689.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>86043</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>Politics</td>\n",
       "      <td>1</td>\n",
       "      <td>7.978424</td>\n",
       "      <td>4968.0</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>65588</td>\n",
       "      <td>0.755410</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>40.475073</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>2698.0</td>\n",
       "      <td>4</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59241</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380224</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56239</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>27.450495</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56562</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>2.435381</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55190</td>\n",
       "      <td>0.756249</td>\n",
       "      <td>0.093405</td>\n",
       "      <td>0.150346</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>5.476286</td>\n",
       "      <td>588.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21012</th>\n",
       "      <td>82601</td>\n",
       "      <td>0.807449</td>\n",
       "      <td>0.080092</td>\n",
       "      <td>0.112459</td>\n",
       "      <td>317</td>\n",
       "      <td>Politics</td>\n",
       "      <td>12</td>\n",
       "      <td>85.605152</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>13417.0</td>\n",
       "      <td>1032</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.723650</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21013</th>\n",
       "      <td>82539</td>\n",
       "      <td>0.917004</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.047652</td>\n",
       "      <td>4184</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>12</td>\n",
       "      <td>8.768596</td>\n",
       "      <td>295.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>9344</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>4.147170</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21014</th>\n",
       "      <td>82353</td>\n",
       "      <td>0.871504</td>\n",
       "      <td>0.053299</td>\n",
       "      <td>0.075196</td>\n",
       "      <td>1488</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>12</td>\n",
       "      <td>2.846027</td>\n",
       "      <td>231701.0</td>\n",
       "      <td>311743.0</td>\n",
       "      <td>2661</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>3.887961</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21015</th>\n",
       "      <td>81992</td>\n",
       "      <td>0.775910</td>\n",
       "      <td>0.094907</td>\n",
       "      <td>0.129183</td>\n",
       "      <td>184</td>\n",
       "      <td>Politics</td>\n",
       "      <td>13</td>\n",
       "      <td>25.558224</td>\n",
       "      <td>487.0</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>510</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.288740</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>82560</td>\n",
       "      <td>0.908440</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>0.052127</td>\n",
       "      <td>4314</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>13</td>\n",
       "      <td>13.763271</td>\n",
       "      <td>43.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>14227</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.028544</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21017</th>\n",
       "      <td>82528</td>\n",
       "      <td>0.919074</td>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>2487</td>\n",
       "      <td>Business</td>\n",
       "      <td>13</td>\n",
       "      <td>4.242025</td>\n",
       "      <td>296.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>8235</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.869016</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21018</th>\n",
       "      <td>82400</td>\n",
       "      <td>0.888755</td>\n",
       "      <td>0.045571</td>\n",
       "      <td>0.065673</td>\n",
       "      <td>868</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>13</td>\n",
       "      <td>25.094254</td>\n",
       "      <td>752.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>3271</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.938564</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21019</th>\n",
       "      <td>82521</td>\n",
       "      <td>0.920108</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>0.045836</td>\n",
       "      <td>2783</td>\n",
       "      <td>Politics</td>\n",
       "      <td>13</td>\n",
       "      <td>20.989461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7620</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>5.078605</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21020</th>\n",
       "      <td>82493</td>\n",
       "      <td>0.886276</td>\n",
       "      <td>0.049403</td>\n",
       "      <td>0.064320</td>\n",
       "      <td>1678</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>13</td>\n",
       "      <td>93.158628</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>5688</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.827761</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21021</th>\n",
       "      <td>82332</td>\n",
       "      <td>0.881278</td>\n",
       "      <td>0.048232</td>\n",
       "      <td>0.070489</td>\n",
       "      <td>821</td>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>6.295037</td>\n",
       "      <td>23969.0</td>\n",
       "      <td>29647.0</td>\n",
       "      <td>2275</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.773389</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21022</th>\n",
       "      <td>82514</td>\n",
       "      <td>0.915364</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>0.048678</td>\n",
       "      <td>4075</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>14</td>\n",
       "      <td>2.760212</td>\n",
       "      <td>219.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>6914</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>4.074938</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21023</th>\n",
       "      <td>82324</td>\n",
       "      <td>0.879806</td>\n",
       "      <td>0.048821</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>932</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>14</td>\n",
       "      <td>12.856403</td>\n",
       "      <td>419.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>2184</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>4.454669</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21024</th>\n",
       "      <td>82492</td>\n",
       "      <td>0.909004</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.052613</td>\n",
       "      <td>1081</td>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>96.467634</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>5552</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>7.132807</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21025</th>\n",
       "      <td>82467</td>\n",
       "      <td>0.902422</td>\n",
       "      <td>0.040710</td>\n",
       "      <td>0.056867</td>\n",
       "      <td>1371</td>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>8.585074</td>\n",
       "      <td>59.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4826</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.503420</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21026</th>\n",
       "      <td>82582</td>\n",
       "      <td>0.909875</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>9050</td>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>1.624103</td>\n",
       "      <td>63.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33750</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.213186</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21027</th>\n",
       "      <td>82420</td>\n",
       "      <td>0.895813</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>0.061559</td>\n",
       "      <td>923</td>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>4.950415</td>\n",
       "      <td>470.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>3484</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.356373</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21028</th>\n",
       "      <td>82558</td>\n",
       "      <td>0.909875</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>6829</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>14</td>\n",
       "      <td>14.121360</td>\n",
       "      <td>296.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>13574</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>3.874699</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21029</th>\n",
       "      <td>82556</td>\n",
       "      <td>0.911353</td>\n",
       "      <td>0.038223</td>\n",
       "      <td>0.050424</td>\n",
       "      <td>3655</td>\n",
       "      <td>Politics</td>\n",
       "      <td>15</td>\n",
       "      <td>45.748574</td>\n",
       "      <td>201.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>12675</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.263742</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21030</th>\n",
       "      <td>82554</td>\n",
       "      <td>0.912982</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>1997</td>\n",
       "      <td>Politics</td>\n",
       "      <td>15</td>\n",
       "      <td>24.400877</td>\n",
       "      <td>363.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>12217</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>8.226483</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21031</th>\n",
       "      <td>82119</td>\n",
       "      <td>0.803248</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.114782</td>\n",
       "      <td>225</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>15</td>\n",
       "      <td>5.521592</td>\n",
       "      <td>865.0</td>\n",
       "      <td>31766.0</td>\n",
       "      <td>791</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.466821</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21032</th>\n",
       "      <td>82440</td>\n",
       "      <td>0.892978</td>\n",
       "      <td>0.044938</td>\n",
       "      <td>0.062083</td>\n",
       "      <td>586</td>\n",
       "      <td>Politics</td>\n",
       "      <td>15</td>\n",
       "      <td>2.423061</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3896</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>10.245423</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21033</th>\n",
       "      <td>82578</td>\n",
       "      <td>0.911433</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>5547</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>16</td>\n",
       "      <td>21.481646</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>25550</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.999197</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21034</th>\n",
       "      <td>82532</td>\n",
       "      <td>0.923831</td>\n",
       "      <td>0.032473</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>2315</td>\n",
       "      <td>Politics</td>\n",
       "      <td>16</td>\n",
       "      <td>1.745002</td>\n",
       "      <td>474.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>8394</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.373106</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21035</th>\n",
       "      <td>82567</td>\n",
       "      <td>0.911433</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>5164</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>16</td>\n",
       "      <td>21.274198</td>\n",
       "      <td>393.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>16700</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.062984</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21036</th>\n",
       "      <td>82562</td>\n",
       "      <td>0.911433</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>2924</td>\n",
       "      <td>Politics</td>\n",
       "      <td>16</td>\n",
       "      <td>23.662750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>14733</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>7.403186</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21037</th>\n",
       "      <td>82587</td>\n",
       "      <td>0.912237</td>\n",
       "      <td>0.037942</td>\n",
       "      <td>0.049820</td>\n",
       "      <td>13597</td>\n",
       "      <td>Politics</td>\n",
       "      <td>17</td>\n",
       "      <td>55.157117</td>\n",
       "      <td>499.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>45451</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.015849</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21038</th>\n",
       "      <td>82469</td>\n",
       "      <td>0.909862</td>\n",
       "      <td>0.037255</td>\n",
       "      <td>0.052883</td>\n",
       "      <td>1724</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>17</td>\n",
       "      <td>25.817683</td>\n",
       "      <td>361.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>4659</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>5.428979</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21039</th>\n",
       "      <td>82588</td>\n",
       "      <td>0.912941</td>\n",
       "      <td>0.037692</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>11475</td>\n",
       "      <td>Politics</td>\n",
       "      <td>19</td>\n",
       "      <td>8.053735</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2427.0</td>\n",
       "      <td>46895</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>6.705481</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21040</th>\n",
       "      <td>82549</td>\n",
       "      <td>0.922105</td>\n",
       "      <td>0.033258</td>\n",
       "      <td>0.044637</td>\n",
       "      <td>2431</td>\n",
       "      <td>Politics</td>\n",
       "      <td>19</td>\n",
       "      <td>17.840755</td>\n",
       "      <td>155.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>10751</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>False</td>\n",
       "      <td>7.801921</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21041</th>\n",
       "      <td>107026</td>\n",
       "      <td>0.812986</td>\n",
       "      <td>0.078072</td>\n",
       "      <td>0.108942</td>\n",
       "      <td>238</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>19</td>\n",
       "      <td>21.730338</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>1049</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>10.068822</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21042 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cid        y1        y2        y3  breadth  \\\n",
       "0       60024  0.755830  0.093593  0.150577        3   \n",
       "1       64755  0.755410  0.093782  0.150808        4   \n",
       "2       62012  0.755830  0.093593  0.150577        3   \n",
       "3       86269  0.755830  0.093593  0.150577        3   \n",
       "4       64725  0.755410  0.093782  0.150808        4   \n",
       "5       63521  0.755830  0.093593  0.150577        3   \n",
       "6       55006  0.756249  0.093405  0.150346        2   \n",
       "7      109934  0.756249  0.093405  0.150346        2   \n",
       "8       58804  0.756249  0.093405  0.150346        2   \n",
       "9       70267  0.753305  0.094729  0.151966        9   \n",
       "10      53525  0.756249  0.093405  0.150346        2   \n",
       "11      60357  0.755830  0.093593  0.150577        3   \n",
       "12      54525  0.756249  0.093405  0.150346        2   \n",
       "13      61194  0.755830  0.093593  0.150577        3   \n",
       "14     109776  0.756249  0.093405  0.150346        2   \n",
       "15      68711  0.754148  0.094349  0.151502        7   \n",
       "16      57057  0.756249  0.093405  0.150346        2   \n",
       "17      55551  0.756249  0.093405  0.150346        2   \n",
       "18      56552  0.756249  0.093405  0.150346        2   \n",
       "19      53433  0.756249  0.093405  0.150346        2   \n",
       "20      58998  0.756249  0.093405  0.150346        2   \n",
       "21      68741  0.754148  0.094349  0.151502        7   \n",
       "22      86062  0.755830  0.093593  0.150577        3   \n",
       "23      57979  0.756249  0.093405  0.150346        2   \n",
       "24      86043  0.755830  0.093593  0.150577        3   \n",
       "25      65588  0.755410  0.093782  0.150808        4   \n",
       "26      59241  0.756249  0.093405  0.150346        2   \n",
       "27      56239  0.756249  0.093405  0.150346        2   \n",
       "28      56562  0.756249  0.093405  0.150346        2   \n",
       "29      55190  0.756249  0.093405  0.150346        2   \n",
       "...       ...       ...       ...       ...      ...   \n",
       "21012   82601  0.807449  0.080092  0.112459      317   \n",
       "21013   82539  0.917004  0.035345  0.047652     4184   \n",
       "21014   82353  0.871504  0.053299  0.075196     1488   \n",
       "21015   81992  0.775910  0.094907  0.129183      184   \n",
       "21016   82560  0.908440  0.039433  0.052127     4314   \n",
       "21017   82528  0.919074  0.034584  0.046342     2487   \n",
       "21018   82400  0.888755  0.045571  0.065673      868   \n",
       "21019   82521  0.920108  0.034056  0.045836     2783   \n",
       "21020   82493  0.886276  0.049403  0.064320     1678   \n",
       "21021   82332  0.881278  0.048232  0.070489      821   \n",
       "21022   82514  0.915364  0.035959  0.048678     4075   \n",
       "21023   82324  0.879806  0.048821  0.071373      932   \n",
       "21024   82492  0.909004  0.038383  0.052613     1081   \n",
       "21025   82467  0.902422  0.040710  0.056867     1371   \n",
       "21026   82582  0.909875  0.038869  0.051256     9050   \n",
       "21027   82420  0.895813  0.042628  0.061559      923   \n",
       "21028   82558  0.909875  0.038869  0.051256     6829   \n",
       "21029   82556  0.911353  0.038223  0.050424     3655   \n",
       "21030   82554  0.912982  0.037433  0.049585     1997   \n",
       "21031   82119  0.803248  0.081970  0.114782      225   \n",
       "21032   82440  0.892978  0.044938  0.062083      586   \n",
       "21033   82578  0.911433  0.038258  0.050309     5547   \n",
       "21034   82532  0.923831  0.032473  0.043697     2315   \n",
       "21035   82567  0.911433  0.038258  0.050309     5164   \n",
       "21036   82562  0.911433  0.038258  0.050309     2924   \n",
       "21037   82587  0.912237  0.037942  0.049820    13597   \n",
       "21038   82469  0.909862  0.037255  0.052883     1724   \n",
       "21039   82588  0.912941  0.037692  0.049366    11475   \n",
       "21040   82549  0.922105  0.033258  0.044637     2431   \n",
       "21041  107026  0.812986  0.078072  0.108942      238   \n",
       "\n",
       "                                 category  depth  engangement  nfollowees  \\\n",
       "0                                Politics      1     9.053365       897.0   \n",
       "1                                Politics      1   325.577912     20670.0   \n",
       "2                                Politics      1    15.567919      1119.0   \n",
       "3                                Politics      1     5.825498       531.0   \n",
       "4                                Politics      1   325.577912     20670.0   \n",
       "5                 War/Terrorism/Shootings      1    47.682066      2848.0   \n",
       "6                                Business      1    53.632710       842.0   \n",
       "7      Viral Photos/Stories/Urban Legends      1     3.682158        65.0   \n",
       "8                 War/Terrorism/Shootings      1    17.310279       947.0   \n",
       "9                                Politics      1   126.061518     36857.0   \n",
       "10                               Politics      1    54.915811      4951.0   \n",
       "11                               Politics      1    23.146818      2167.0   \n",
       "12                               Business      1     0.710527       980.0   \n",
       "13                               Politics      1   325.577912     20670.0   \n",
       "14     Viral Photos/Stories/Urban Legends      1     4.528703      2128.0   \n",
       "15                               Politics      1   325.577912     20670.0   \n",
       "16     Viral Photos/Stories/Urban Legends      1     6.453572       842.0   \n",
       "17                      Natural Disasters      1     2.727532      1878.0   \n",
       "18                               Business      1    32.243176       792.0   \n",
       "19                               Politics      1    10.695619       707.0   \n",
       "20                          Entertainment      1     3.644581      1598.0   \n",
       "21                               Politics      1   325.577912     20670.0   \n",
       "22                War/Terrorism/Shootings      1    51.269381       966.0   \n",
       "23     Viral Photos/Stories/Urban Legends      1     7.657301       195.0   \n",
       "24                               Politics      1     7.978424      4968.0   \n",
       "25                               Business      1    40.475073      2209.0   \n",
       "26                          Entertainment      1     0.380224      1402.0   \n",
       "27                               Business      1    27.450495      2181.0   \n",
       "28                               Business      1     2.435381      1110.0   \n",
       "29                               Business      1     5.476286       588.0   \n",
       "...                                   ...    ...          ...         ...   \n",
       "21012                            Politics     12    85.605152      6096.0   \n",
       "21013  Viral Photos/Stories/Urban Legends     12     8.768596       295.0   \n",
       "21014     Science/Nature/Tech/Food/Health     12     2.846027    231701.0   \n",
       "21015                            Politics     13    25.558224       487.0   \n",
       "21016  Viral Photos/Stories/Urban Legends     13    13.763271        43.0   \n",
       "21017                            Business     13     4.242025       296.0   \n",
       "21018  Viral Photos/Stories/Urban Legends     13    25.094254       752.0   \n",
       "21019                            Politics     13    20.989461         NaN   \n",
       "21020                       Entertainment     13    93.158628       443.0   \n",
       "21021                            Politics     14     6.295037     23969.0   \n",
       "21022     Science/Nature/Tech/Food/Health     14     2.760212       219.0   \n",
       "21023  Viral Photos/Stories/Urban Legends     14    12.856403       419.0   \n",
       "21024                            Politics     14    96.467634         9.0   \n",
       "21025                            Politics     14     8.585074        59.0   \n",
       "21026                            Politics     14     1.624103        63.0   \n",
       "21027                            Politics     14     4.950415       470.0   \n",
       "21028                       Entertainment     14    14.121360       296.0   \n",
       "21029                            Politics     15    45.748574       201.0   \n",
       "21030                            Politics     15    24.400877       363.0   \n",
       "21031                       Entertainment     15     5.521592       865.0   \n",
       "21032                            Politics     15     2.423061        35.0   \n",
       "21033  Viral Photos/Stories/Urban Legends     16    21.481646      1002.0   \n",
       "21034                            Politics     16     1.745002       474.0   \n",
       "21035  Viral Photos/Stories/Urban Legends     16    21.274198       393.0   \n",
       "21036                            Politics     16    23.662750         2.0   \n",
       "21037                            Politics     17    55.157117       499.0   \n",
       "21038     Science/Nature/Tech/Food/Health     17    25.817683       361.0   \n",
       "21039                            Politics     19     8.053735       214.0   \n",
       "21040                            Politics     19    17.840755       155.0   \n",
       "21041     Science/Nature/Tech/Food/Health     19    21.730338      1556.0   \n",
       "\n",
       "       nfollowers   size veracity verified   virality train_test  \n",
       "0           906.0      3    FALSE    False   1.333333      train  \n",
       "1         41239.0      4    FALSE    False   1.500000      train  \n",
       "2          1460.0      3    FALSE    False   1.333333      train  \n",
       "3          3198.0      3     TRUE    False   1.333333      train  \n",
       "4         41239.0      4    FALSE    False   1.500000      train  \n",
       "5           887.0      3    FALSE    False   1.333333      train  \n",
       "6          1075.0      2    FALSE    False   1.000000      train  \n",
       "7           105.0      2    MIXED    False   1.000000      train  \n",
       "8           722.0      2    FALSE    False   1.000000      train  \n",
       "9         37019.0      9    FALSE    False   1.777778      train  \n",
       "10         4139.0      2    FALSE    False   1.000000      train  \n",
       "11         3871.0      3    FALSE    False   1.333333      train  \n",
       "12          486.0      2    FALSE    False   1.000000      train  \n",
       "13        41239.0      3    FALSE    False   1.333333      train  \n",
       "14         1237.0      2    MIXED    False   1.000000      train  \n",
       "15        41239.0      7    FALSE    False   1.714286      train  \n",
       "16         1208.0      2    FALSE    False   1.000000      train  \n",
       "17         3172.0      2    FALSE    False   1.000000      train  \n",
       "18         2440.0      2    FALSE    False   1.000000      train  \n",
       "19          319.0      2    FALSE    False   1.000000      train  \n",
       "20         1034.0      2    FALSE    False   1.000000      train  \n",
       "21        41239.0      7    FALSE    False   1.714286      train  \n",
       "22         1536.0      3     TRUE    False   1.333333      train  \n",
       "23         2689.0      2    FALSE    False   1.000000      train  \n",
       "24         3232.0      3     TRUE    False   1.333333      train  \n",
       "25         2698.0      4    FALSE    False   1.500000      train  \n",
       "26          343.0      2    FALSE    False   1.000000      train  \n",
       "27         2134.0      2    FALSE    False   1.000000      train  \n",
       "28          846.0      2    FALSE    False   1.000000      train  \n",
       "29          634.0      2    FALSE    False   1.000000      train  \n",
       "...           ...    ...      ...      ...        ...        ...  \n",
       "21012     13417.0   1032     TRUE    False   5.723650      train  \n",
       "21013       339.0   9344    FALSE    False   4.147170      train  \n",
       "21014    311743.0   2661    FALSE    False   3.887961      train  \n",
       "21015      1062.0    510    FALSE    False   5.288740      train  \n",
       "21016        79.0  14227    FALSE    False   5.028544      train  \n",
       "21017       239.0   8235    FALSE    False   5.869016      train  \n",
       "21018       439.0   3271    FALSE    False   5.938564      train  \n",
       "21019         NaN   7620    FALSE     None   5.078605      train  \n",
       "21020      1095.0   5688    FALSE    False   5.827761      train  \n",
       "21021     29647.0   2275    FALSE    False   5.773389      train  \n",
       "21022       207.0   6914    FALSE    False   4.074938      train  \n",
       "21023       463.0   2184    FALSE    False   4.454669      train  \n",
       "21024      1763.0   5552    FALSE    False   7.132807      train  \n",
       "21025       100.0   4826    FALSE    False   5.503420      train  \n",
       "21026        14.0  33750    FALSE    False   6.213186      train  \n",
       "21027       385.0   3484    FALSE    False   6.356373      train  \n",
       "21028       457.0  13574    FALSE    False   3.874699      train  \n",
       "21029       877.0  12675    FALSE    False   6.263742      train  \n",
       "21030       233.0  12217    FALSE    False   8.226483      train  \n",
       "21031     31766.0    791    FALSE    False   6.466821      train  \n",
       "21032        30.0   3896    FALSE    False  10.245423      train  \n",
       "21033      1760.0  25550    FALSE    False   6.999197      train  \n",
       "21034       452.0   8394    FALSE    False   6.373106      train  \n",
       "21035       633.0  16700    FALSE    False   6.062984      train  \n",
       "21036       688.0  14733    FALSE    False   7.403186      train  \n",
       "21037      4313.0  45451    FALSE    False   6.015849      train  \n",
       "21038       523.0   4659    FALSE    False   5.428979      train  \n",
       "21039      2427.0  46895    FALSE    False   6.705481      train  \n",
       "21040       224.0  10751    FALSE    False   7.801921      train  \n",
       "21041     20870.0   1049    MIXED    False  10.068822      train  \n",
       "\n",
       "[21042 rows x 15 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"train_test\"] = \"train\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_saved = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing: Make data numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed categories to numeric values, this is how they match [Politics, War/Terrorism/Shootings, Business, Viral Photos/Stories/Urban Legends, Natural Disasters, Entertainment, Science/Nature/Tech/Food/Health]\n",
      "Categories (7, object): [Politics, War/Terrorism/Shootings, Business, Viral Photos/Stories/Urban Legends, Natural Disasters, Entertainment, Science/Nature/Tech/Food/Health] [4 7 1 6 3 2 5]\n",
      "Transformed veracity to numeric values, this is how they match [FALSE, TRUE, MIXED]\n",
      "Categories (3, object): [FALSE, TRUE, MIXED] [1 3 2]\n",
      "Transformed verified to numeric values, this is how they match [False True None] [-9223372036854775808]\n"
     ]
    }
   ],
   "source": [
    "# Make category numeric\n",
    "df[\"category\"] = df[\"category\"].astype('category')\n",
    "df[\"category_num\"] = df.category.cat.rename_categories([1,2,3,4,5,6,7])\n",
    "df[\"category_num\"] = df[\"category_num\"].astype('int')\n",
    "print(\"Transformed categories to numeric values, this is how they match\",df.category.unique(),df.category_num.unique())\n",
    "\n",
    "# Make veracity numeric\n",
    "df[\"veracity\"] = df[\"veracity\"].astype('category')\n",
    "df[\"veracity_num\"] = df.veracity.cat.rename_categories([1,2,3])\n",
    "df[\"veracity_num\"] = df[\"veracity_num\"].astype('int')\n",
    "print(\"Transformed veracity to numeric values, this is how they match\",df.veracity.unique(),df.veracity_num.unique())\n",
    "\n",
    "# Make verified numeric\n",
    "df[\"verified_cat\"] = df[\"verified\"].astype('category')\n",
    "df[\"verified_cat\"] = df[\"verified_cat\"].cat.set_categories([\"True\",\"False\",\"None\"])\n",
    "#df[\"verified_cat\"].isnull().sum() # 136 nan / none values for verified\n",
    "#df.loc[df[\"verified_cat\"].isnull(),'verified'] = \"None\" # -> leave these cascades in. # this is wrong\n",
    "df[\"verified_num_pre\"] = df.verified_cat.cat.rename_categories([3,2,1])\n",
    "df[\"verified_num\"] = df[\"verified_num_pre\"].astype('int')\n",
    "print(\"Transformed verified to numeric values, this is how they match\",df.verified.unique(),df.verified_num.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keep relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>veracity_num</th>\n",
       "      <th>breadth</th>\n",
       "      <th>category_num</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>verified_num</th>\n",
       "      <th>virality</th>\n",
       "      <th>train_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60024</td>\n",
       "      <td>0.75583</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9.053365</td>\n",
       "      <td>897.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64755</td>\n",
       "      <td>0.75541</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62012</td>\n",
       "      <td>0.75583</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15.567919</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86269</td>\n",
       "      <td>0.75583</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.150577</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.825498</td>\n",
       "      <td>531.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64725</td>\n",
       "      <td>0.75541</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>325.577912</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>41239.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-9223372036854775808</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cid       y1        y2        y3  veracity_num  breadth  category_num  \\\n",
       "0  60024  0.75583  0.093593  0.150577             1        3             4   \n",
       "1  64755  0.75541  0.093782  0.150808             1        4             4   \n",
       "2  62012  0.75583  0.093593  0.150577             1        3             4   \n",
       "3  86269  0.75583  0.093593  0.150577             3        3             4   \n",
       "4  64725  0.75541  0.093782  0.150808             1        4             4   \n",
       "\n",
       "   depth  engangement  nfollowees  nfollowers  size         verified_num  \\\n",
       "0      1     9.053365       897.0       906.0     3 -9223372036854775808   \n",
       "1      1   325.577912     20670.0     41239.0     4 -9223372036854775808   \n",
       "2      1    15.567919      1119.0      1460.0     3 -9223372036854775808   \n",
       "3      1     5.825498       531.0      3198.0     3 -9223372036854775808   \n",
       "4      1   325.577912     20670.0     41239.0     4 -9223372036854775808   \n",
       "\n",
       "   virality train_test  \n",
       "0  1.333333      train  \n",
       "1  1.500000      train  \n",
       "2  1.333333      train  \n",
       "3  1.333333      train  \n",
       "4  1.500000      train  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep relevant columns\n",
    "column_names_df = ['cid','y1','y2','y3','veracity_num','breadth', 'category_num', 'depth', 'engangement','nfollowees', 'nfollowers', 'size', 'verified_num', 'virality','train_test']\n",
    "column_names_x =['cid','y1','y2','y3','breadth', 'category_num', 'depth', 'engangement','nfollowees', 'nfollowers', 'size', 'verified_num', 'virality']\n",
    "column_names_x_cat = ['category_num','verified_num']  # add cid?\n",
    "column_names_x_con = ['y1','y2','y3','breadth', 'depth', 'engangement', 'nfollowees', 'nfollowers', 'size', 'virality'] #add cid\n",
    "column_names_y =['veracity_num','cid'] # ['cid','veracity_num']\n",
    "\n",
    "df = df.loc[:,column_names_df]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_cat  = df.loc[df[\"train_test\"] == \"train\",column_names_x_cat ]\n",
    "X_test_cat  = df.loc[df[\"train_test\"] == \"test\",column_names_x_cat ]\n",
    "X_train_con  = df.loc[df[\"train_test\"] == \"train\",column_names_x_con ]\n",
    "X_test_con  = df.loc[df[\"train_test\"] == \"test\",column_names_x_con ]\n",
    "Y_train = df.loc[df[\"train_test\"] == \"train\",column_names_y ]\n",
    "Y_test = df.loc[df[\"train_test\"] == \"test\",column_names_y ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veracity_num</th>\n",
       "      <th>cid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>62012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   veracity_num    cid\n",
       "0             1  60024\n",
       "1             1  64755\n",
       "2             1  62012"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_Y_train = df.loc[df[\"train_test\"] == \"train\",column_names_y ]\n",
    "save_Y_test = df.loc[df[\"train_test\"] == \"train\",column_names_y ]\n",
    "save_Y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_Y_train.head(10)\n",
    "def change_formatY(save_Y_train):\n",
    "    save_Y_train.index = np.arange(1, len(save_Y_train) + 1)\n",
    "    for a in range(3):\n",
    "        save_Y_train[\"Y_input_%d\"% (a+1)] = 0\n",
    "    for i in range(len(save_Y_train)):\n",
    "        for j in range(4):\n",
    "            if save_Y_train.iloc[i,0] == j:\n",
    "                save_Y_train[\"Y_input_%d\"% (j)][i+1] = 1\n",
    "                break\n",
    "    return(save_Y_train.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_input_1</th>\n",
       "      <th>Y_input_2</th>\n",
       "      <th>Y_input_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_input_1  Y_input_2  Y_input_3\n",
       "1          1          0          0\n",
       "2          1          0          0\n",
       "3          1          0          0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = change_formatY(save_Y_train)\n",
    "Y_test = change_formatY(save_Y_test)\n",
    "Y_train = Y_train.loc[:,['Y_input_1','Y_input_2','Y_input_3']] # without CID\n",
    "Y_test = Y_test.loc[:,['Y_input_1','Y_input_2','Y_input_3']] # without CID\n",
    "Y_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_formatX(X_train_cat):\n",
    "    X_train_cat.index = np.arange(1, len(X_train_cat) + 1)\n",
    "    for a in range(7):\n",
    "        X_train_cat[\"category_num_%d\"% (a+1)] = 0\n",
    "    #for b in range(31):\n",
    "     #   X_train_cat[\"day_%d\"% (b+1)] = 0\n",
    "    for c in range(3):\n",
    "        X_train_cat[\"verified_%d\"% (c+1)] = 0\n",
    "    \n",
    "    for i in range(len(X_train_cat)):\n",
    "        for j in range(8):\n",
    "            if X_train_cat.iloc[i,0] == j:\n",
    "                X_train_cat[\"category_num_%d\"% (j)][i+1] = 1\n",
    "                break\n",
    "    #    for k in range(32):\n",
    "     #       if X_train_cat.iloc[i,1] == k:\n",
    "      #          X_train_cat[\"day_%d\"% (k)][i+1] = 1\n",
    "       #         break\n",
    "        for l in range(4):\n",
    "            if X_train_cat.iloc[i,2] == l:\n",
    "                X_train_cat[\"verified_%d\"% (l)][i+1] = 1\n",
    "                break     \n",
    "    return X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_cat2 = change_formatX(X_train_cat)\n",
    "X_test_cat2 = change_formatX(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_num_1</th>\n",
       "      <th>category_num_2</th>\n",
       "      <th>category_num_3</th>\n",
       "      <th>category_num_4</th>\n",
       "      <th>category_num_5</th>\n",
       "      <th>category_num_6</th>\n",
       "      <th>category_num_7</th>\n",
       "      <th>verified_1</th>\n",
       "      <th>verified_2</th>\n",
       "      <th>verified_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_num_1  category_num_2  category_num_3  category_num_4  \\\n",
       "1               0               0               0               1   \n",
       "2               0               0               0               1   \n",
       "3               0               0               0               1   \n",
       "4               0               0               0               1   \n",
       "5               0               0               0               1   \n",
       "\n",
       "   category_num_5  category_num_6  category_num_7  verified_1  verified_2  \\\n",
       "1               0               0               0           0           0   \n",
       "2               0               0               0           0           0   \n",
       "3               0               0               0           0           0   \n",
       "4               0               0               0           0           0   \n",
       "5               0               0               0           0           0   \n",
       "\n",
       "   verified_3  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this block only once (or in combination with the block above)\n",
    "X_train_cat2 = X_train_cat2.iloc[:,3:] # [:,4:] for dataframe without cid [:,3:] for dataframe with cid \n",
    "X_test_cat2 = X_test_cat2.iloc[:,3:] # [:,4:] for dataframe without cid\n",
    "X_train_cat2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize continious data ONLY RUN ONCE\n",
    "X_train_con = np.log(X_train_con.iloc[:,:]+1)\n",
    "X_test_con = np.log(X_test_con.iloc[:,:]+1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change datastructue df -> matrix\n",
    "X_train_cat  = X_train_cat2.as_matrix()\n",
    "X_test_cat = X_test_cat2.as_matrix() \n",
    "X_train_con  = X_train_con.as_matrix()\n",
    "X_test_con = X_test_con.as_matrix()\n",
    "Y_train = Y_train.as_matrix()\n",
    "Y_test = Y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21042/21042 [==============================] - 1s 65us/step - loss: 0.7433 - mean_squared_error: 0.1387 - acc: 0.7528\n",
      "Epoch 2/10\n",
      "21042/21042 [==============================] - 1s 42us/step - loss: 0.6950 - mean_squared_error: 0.1276 - acc: 0.7586\n",
      "Epoch 3/10\n",
      "21042/21042 [==============================] - 1s 42us/step - loss: 0.6895 - mean_squared_error: 0.1266 - acc: 0.7586\n",
      "Epoch 4/10\n",
      "21042/21042 [==============================] - 1s 42us/step - loss: 0.6871 - mean_squared_error: 0.1262 - acc: 0.7586\n",
      "Epoch 5/10\n",
      "21042/21042 [==============================] - 1s 44us/step - loss: 0.6863 - mean_squared_error: 0.1261 - acc: 0.7586\n",
      "Epoch 6/10\n",
      "21042/21042 [==============================] - 1s 43us/step - loss: 0.6856 - mean_squared_error: 0.1260 - acc: 0.7586\n",
      "Epoch 7/10\n",
      "21042/21042 [==============================] - 1s 44us/step - loss: 0.6848 - mean_squared_error: 0.1259 - acc: 0.7586\n",
      "Epoch 8/10\n",
      "21042/21042 [==============================] - 1s 45us/step - loss: 0.6845 - mean_squared_error: 0.1259 - acc: 0.7586\n",
      "Epoch 9/10\n",
      "21042/21042 [==============================] - 1s 46us/step - loss: 0.6841 - mean_squared_error: 0.1259 - acc: 0.7586\n",
      "Epoch 10/10\n",
      "21042/21042 [==============================] - 1s 45us/step - loss: 0.6839 - mean_squared_error: 0.1259 - acc: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1857c94b00>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(10,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(4, activation='relu')(inputs)\n",
    "x = Dense(4, activation='relu')(x)\n",
    "x = Dense(4, activation='tanh')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model_cat_new = Model(inputs=inputs, outputs=predictions)\n",
    "model_cat_new.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['mse','accuracy']) #accuracy\n",
    "model_cat_new.fit(X_train_cat, Y_train,epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cat_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model as image\n",
    "plot_model(model_cat_new, to_file='Images/model_cat_new.png')\n",
    "Image(\"Images/model_cat_new.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_con = Sequential()\n",
    "\n",
    "model_con.add(Dense(4,input_dim = 10,activation = 'relu')) \n",
    "\n",
    "model_con.add(Dense(40, activation = 'tanh' ))\n",
    "model_con.add(Dense(40, activation = 'relu' ))\n",
    "model_con.add(Dense(3, activation = 'softmax' ))\n",
    "\n",
    "model_con.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL8AAAHBCAYAAAA4tWoDAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_con, to_file='Images/model_con.png')\n",
    "Image(\"Images/model_con.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 4)                 44        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 40)                200       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 123       \n",
      "=================================================================\n",
      "Total params: 2,007\n",
      "Trainable params: 2,007\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_con.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21042/21042 [==============================] - 1s 35us/step - loss: nan - mean_squared_error: nan - acc: 0.7424\n",
      "Epoch 2/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 3/20\n",
      "21042/21042 [==============================] - 0s 13us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 4/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 5/20\n",
      "21042/21042 [==============================] - 0s 13us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 6/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 7/20\n",
      "21042/21042 [==============================] - 0s 16us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 8/20\n",
      "21042/21042 [==============================] - 0s 15us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 9/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 10/20\n",
      "21042/21042 [==============================] - 0s 16us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 11/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 12/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 13/20\n",
      "21042/21042 [==============================] - 0s 17us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 14/20\n",
      "21042/21042 [==============================] - 0s 15us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 15/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 16/20\n",
      "21042/21042 [==============================] - 0s 14us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 17/20\n",
      "21042/21042 [==============================] - 0s 16us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 18/20\n",
      "21042/21042 [==============================] - 0s 15us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 19/20\n",
      "21042/21042 [==============================] - 0s 16us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 20/20\n",
      "21042/21042 [==============================] - 0s 16us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185a002710>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_con.fit(X_train_con, Y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get test_set from Nic\n",
    "#score_con = model_con.evaluate(X_test_con, Y_test, batch_size=128)\n",
    "#score_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(10,), name='Categorial_input') \n",
    "con_input = Input(shape=(10,), name='Continous_input')\n",
    "\n",
    "#lstm_input = ??\n",
    "\n",
    "x = keras.layers.concatenate([cat_input, con_input])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(3, activation='softmax', name='main_output')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_total = Model(inputs=[cat_input, con_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Categorial_input (InputLayer)   (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Continous_input (InputLayer)    (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 20)           0           Categorial_input[0][0]           \n",
      "                                                                 Continous_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 64)           1344        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 64)           4160        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 64)           4160        dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 3)            195         dense_53[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,859\n",
      "Trainable params: 9,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_total.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAIjCAYAAADLIIbOAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE\nQVR4nOzde1hU5d4+8HsxMyAkaGJqiuKhXV6a2/QtX43C2FZbKkwNEQ0PISnla2LptuywM9t28Lgl\nythpClkOhpoWkuU2tRTN3u0hUBM1RfOsiKLCMPP9/eGPeUGGgYGHWYPen+vi0lmHZ33XmrXmnrWe\nNTOaiAiIiIgU8NK7ACIiunEwVIiISBmGChERKcNQISIiZYzXD9iyZQtmz56tRy1EbvXiiy+iV69e\nddL2oEGD6qRdIk/Sq1cvvPjii+WGVThTycvLw5dffum2ooj08OWXXyIvL69O2z969GidtU+kt6ys\nLGzZsqXC8ApnKqWWLVtWpwUR6UnTtDpfxoQJExAVFVXnyyHSQ2Vn4+xTISIiZRgqRESkDEOFiIiU\nYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKG\noUJERMowVIiISBmGChERKcNQISIiZZSFynfffYfQ0FCMHz8eM2bMwODBg9GzZ08kJCSoWoQyDz30\nEN59912n02zevBlt2rTBpEmTlLXpLmvXrkX37t2haRoSEhLc9rO26enpuP322+Hl5YXExERcvXrV\nLcu9UbjzGPKk/bWUJ9XEY6gW5Dpms1kcDHbq448/lsDAQNm9e3e54VOnTpXY2Ngq59+1a5fk5ua6\ntMzaOHfunBQXF1c5XUxMjEycOFFpm7XhynaaMWOGAJCLFy+6taYhQ4bInXfeWafLVAGAmM1mj2m/\ntsdQVa5/ntyxv7qKx9A19eUYioyMlMjIyArDa32mcurUKUyaNAkvvPAC7r777nLjJk+ejICAAKfz\n5+fnIzo6GoWFhbUtpdpuvfVWmEymKqczGAzV/i3z6rZZU65up1tuuaXcv+6qyc/PD76+vnW2zBtR\nbY+hqjh6nup6f60JHkPX1PdjqNahsmLFChQUFCAyMrLCOB8fH0ybNg0AMGvWLJjNZjz33HN4/fXX\n7dMsXrwYOTk5mDt3LlavXo3MzEyMGTMGoaGhSExMLNfevn378NZbb2HatGkICQnB+PHj8dVXXwEA\ntm3bhnHjxuHNN99EREQEduzYAQBYvnw5+vTpgyVLlqBz587o27cvnnnmmXI1VFZbde3evbtcm+np\n6QgJCUFqaiqioqLQpEkTLF26FADw+eef4/7778cHH3yA3r17w8/PD3//+98BAKmpqWjevDl+++03\nHD16FNHR0ejdu7fD7QQA/fr1wzvvvFOtGt1VU3U42t4pKSn405/+hLfeegslJSUoKChAdHQ0MjMz\nAcDhfnH9c1vdS5WeprrHEFD5fu7s+b3+eSq7vzqbz9nynO0XwLXneNGiRYiIiMDKlSur3AY8hqp/\nDKk6foA6OoauP3Vx9fLX+PHjBYBcunSp0mny8vKkUaNGIiJy+fJlMZlM9tPckpISASA5OTmSm5sr\n8fHxIiKSn58vPj4+kp2dbW/niSeekB07doiIyOOPPy4vvPCCXL58WY4fPy7t27e3n6aazWYJDAyU\ns2fPyokTJ8RgMMj48eNlx44dsmnTJhkwYIBMmDChytpGjBghkyZNqtZ2KNtmUVGRBAYGSkJCglgs\nFpk9e7Z06dLFvgyj0ShvvPGGWCwW+eijj0TTNDlx4oR9W5Suc0pKinTu3LnCdiq1YMEC2bBhg8N6\nPvzwQwEgNpvNrTWNGjVKunbtWul2cra977nnHnnnnXfs0z7//PMiIpXuF46e2+qCB13+qs4xJCJO\n93Nnz6+j56l0f3U2n7PlOdsv9u/fL4MGDRKRa89XampqtbYDj6FrnB1DKo8fEanVMVRnl78sFgs0\nTYOXV+VNtWrVChs2bAAAbNmyBVarFXl5eRWmS05OxoULFzB9+nQkJSWhZ8+eyMrKAgDYbDasW7cO\nFy9eBAD06tULBQUF8PX1xaeffoo777wTDRs2BAA88cQTyM/Ph9lsRvPmzdG0aVNERESga9eueOCB\nB9CkSROXa6tK2Ta9vb3h7++PkJAQGI1G9OjRw96mr68vfH198cgjj8BoNCI+Ph7NmjXDt99+C4PB\nUK5No9HodJmxsbEIDQ2tVn3uqqkqzrb3uHHj8PHHH8Nms+HEiRNo06YNgMr3C0fPbX1UnWMIgNP9\n3Nnz60jp/upsPmfLc7ZfBAQEYPXq1Zg3bx78/f0xcODAam0HHkNVU3n8AKiTY6jWoXLXXXdBRHDo\n0KFKp9E0DQUFBXjllVcQHBwMTdNgtVorTJObm4tHH30UU6ZMwZQpU/DDDz8gNjb2WqFeXggNDcWX\nX34JADh8+DBiYmIAAIcOHSp3QPr5+aFLly74/fff7fNW9kRWp7baMhgMEJFKx/fq1Qt79+6tVlvV\n7ePx1Jqcbe8hQ4agoKAAmZmZWLlyJaKiogCgyv2itkGnt+ocQ0DV+3lZjp7f6jxPZedzZXllNWvW\nDMnJyZg8eTLCwsJw5cqVKpfrSl2O3CzHkOrjB1B/DNU6VPr16wcfHx988cUXlU6TnZ2NUaNGYdq0\naejQoYPDaTRNQ9euXbF58+Zyww8cOGD//+eff46dO3ciOTkZ8fHx6NOnD4Br6b1t27Zy85lMJrRq\n1arK+qtTW13Lzc3FnXfeWa1pVR0QVVFd0/Hjx7Fz506n29vX1xejRo3Chx9+iLy8PLRr1w4Aqtwv\n6rvqHENA7fZzwPV9p6bLO3XqFGJiYvDLL7/g/PnzGDdunEvLrYmb5Rj6/PPPPf74qXWotG3bFi+/\n/DLmzp1rP6UqdfjwYXz88cfYuHEjLl68CBHB3r17YbVaYbFYAFxLex8fH5w7dw5hYWFISUnB/Pnz\nYbFY8NNPP2HXrl329l577TWYzWaMHj0a3bt3tw+Pjo5Gfn4+fv31VwDXLifs378fTz31FIBrl85K\nlwcARUVFKC4uBgCntVmt1mqftZRts3Te0ncxxcXFsNls5aYvvdvj7NmzOHHihL2Ttk2bNsjJyQEA\n7Nmzx365r+x2Kr13PSMjw95xer1Lly6V+9ddNRUWFlZ492az2TB+/Hi0bNnS6fYGgOeffx5r165F\ny5Yt7cPCw8Mr3S+uf27ro+ocQ0DV+3llz6+j56ns/lrZfFUtr7L9YseOHdi6dSs6deqEhQsX4ty5\nc9XaDjyGqj6GcnNzlR4/pW0rPYau72SpyedURK51eLVu3VpGjBghb7/9tkyaNElmzJghJSUlcujQ\nIWnZsqXce++98vHHH0uvXr3k0UcflTNnzoiIyHPPPSfBwcFiNpslLi5ONE2T4OBgmTJlir2TTETk\nwQcfFE3TpFGjRtK6dWsZNmyYXLhwQUREUlNTJTQ0VDIyMiQmJkbS09NFROSzzz4TADJo0CD5/fff\nJSsrSzp06CB33323/Prrr5XW9s0330hwcLB069atXCeaI9e3uW7dOtE0TYYNGyanT5+WuLg4ASCr\nVq0SERF/f38ZMmSIfPDBB/LUU0+V6yh8//33pUGDBhIRESFz586VTp06yZo1a8ptp7S0NBER6d27\nt71js6y1a9dKt27dBIAkJCRIXl6eW2pKT0+XFi1aiI+Pj8TFxUl8fLwMHTpU7rjjDvnzn/8sIlLl\nviAi0rdvXzl+/Lj9sc1mc7hfXP/cugIe1FFfytkxVKqy/byq57fs81R2f503b57T+Spbnkjl+8Xa\ntWslLCxMMjMzZebMmbJ+/foq153HUPWOIZXHj0jF10dXVNZRryxUSh09etRhcRaLxX5wlJSUlAsL\nESl358v58+elqKiowvi3335bjh8/Ljt37pQff/xR5syZU+7OkqtXr8qePXsqzFuVqmpTzd/fXzZt\n2iQnT550uKzSu20sFkuFcWW309WrV5XVqqqm6qhqe5fetXI9R/tFTXliqJSq7BgqVdP93NXnqTrL\nc7RfWK1WERE5ffp0jZZXHTfzMeQJx49I5aGivIezsuutZTuCrr8bAij/AaPGjRtXGP/+++/jjz/+\nQIsWLdCiRQuICA4ePIhu3brZp/Hx8UHHjh1drrmq2gCgf//+DodrmoYVK1a4tDwRgc1mQ7NmzRyO\nL73bxlHnWdnt5OPj49Jy3VFTdTja3kePHsVvv/2GnJwcDBgwwOF8jvaLG1FVfRY13c9r+iE+Z8tz\ntF+Udu43bdq03LQ8htQcQ55+/NSb22ZGjx6NZ599Fn/+859xzz33oGXLloiMjETnzp3dsvzqfICr\nOsxmMy5duoQlS5agQ4cO1e5krUueUNOqVavw8ssvY9KkSXj44YfdvnyqezyG6o4nHT+aSPkeobS0\nNAwePNjprXJ6stlsVd7P78nKdsL5+Ph4xFdleEpN7nxuNU2D2Wy233ZZ39q/mXnK/lqWJ9Tk7tfG\nQYMGAQCWLVtWbni9OVMpVZ8DBajb7xGqKU+pqb4/t+QenrK/luUJNXnK8eMZVRAR0Q2BoUJERMow\nVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQ\nISIiZSr9luLSrzWmG4fVasXly5fh7++vdyk3hTlz5lT4WvCbzcWLF+Hn51fpj99R/ZWVlYWePXtW\nGF7hTKV169aIjIx0S1HkXvv27cP69etx9uxZvUvRXWRkJFq3bl2n7QcFBdVZ+/XB2bNnsX79euzb\nt0/vUqgO9OzZE7169aowvMKPdNGNq6ioCEOHDkVmZiaWL1+Ov/71r3qXRDeodevWoX///ggLC4PZ\nbIavr6/eJZGbsE/lJuLj44O0tDRERUWhX79++PLLL/UuiW5AX3zxBcLDw9G/f38sX76cgXKTYajc\nZAwGAxYuXIjnn38e0dHRWLBggd4l0Q3ko48+QkxMDOLj47F48WIYjfXux2WplviM34Q0TcOcOXPQ\nokULPPvss8jPz8dLL72kd1lUz7333nt4+eWXMXnyZLz77rt6l0M6YajcxCZPngxfX18kJCTg9OnT\nfCGgGhERTJo0CXPnzsX8+fMxZswYvUsiHTFUbnIvvPACGjdujFGjRuHSpUuYN28evLx4VZSqx2q1\nYvTo0fjss8/w+eefIyoqSu+SSGcMFcLw4cMREBCA6OhoXLhwAZ9++imvhVOVSu8m/Pbbb/HVV1+h\nb9++epdEHoC3FJNdRkYGBg0ahIcffhhmsxkNGjTQuyTyUBcuXEBERAR+/fVXfP3117j//vv1Lok8\nBEOFytm0aRMiIiLQvXt3fPXVV/z0PVVw8uRJhIeH48SJE8jMzMSf//xnvUsiD8JQoQr+93//F337\n9kXbtm2xZs0aBAYG6l0SeYjDhw/j0UcfRUlJCdauXYsOHTroXRJ5GPbIUgXdu3fHxo0bceLECYSG\nhuKPP/7QuyTyAHv27MEDDzwAb29vbNq0iYFCDjFUyKGOHTti06ZNKCkpwQMPPIADBw7oXRLp6Oef\nf0ZoaCjat2+PH3/8ES1bttS7JPJQDBWqVHBwMDZu3IhGjRrhwQcfxO7du/UuiXTw73//G3369EHP\nnj2RmZmJRo0a6V0SeTCGCjnVvHlzrF+/Hu3bt8dDDz2ErVu36l0SudHKlSvx+OOPo1+/fvweL6oW\nhgpVqXHjxli7di3uu+8+PPzww1i3bp3eJZEbLFq0CIMGDUJcXBxSUlJgMpn0LonqAYYKVYufnx9W\nrVqFvn374vHHH8fKlSv1Lonq0HvvvYfY2Fi89NJLSExM5LcsULVxT6Fq8/b2xtKlSxETE4NBgwZh\n8eLFepdEiokI/va3v+GVV17B7Nmz+X1w5DJ+Fwe5xGAw4F//+hcaN26M2NhYFBUVYfTo0XqXRQpY\nrVaMGTMGqamp+PzzzxEdHa13SVQPMVTIZZqmYebMmbjtttsQHx+P/Px8/O1vf9O7LKqFoqIiPP30\n01izZg1WrlyJ8PBwvUuieoqhQjU2efJkNGzYEC+88ALOnTvHSyX11KVLlzBgwABs374da9euRUhI\niN4lUT3GUKFaGTt2LBo1aoRnnnkGFy5cQFJSEjt165Fz587hsccew+HDh/HDDz+ga9euepdE9RxD\nhWotJiYGjRo1QlRUFC5cuIDFixfz9tN64PDhw/jrX/+K4uJibNq0CXfccYfeJdENgG8pSYmIiAhk\nZGTg66+/xoABA3DlyhW9SyIn9uzZgwcffBBGo5GBQkoxVEiZsLAwrFu3DllZWejbty8KCgr0Lokc\n2L59O3r37o2WLVtiw4YNaNWqld4l0Q2EoUJK3Xfffdi4cSNyc3Pxl7/8BadPn9a7JCpj/fr16NOn\nD3r06IF///vf/FkDUo6hQsp16tQJP/74I/Lz89G7d28cPXpU75IIwFdffYXHHnsMTzzxBFasWAE/\nPz+9S6IbEEOF6kS7du2wadMmGI1GPPDAA9i/f7/eJd3UUlJSEBkZidjYWKSmpvJGCqozDBWqM7ff\nfjt++OEHtGjRAqGhodi5c6feJd2U/vnPf2LkyJF46aWXeMs31TnuXVSnmjRpgu+//x6dO3dGWFgY\ntmzZondJNw0RweTJkzFhwgTMnDmTH04lt+Bv1JNbFBUVITo6Gt999x2WL1+ORx99VO+SbmhWqxXP\nPfccPv30UyQnJ+OZZ57RuyS6SfBMhdzCx8cHy5YtQ2RkJCIiIpCenq53STes4uJiREdHY8mSJfjq\nq68YKORW/EQ9uY3RaMSnn36KRo0aYfDgwUhOTkZsbKzeZd1QCgsLMXDgQGzbtg3ffvstHnjgAb1L\nopsMQ4XcStM0zJ07Fw0aNEBcXBwuXLiACRMm6F3WDeHcuXN4/PHHcejQIaxfvx733HOP3iXRTYih\nQm6naRree+89NGnSBC+99BJOnjzJTuRa+uOPP9C3b19cvHgRmzZtwp/+9Ce9S6KbFEOFdDN58mQ0\natQIY8eORWFhIf75z386vN11//79uOOOO6Bpmg5VeoYjR46gTZs2Dsft3bsXf/3rX9GwYUP8+OOP\n/NoV0hU76klX8fHxWLJkCT7++GOMHDkSJSUl5cbv378fISEhN3XHfnFxMUJDQ/Hhhx9WGPfLL78g\nNDQULVq0wMaNGxkopD8h8gBff/21+Pr6ypNPPilXrlwREZG8vDxp2bKlaJomd9xxh5SUlOhcpT7m\nzZsnmqaJpmny+eef24f/8MMPEhAQIH369JGCggIdKyT6P/ycCnmMjRs3IiIiAvfeey8WLlyIhx9+\nGIcPH4bFYoGXlxcWLlyIESNG6F2mW126dAnBwcE4d+4cAMBgMGDVqlWwWq0YPHgw+vbtiy+++AI+\nPj46V0p0DUOFPMr27dvRt29fAEBBQQEsFguAa537t99+Ow4ePHhTvYBOnToVb7/9tv2yoKZpMBqN\nsNlsGDNmDBITE/m1K+RRuDeSR+ncuTPatGmDCxcu2AMFuPaVIydPnsQnn3yiY3XudebMGbz//vvl\n+plEBDabDd7e3oiLi2OgkMfhHkkew2KxYODAgdi9e3eFDnvg2lePvPnmm7h8+bIO1bnf9OnTywVr\nKavVCovFgocffhi//fabDpURVY6hQh7BZrPh6aefxvfff+8wUEqdP38eiYmJbqxMH0eOHMEHH3zg\nMFQAoKSkBAUFBXj44Ydx/PhxN1dHVDmGCnmEf/zjH1i2bBlsNpvT6axWK6ZPn44LFy64qTJ9vPHG\nG1VOU1JSgry8PDz22GMoKipyQ1VEVWOokEd49dVXsWrVKoSGhgKA0x+Runz5MmbNmuWu0txuz549\nSE1NrfQsRdM0GAwG+Pn5ISEhAV9++eVNdfMCeTbe/UUe5z//+Q9mzZqFpUuXwsvLy+GLq6+vLw4d\nOoTmzZvrUGHdevLJJ7FmzZoK6200GlFSUoLWrVtj7NixGDNmDBo3bqxTlUSOMVTIY504cQLz58/H\n3LlzcenSJdhsNpTuriaTCWPHjsWcOXN0rlKtbdu2oWfPnih7WHp7e6O4uBj//d//jZdeegkDBw6E\nwWDQsUqiyjFUyOMVFhYiJSUFM2fOxMGDB+3v2E0mEw4cOIDWrVvrXaIyoaGh+Omnn2Cz2WAwGGA0\nGjFixAiMHz8enTp10rs8oioxVOq5tLQ0vUtwGxHBf/7zH6xevRo5OTkAgLCwMMTHx+tcmRq7du3C\nP/7xDwBA48aN8fjjj+Mvf/kLGjZsqHNl7hMVFaV3CVRLDJV67mb+5l668fDlqP7j3V83ALPZDBG5\nKf9OnDiBrVu36l5Hbf+OHTuG7du3616HXn9ms1nvw4gU4e+pUL3WvHnzG+IOsJYtW6Jly5Z6l0FU\nazxTISIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQISIiZRgqRESk\nDEOFiIiUYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQIarE1atX0bFjR+zatcul+b777juE\nhoZi/PjxmDFjBgYPHoyePXsiISGhjiol8hz85Udyu927d8PPzw8dOnTw6LY//PBDHDt2zKV5kpOT\nMWXKFPzwww+4++677cPfeustHD58uNY1uaq+bGu6cfBMhdwqPz8f0dHRKCws9Oi2t27dig4dOqBB\ngwbVnufUqVOYNGkSXnjhhXKBAgCTJ09GQEBAretyRX3Z1nRjYajcZP7zn/8gNjYW7733Hp588knk\n5+fbx23btg3jxo3Dm2++iYiICOzYsQMAkJ6ejpCQEKSmpiIqKgpNmjTB0qVLq2xz1qxZMJvNeO65\n5/D6668DABYvXoycnBzMnTsXq1evBgBkZmZizJgxCA0NRWJiYrWWWZu2q1JUVISMjAw8+eSTFcb1\n69cP77zzjsP5VqxYgYKCAkRGRlYY5+Pjg2nTprltOzvaHpVtCz23Nd2AhOo1AGI2m6s17ZkzZ6RH\njx5itVpFRCQ8PFxmzJghIiLHjx+X9u3by8WLF0VExGw2S2BgoJw9e1aKiookMDBQEhISxGKxyOzZ\ns6VLly5O28zLy5NGjRqJiMjly5fFZDJJcXGxlJSUCADJyckREZHc3FyJj48XEZH8/Hzx8fGR7Oxs\np8usbdtVef/99+XkyZMiItK0aVPZuXOnfdyCBQtkw4YNDucbP368AJBLly5V2ra7trOIlNsezraF\nntu6lNlsFr4c3Rh4pnIT+eSTT9CjRw94eV172tPS0vDCCy8AAD799FPceeedaNiwIQDgiSeeQH5+\nPsxmM7y9veHv74+QkBAYjUb06NEDeXl5Ttts1aoVNmzYAADYsmULrFarfZ6ykpOTceHCBUyfPh1J\nSUno2bMnsrKynC6ztm078/PPPyMoKAjNmjVzOD42NhahoaEOx1ksFmiaZt8Wjnjadgag27amGxM7\n6m8iOTk5CAoKsj8ufWEDgEOHDpV7MfTz80OXLl3w+++/V2jHYDBARKpss6CgAK+88gri4uKgaRqs\nVqt9nKZpAIDc3FxERERg5MiRAIApU6Y4rL3sMjVNU9p2WW+++Sa6du2K3bt3AwAKCwsxb948PPbY\nYxg4cKDTee+66y6ICA4dOoROnTo5nMbd2xm4tj1c2Rbu2tZ0Y+KZyk2kcePGyMjIKDfs+PHjAK69\nI922bVu5cSaTCa1atapRm9nZ2Rg1ahSmTZvm8O6g0hejrl27YvPmzeXGHThwwOky67Lt/v37IyAg\nwP5nMBhwyy23wNfX1+l8wLX+Fh8fH3zxxReVTuPu7Qxc2x412RZA3W5rujExVG4ijz/+OHbs2IF/\n/etfuHr1KpYvX25/Rx4dHY38/Hz8+uuvAK5dytm/fz+eeuopAIDVarW/ey0uLobNZnPa5saNG3Hx\n4kWICPbu3Qur1QqLxQKDwQAfHx+cO3cOV69eRXh4OFJSUjB//nxYLBb89NNP9s+FVLZMFW1X5tln\nn8XLL79s/2vYsCFGjRqF8PBwAEBGRoa9Y/16bdu2xcsvv4y5c+dWuPRz+PBhfPzxx27bzgDKbY+w\nsDCn20KPbU03KF16ckgZuNBRLyLyxhtviMlkEh8fH5kyZUq5campqRIaGioZGRkSExMj6enpIiKy\nbt060TRNhg0bJqdPn5a4uDgBIKtWraq0zUOHDknLli3l3nvvlY8//lh69eoljz76qJw5c0aee+45\nCQ4OlrS0NLHZbBIXFyeapklwcLBMmTJFbDab02XWtm1XtGjRolxHfe/evWXChAlO51mwYIG0bt1a\nRowYIW+//bZMmjRJZsyYISUlJW7dziJi3x5ms7nSbeEJ25od9TcOTeT/vz2heknTNJjNZkRFRVV7\nnqtXr8Jms8HPz6/CuKKiIhw6dAjt27eHt7d3rdosKSmBpmkwGAywWq3w8vKyXy4pLCzELbfcYp82\nPz8ffn5+1V5mXbbtTFFREby9ve3LcubYsWMoKSlBcHCww3bcsZ2B8tujJtvCHds6LS0NgwcPBl+O\n6j921N+EnH2gz8fHBx07dlTSptH4f7uXwWAoN67sCxFwrc/AFbVpu3///g7b1DQNK1ascLpcHx+f\natforJ/EXdsZKL89XN3OVbVf2+eRbjwMFbrprFy5Uu8SiG5Y7KgnIiJlGCpERKQMQ4WIiJRhqBAR\nkTIMFSIiUoahQkREyjBUiIhIGYYKEREpw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIMFSIiUoahQkRE\nyjBUiIhIGf6eyg1gy5YtepdAVCvch28c/Dnheq46P2tLVF/w5aj+45lKPceDsO5FRUUBuPY76kTk\nHPtUiIhIGYYKEREpw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIMFSIiUoahQkREyjBUiIhIGYYKEREp\nw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIMFSIiUoahQkREyjBUiIhIGYYKEREpw1AhIiJlGCpERKQM\nQ4WIiJRhqBARkTIMFSIiUoahQkREyjBUiIhIGYYKEREpw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIM\nFSIiUoahQkREyjBUiIhIGaPeBRB5kg0bNiArK6vcsL179wIA3nvvvXLDe5xLeVIAACAASURBVPbs\nid69e7utNqL6QBMR0bsIIk/x3Xff4dFHH4XJZIKXl+MTeZvNBovFgrVr1+KRRx5xc4VEno2hQlSG\n1WpF8+bNcfbsWafT3XrrrTh16hSMRp7sE5XFPhWiMgwGA55++ml4e3tXOo23tzeGDRvGQCFygKFC\ndJ0hQ4aguLi40vHFxcUYMmSIGysiqj94+YvIgeDgYBw5csThuKCgIBw5cgSaprm5KiLPxzMVIgdi\nYmJgMpkqDPf29saIESMYKESV4JkKkQN79uxBp06dHI7bvXs37r77bjdXRFQ/MFSIKtGpUyfs2bOn\n3LCOHTtWGEZE/4eXv4gqMXz48HKXwEwmE0aMGKFjRUSej2cqRJU4cuQI2rZti9JDRNM0HDx4EG3b\nttW3MCIPxjMVokq0adMG9957L7y8vKBpGu677z4GClEVGCpETgwfPhxeXl4wGAwYNmyY3uUQeTxe\n/iJy4vTp07j99tsBAMeOHUPz5s11rojIs/FMhWokLS0Nmqbd8H/NmjWD1WqF1WpFixYtdK/HHX9p\naWl6715Uj/HLi6hWzGaz3iXUuQ0bNkDTNISGhupdSp0bPHiw3iVQPcdQoVqJiorSu4Q617dvXwBA\nQECAzpXUPYYK1RZDhagKN0OYEKnCPhUiIlKGoUJERMowVIiISBmGChERKcNQISIiZRgqRESkDEOF\niIiUYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiUYagQEZEyDBVy\nu0uXLmHcuHFo3ry53qWU06NHD/vvtHfr1q3cuK+//hpdu3bF7t27q9XWmjVr0KFDBxgMBowbNw6T\nJk3CxIkT8dZbb+G3336ri/KJPAJDhdyuYcOGiIyMhNHoOT88mpWVhWHDhmHfvn3Yt28fvv/+e/u4\n48ePo2XLlti1a1e12wsPD0d4eDiCgoKQmJiIGTNm4P3330dgYCBCQkKwffv2ulgNIt15zlFNNw2b\nzQYvLy9omqZ3KXaJiYm4++67cfnyZdxzzz3lxt1+++247bbbXG7T19e33Dp6eXlh7NixyM7ORp8+\nfZCXl8efKqYbDs9UyG1+/vlnJCQkYO7cufjggw/KveBmZmZizJgxCA0NRWJiIgAgPT0dISEhSE1N\nRVRUFJo0aYKlS5fa55k1axYWLVqEiIgIrFy50mlbzhQXFyM3NxevvfYaunXrhri4OBQVFVVrnfr1\n64d33nmnupsAABAfH4+CggJs3brVab01WX9X151IOSGqAbPZLK7sPvn5+dKuXTspKioSEZF3331X\ngoKCREQkNzdX4uPj7dP5+PhIdna2FBUVSWBgoCQkJIjFYpHZs2dLly5dRERk//79MmjQIPs8qamp\nTtuqbo1vvPGGaJomU6dOLTfOYrEIANm1a1e54QsWLJANGzY4bG/ixIkSHBxcYfjVq1fFYDDI1KlT\nndbr6vrXZt1LARCz2ezSPERl8UyF3GLRokW466674O3tDQDo1auX/UwlOTkZFy5cwPTp05GUlISe\nPXsiKysL3t7e8Pf3R0hICIxGI3r06IG8vDwAQEBAAFavXo158+bB398fAwcOdNpWdTRq1AhTp07F\n9OnTkZKSUq15YmNjERoa6tK2sNls9n+d1evq+tdm3YlUYZ8KuUV2djZatWplf1x6lxUA5ObmIiIi\nAiNHjgQATJkyxWEbBoMBIgIAaNasGZKTkzF69Gikp6dj+fLl8PPzq3ZbzkRFRWHatGkuz1ddOTk5\nsFqt6N69OxYvXlzteqtafxXrTlRbPFMht2jXrl2l75q7du2KzZs3lxt24MABp+2dOnUKMTEx+OWX\nX3D+/HmMGzeuxm1dz2KxoHPnzi7N44olS5agXbt2CAsLq3G9jtZfxboT1RZDhdxiwIAByMnJwc6d\nOwEAx44dQ2FhIUQE4eHhSElJwfz582GxWPDTTz/Zb9+1Wq32d+fFxcX2S0c7duzA1q1b0alTJyxc\nuBDnzp0DAKdtVebYsWPIzc21P162bBleffXVctOUlJQ4nDcjIwM7duxwOK50/UpduXIFSUlJSEpK\nwtKlS+Hv719lva6sf03WnUg5PTt0qP5ytaNeROTFF1+UJk2ayMCBA2XUqFHSvn17+eSTT8Rms0lc\nXJxomibBwcEyZcoUsdlssm7dOtE0TYYNGyanT5+WuLg4ASCrVq2StWvXSlhYmGRmZsrMmTNl/fr1\nIiKVtuXMN998I0ajUYYOHSqTJ0+Wzz77rNz4kydPytSpUwWATJgwQQ4fPmwf17t3b5kwYUKFNjMy\nMqRt27aiaZo8++yz0r9/fwkNDZXY2FjJycmxT+esXlfXvybrfj2wo55qSRMp81aKqJrS0tIwePBg\nuLr7FBYWwmQyQdM0GI3GcrcV5+fnw8/Pz96Z70zpZ13OnDmDpk2bVhjvSlul0xcVFbn8Kf+ioiJ4\ne3vX+jM3rtbrbP1dbassTdNgNpsRFRXl8rxEADvqyc1uueWWSsc1bty42u14eV27cusoUBy11b9/\nf4fTaZqGFStWuLTssnx8fGo03/VcXb6z9a/puhCpwFChm0LZD0cSUd1hRz0RESnDUCEiImUYKkRE\npAxDhYiIlGGoEBGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGR\nMgwVIiJShqFCRETK8PdUqFZq+4uHRHRj4c8JU40cPXoUmzdv1rsMt5gzZw4AYMKECTpX4h73338/\ngoKC9C6D6imGClEVSn+vPS0tTedKiDwf+1SIiEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGR\nMgwVIiJShqFCRETKMFSIiEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGRMgwVIiJShqFCRETK\nMFSIiEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnD\nUCEiImUYKkREpAxDhYiIlGGoEBGRMgwVIiJShqFCRETKGPUugMiTnDlzBgUFBeWGFRYWAgAOHjxY\nbnhAQACaNm3qttqI6gNNRETvIog8xYIFCxAXF1etaT/55BOMGjWqjisiql8YKkRlnD9/Hs2bN4fF\nYnE6nclkwsmTJ3Hrrbe6qTKi+oF9KkRl3Hrrrejbty+MxsqvDBuNRoSHhzNQiBxgqBBdJyYmBlar\ntdLxVqsVMTExbqyIqP7g5S+i61y9ehWBgYG4fPmyw/G+vr44c+YM/Pz83FwZkefjmQrRdRo0aIAB\nAwbAZDJVGGcymfDUU08xUIgqwVAhcmDo0KEOO+stFguGDh2qQ0VE9QMvfxE5UFJSgmbNmuH8+fPl\nhjdu3BinTp1yeBZDRDxTIXLIaDQiOjoa3t7e9mEmkwlDhw5loBA5wVAhqsSQIUNQXFxsf2yxWDBk\nyBAdKyLyfLz8RVQJEUFQUBD++OMPAECLFi3wxx9/QNM0nSsj8lw8UyGqhKZpiImJgbe3N0wmE4YP\nH85AIaoCQ4XIidJLYLzri6h6+C3FVCNbtmzB7Nmz9S7DLRo2bAgAePvtt3WuxD1efPFF9OrVS+8y\nqJ7imQrVSF5eHr788ku9y3CL4OBgBAcH612GW3z55ZfIy8vTuwyqx3imQrWybNkyvUuocwcOHAAA\ndOjQQedK6h77jKi2GCpEVbgZwoRIFV7+IiIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKGoUJERMow\nVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQ\nIbe7dOkSxo0bh+bNm+tdSjk9evSApmnQNA3dunWzD09JSUHnzp1hMpnwxBNP4ODBg1W2tWbNGnTo\n0AEGgwHjxo3DpEmTMHHiRLz11lv47bff6nI1iHTFUCG3a9iwISIjI2E0es4Pj2ZlZWHYsGHYt28f\n9u3bh++//x4AsH//fmzbtg3r16/Hrl27sH//fsybN6/K9sLDwxEeHo6goCAkJiZixowZeP/99xEY\nGIiQkBBs3769rleJSBeec1TTTcNms8HLy8ujfg89MTERd999Ny5fvox77rnHPnz//v2YM2cOTCYT\nmjVrhuHDh2PJkiXVatPX17fcOnp5eWHs2LHIzs5Gnz59kJeXh4CAAOXrQqQnnqmQ2/z8889ISEjA\n3Llz8cEHH5R7wc3MzMSYMWMQGhqKxMREAEB6ejpCQkKQmpqKqKgoNGnSBEuXLrXPM2vWLCxatAgR\nERFYuXKl07acKS4uRm5uLl577TV069YNcXFxKCoqAgA89thjMJlM9mnbtGmDsLAw++N+/frhnXfe\ncWk7xMfHo6CgAFu3bnVab03W39V1J1JOiGrAbDaLK7tPfn6+tGvXToqKikRE5N1335WgoCAREcnN\nzZX4+Hj7dD4+PpKdnS1FRUUSGBgoCQkJYrFYZPbs2dKlSxcREdm/f78MGjTIPk9qaqrTtqpb4xtv\nvCGapsnUqVMdThMXFycbNmywP16wYEG5x2VNnDhRgoODKwy/evWqGAwGmTp1qtN6XV3/2qx7KQBi\nNptdmoeoLJ6pkFssWrQId911F7y9vQEAvXr1sp+pJCcn48KFC5g+fTqSkpLQs2dPZGVlwdvbG/7+\n/ggJCYHRaESPHj2Ql5cHAAgICMDq1asxb948+Pv7Y+DAgU7bqo5GjRph6tSpmD59OlJSUiqMP3jw\nIIxGI0JDQ+3DYmNjyz2uDpvNZv/XWb2urn9t1p1IFfapkFtkZ2ejVatW9seld1kBQG5uLiIiIjBy\n5EgAwJQpUxy2YTAYICIAgGbNmiE5ORmjR49Geno6li9fDj8/v2q35UxUVBSmTZtWblhxcTFmz56N\nOXPmuNze9XJycmC1WtG9e3csXry42vVWtf4q1p2otnimQm7Rrl27St81d+3aFZs3by437MCBA07b\nO3XqFGJiYvDLL7/g/PnzGDduXI3bup7FYkHnzp3LDZszZw5ef/11NGjQAMC1kKmpJUuWoF27dggL\nC6txvY7WX8W6E9UWQ4XcYsCAAcjJycHOnTsBAMeOHUNhYSFEBOHh4UhJScH8+fNhsVjw008/Ydeu\nXQAAq9Vqf3deXFxsv3S0Y8cObN26FZ06dcLChQtx7tw5AHDaVmWOHTuG3Nxc++Nly5bh1VdftT/+\n6KOP0LFjR1y8eBG5ubn497//jeXLlwMAMjIysGPHDoftlq5fqStXriApKQlJSUlYunQp/P39q6zX\nlfWvyboTKadnhw7VX6521IuIvPjii9KkSRMZOHCgjBo1Stq3by+ffPKJ2Gw2iYuLE03TJDg4WKZM\nmSI2m03WrVsnmqbJsGHD5PTp0xIXFycAZNWqVbJ27VoJCwuTzMxMmTlzpqxfv15EpNK2nPnmm2/E\naDTK0KFDZfLkyfLZZ5+VG+fl5SUA7H8mk0lOnTolIiK9e/eWCRMmVGgzIyND2rZtK5qmybPPPiv9\n+/eX0NBQiY2NlZycHPt0zup1df1rsu7XAzvqqZY0kTJvpYiqKS0tDYMHD4aru09hYSFMJhM0TYPR\naCx3W3F+fj78/PzsnfnOlH7W5cyZM2jatGmF8a60VTp9UVGRy5/yLyoqgre3d60/c+Nqvc7W39W2\nytI0DWazGVFRUS7PSwSwo57c7JZbbql0XOPGjavdjpfXtSu3jgLFUVv9+/d3OJ2maVixYoVLyy7L\nx8enRvNdz9XlO1v/mq4LkQoMFboplP1wJBHVHXbUExGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnD\nUCEiImUYKkREpAxDhYiIlGGoEBGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnDUCEiImUYKkREpAx/\nT4VqZdCgQXqXQEQehGcqVCOtW7dGZGSk3mW4xfbt27F9+3a9y3CLyMhItG7dWu8yqB7jb9QTVaH0\n99rT0tJ0roTI8/FMhYiIlGGoEBGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnDUCEiImUYKkREpAxD\nhYiIlGGoEBGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGRMgwV\nIiJShqFCRETKMFSIiEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGRMgwVIiJShqFCRETKMFSI\niEgZhgoRESnDUCEiImUYKkREpAxDhYiIlNFERPQugshTLFq0CHPnzoXVarUPO336NADgtttusw8z\nGAxISEjAyJEj3V0ikUdjqBCVsW/fPnTs2LFa0+7Zs6fa0xLdLHj5i6iMu+66C126dIGmaZVOo2ka\nunTpwkAhcoChQnSd4cOHw2AwVDreaDRixIgRbqyIqP7g5S+i6/zxxx8ICgpCZYeGpmk4cuQIgoKC\n3FwZkefjmQrRdVq2bIn7778fXl4VDw8vLy/cf//9DBSiSjBUiBwYNmyYw34VTdMwfPhwHSoiqh94\n+YvIgXPnzqF58+YoKSkpN9xgMODkyZMIDAzUqTIiz8YzFSIHmjRpgkceeQRGo9E+zGAw4JFHHmGg\nEDnBUCGqRExMDGw2m/2xiGDYsGE6VkTk+Xj5i6gShYWFaNq0Ka5evQoA8PHxwZkzZ9CwYUOdKyPy\nXDxTIarELbfcgn79+sFkMsFoNKJ///4MFKIqMFSInHj66adRUlICq9WKoUOH6l0OkcczVj0JUUVH\njx7F5s2b9S6jzlmtVjRo0AAigkuXLiEtLU3vkuocP4dDtcE+FaqRtLQ0DB48WO8yqA6YzWZERUXp\nXQbVUzxToVq5Gd6TrF+/Hpqm4aGHHtK7lDrn7Is0iaqDoUJUhd69e+tdAlG9wVAhqoKj7wAjIsd4\ntBARkTIMFSIiUoahQkREyjBUiIhIGYYKEREpw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIMFSIiUoah\nQkREyjBUiIhIGYYKEREpw1AhIiJlGCpERKQMQ4Xc7tKlSxg3bhyaN2+udynl9OjRA5qmQdM0dOvW\nzT48PT0d/fr1Q+vWrfFf//VfOHfuXJVtrVmzBh06dIDBYMC4ceMwadIkTJw4EW+99RZ+++23ulwN\nIl0xVMjtGjZsiMjISBiNnvMbcVlZWRg2bBj27duHffv24fvvvwcAXLhwAd7e3li1ahUOHz6MwsJC\nLFmypMr2wsPDER4ejqCgICQmJmLGjBl4//33ERgYiJCQEGzfvr2uV4lIFwwVcjubzQYvLy+P+j30\nxMREXLp0CZcvX8add96JwMBAANd+9TEiIsL+/3vuuQcdOnSoVpu+vr7l1tHLywtjx47FoEGD0KdP\nHxQUFKhfESKdMVTIbX7++WckJCRg7ty5+OCDD8q94GZmZmLMmDEIDQ1FYmIigGuXnUJCQpCamoqo\nqCg0adIES5cutc8za9YsLFq0CBEREVi5cqXTtpwpLi5Gbm4uXnvtNXTr1g1xcXEoKioCAPj7+9un\nO3DgABo2bIi+ffvah/Xr1w/vvPOOS9shPj4eBQUF2Lp1q9N6a7L+rq47kXJCVANms1lc2X3y8/Ol\nXbt2UlRUJCIi7777rgQFBYmISG5ursTHx9un8/HxkezsbCkqKpLAwEBJSEgQi8Uis2fPli5duoiI\nyP79+2XQoEH2eVJTU522Vd0a33jjDdE0TaZOnVpu3Pz588XPz09uu+022bp1q334ggULZMOGDQ7b\nmzhxogQHB1cYfvXqVTEYDDJ16lSn9bq6/rVZ91IAxGw2uzQPUVk8UyG3WLRoEe666y54e3sDAHr1\n6mU/U0lOTsaFCxcwffp0JCUloWfPnsjKyoK3tzf8/f0REhICo9GIHj16IC8vDwAQEBCA1atXY968\nefD398fAgQOdtlUdjRo1wtSpUzF9+nSkpKSUGzdmzBjs27cPd911F2bOnGkfHhsbi9DQUJe2hc1m\ns//rrF5X1782606kiuf0lNINLTs7G61atbI/Lr3LCgByc3MRERGBkSNHAgCmTJnisA2DwQARAQA0\na9YMycnJGD16NNLT07F8+XL4+flVuy1noqKiMG3atArDg4KCMGfOHDz44IOwWq0wGAwutw0AOTk5\nsFqt6N69OxYvXlzteqtafxXrTlRbPFMht2jXrl2l75q7du2KzZs3lxt24MABp+2dOnUKMTEx+OWX\nX3D+/HmMGzeuxm1dz2KxoHPnzg7H3XHHHbj99ttrHCgAsGTJErRr1w5hYWE1rtfR+qtYd6LaYqiQ\nWwwYMAA5OTnYuXMnAODYsWMoLCyEiCA8PBwpKSmYP38+LBYLfvrpJ+zatQsAYLVa7e/Oi4uL7ZeO\nduzYga1bt6JTp05YuHCh/bMjztqqzLFjx5Cbm2t/vGzZMrz66qsArn2m5ujRo/Zxa9aswSuvvGJ/\nnJGRgR07djhst3T9Sl25cgVJSUlISkrC0qVL4e/vX2W9rqx/TdadSDk9O3So/nK1o15E5MUXX5Qm\nTZrIwIEDZdSoUdK+fXv55JNPxGazSVxcnGiaJsHBwTJlyhSx2Wyybt060TRNhg0bJqdPn5a4uDgB\nIKtWrZK1a9dKWFiYZGZmysyZM2X9+vUiIpW25cw333wjRqNRhg4dKpMnT5bPPvvMPm7z5s0SEBAg\nAwcOlKlTp8qiRYvKzdu7d2+ZMGFChTYzMjKkbdu2ommaPPvss9K/f38JDQ2V2NhYycnJsU/nrF5X\n178m6349sKOeakkTKfNWiqia0tLSMHjwYLi6+xQWFsJkMkHTNBiNxnK3Fefn58PPz8/eme9M6Wdd\nzpw5g6ZNm1YY70pbpdMXFRU5/JS/1WrF1atXccstt1QYV1RUBG9v71p/5sbVep2tv6ttlaVpGsxm\nM6KiolyelwhgRz25maMX5lKNGzeudjteXteu3DoKFEdt9e/f3+F0mqZhxYoVTpdtMBgqrdvHx6c6\n5VbJlXUHnK+/q20RqcRQoZtC2Q9HElHdYUc9EREpw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIMFSIi\nUoahQkREyjBUiIhIGYYKEREpw1AhIiJlGCpERKQMQ4WIiJRhqBARkTIMFSIiUoahQkREyvD3VKhW\n0tLS9C6BiDwIQ4VqZfDgwXqXQEQehL9RT1SF0t9r51kZUdXYp0JERMowVIiISBmGChERKcNQISIi\nZRgqRESkDEOFiIiUYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiU\nYagQEZEyDBUiIlKGoUJERMowVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKG\noUJERMowVIiISBmGChERKcNQISIiZRgqRESkDEOFiIiUYagQEZEyDBUiIlKGoUJERMoY9S6AyJNs\n2LABWVlZ5Ybt3bsXAPDee++VG96zZ0/07t3bbbUR1QeaiIjeRRB5iu+++w6PPvooTCYTvLwcn8jb\nbDZYLBasXbsWjzzyiJsrJPJsDBWiMqxWK5o3b46zZ886ne7WW2/FqVOnYDTyZJ+oLPapEJVhMBjw\n9NNPw9vbu9JpvL29MWzYMAYKkQMMFaLrDBkyBMXFxZWOLy4uxpAhQ9xYEVH9wctfRA4EBwfjyJEj\nDscFBQXhyJEj0DTNzVUReT6eqRA5EBMTA5PJVGG4t7c3RowYwUAhqgTPVIgc2LNnDzp16uRw3O7d\nu3H33Xe7uSKi+oGhQlSJTp06Yc+ePeWGdezYscIwIvo/vPxFVInhw4eXuwRmMpkwYsQIHSsi8nw8\nUyGqxJEjR9C2bVuUHiKapuHgwYNo27atvoUReTCeqRBVok2bNrj33nvh5eUFTdNw3333MVCIqsBQ\nIXJi+PDh8PLygsFgwLBhw/Quh8jj8fIXkROnT5/G7bffDgA4duwYmjdvrnNFRJ6NoUIO8XMY5Axf\nNqgy/PIiqlRCQgJ69eqldxm627BhAzRNQ2hoqN6l6G7Lli2YO3eu3mWQB2OoUKV69eqFqKgovcvQ\nXd++fQEAAQEBOlfiGRgq5AxDhagKDBOi6uPdX0REpAxDhYiIlGGoEBGRMgwVIiJShqFCRETKMFSI\niEgZhgoRESnDUCEiImUYKkREpAxDhYiIlGGoEBGRMgwVIiJShqFCRETKMFSIiEgZhgoRESnDUCEi\nImX4I13kMR566CH07dsXL7/8st6luMWaNWvwP//zP/j999/x/PPPo0GDBhARBAQEIDo6Gnfeeafe\nJRK5jKFCHmPFihVo2LChbsvfvXs3/Pz80KFDB7e0Ex4ejvDwcKxevRqJiYkAAJvNho8++gghISFY\ns2YN7r333lrVQuRuvPxFHuPWW2+FyWTSZdn5+fmIjo5GYWGhW9vx9fWFpmn2x15eXhg7diwGDRqE\nPn36oKCgoFb1ELkbQ4Vq7YcffsDAgQORmpqKMWPGoHXr1khKSkJWVhYiIyPRunVrfPvtt/bpZ82a\nBbPZjOeeew6vv/46gGvv7p955hn74/T0dISEhCA1NRVRUVFo0qQJli5dWq16tm3bhnHjxuHNN99E\nREQEduzYAQBITU1F8+bN8dtvv+Ho0aOIjo5G7969AQCLFy9GTk4O5s6di9WrV+Pzzz/H/fffjw8+\n+AC9e/eGn58f/v73v7vcDgD069cP77zzjkvbND4+HgUFBdi6dat9WGZmJsaMGYPQ0FD7mU1V22nW\nrFlYtGgRIiIisHLlykrbIVJGiBwAIGazuVrTXr16Vdq2bSujRo2SkpISSUtLEx8fH/nss8/EZrPJ\nK6+8IuHh4SIikpeXJ40aNRIRkcuXL4vJZJLi4mIRERkwYIBMmDBBRESKiookMDBQEhISxGKxyOzZ\ns6VLly5V1nL8+HFp3769XLx4UUREzGazBAYGytmzZ6WkpEQASHZ2toiIpKSkSOfOnUVE7ONycnLs\ntRmNRnnjjTfEYrHIRx99JJqmyYkTJ1xqR0RkwYIFsmHDBof1Tpw4CmcfPQAABZpJREFUUYKDgx1u\nU4PBIFOnThURkdzcXImPjxcRkfz8fPHx8ZHs7Gyn22n//v0yaNAg+zypqamVtlNdZrNZ+LJBzvBM\nhWrNx8cHt912G3r37g2DwYBHHnkERUVFCAsLg6ZpeOihh3DkyBEAQKtWrbBhwwYAwJYtW2C1WpGX\nlwcAaNKkib1Nb29v+Pv7IyQkBEajET169LBP58ynn36KO++8094388QTTyA/Px9msxkGg6HctEZj\n5V2Kvr6+8PX1xSOPPAKj0Yj4+Hg0a9YM3377rUvtAEBsbCxCQ0OrrL0sm81W7t/k5GRcuHAB06dP\nR1JSEnr27ImsrCyn2ykgIACrV6/GvHnz4O/vj4EDB1baDpEq7Kgn5QICAso9NplMuHLlCgBA0zQU\nFBTglVdeQVxcHDRNg9VqrbJNg8EAEalyukOHDsHL6//eK/n5+aFLly74/fffq1V72f6N6/Xq1Qt7\n9+6tdTvVkZOTA6vViu7duwMAcnNzERERgZEjRwIApkyZ4nC+stupWbNmSE5OxujRo5Geno7ly5dX\nux2imuKZCrlVdnY2Ro0ahWnTptX6LitHWrVqhW3btpUbZjKZ0KpVq2rN7ywMcnNzq32bb21DZcmS\nJWjXrh3CwsIAAF27dsXmzZvLTXPgwAGnbZw6dQoxMTH45ZdfcP78eYwbN65G7RC5gqFCSthsNvs7\n5NI7nywWi31cqY0bN+LixYsQEezduxdWq9U+XVFREYqLi+3TWq1We5vFxcXl2qlMdHQ08vPz8euv\nv9pr2L9/P5566ikAQJs2bZCTkwMA2LNnDy5evAjg2jt8Hx8fnDt3DlevXrW3V7ouZ8+exYkTJxAZ\nGelyOxkZGfabBa5XWFhY7gzsypUrSEpKQlJSEpYuXQp/f38A124/TklJwfz582GxWPDTTz9h165d\nTrfTjh07sHXrVnTq1AkLFy7EuXPnnLZDpISO/TnkweBCR/2WLVvEx8dHoqOj5cyZMzJjxgwBIC+/\n/LKcOXNG4uLixGAwyLfffiuHDh2Sli1byr33/r/27l6lkTAK4/h54xLFD7BQ24gBCZJyG5uIjZVC\nQFAE04RYeAteglikSGMtFpNFBIvxA8SbsPcCTGERi0Ccx0IiiY7rqO+uqP9fmZkc3kkxDzPnTOa3\ndnd3NTs7q4WFBZ2eniqbzSqfz+vy8lLn5+dyzqlUKun6+lqVSkVmpqOjo1fXs7e3p0KhoDAMtb6+\nroODg8dt29vbGhgY0NLSkqrVqmZmZnR8fCxJ2tzcVCaTUb1elySNjIxobW1NtVpNy8vLPc32t9SZ\nm5t7HEDoFoahJicn5ZzTxsaGisWiCoWCyuVyT6NfkqIoUqVSkXNOmUxGW1tbiqLor7/T2dmZ5ufn\ndXJyop2dHV1cXLxYJyka9XiNkxLcqMaP45yzIAhsZWXFe+12u23OOevr67O7uztLpVIfvl30VKvV\nsqurK5uamrJ0Ot2zrdls2vDwsLXb7WdN9tvbWxsaGjKzh95QGIY2PT1t4+Pjz9aYtE6r1bJ0Ou3l\nGG9ubmxwcPDZMcWJoshSqZQ1Gg0bGxt7d51u9XrdVldXE/W38DPRqMd/130CfjpJlUSxWIz93Dln\nh4eHZvYwkZbL5WL360yGxU1tdYLAzEySRVFkExMTH6rT398f+/33GB0dTbxvZ2DhaaC8tQ7wFoQK\nvpzOQ3z/UhAE1mw2bX9/37LZbOJGP/DTESpAjMXFxcfmu88rDeC7I1SAGN23rwAkx0gxAMAbQgUA\n4A2hAgDwhlABAHhDqAAAvCFUAADeECoAAG8IFQCAN4QKAMAbQgUA4A2hAgDwhlABAHhDqAAAvOHN\nj4jl+02M+F44beAl/PU9YgVB8NlLAPAFcaUCAPCGngoAwBtCBQDgDaECAPDml5n9+exFAAC+h3vP\nQMIdgZijOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_total, to_file='Images/model_combined.png')\n",
    "from IPython.display import Image\n",
    "Image(\"Images/model_combined.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_total.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21042/21042 [==============================] - 2s 72us/step - loss: nan - mean_squared_error: nan - acc: 0.7578\n",
      "Epoch 2/20\n",
      "21042/21042 [==============================] - 1s 47us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 3/20\n",
      "21042/21042 [==============================] - 1s 49us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 4/20\n",
      "21042/21042 [==============================] - 1s 57us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 5/20\n",
      "21042/21042 [==============================] - 1s 57us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 6/20\n",
      "21042/21042 [==============================] - 1s 55us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 7/20\n",
      "21042/21042 [==============================] - 1s 55us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 8/20\n",
      "21042/21042 [==============================] - 1s 61us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 9/20\n",
      "21042/21042 [==============================] - 1s 55us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 10/20\n",
      "21042/21042 [==============================] - 1s 55us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 11/20\n",
      "21042/21042 [==============================] - 1s 57us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 12/20\n",
      "21042/21042 [==============================] - 1s 54us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 13/20\n",
      "21042/21042 [==============================] - 1s 53us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 14/20\n",
      "21042/21042 [==============================] - 1s 56us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 15/20\n",
      "21042/21042 [==============================] - 1s 59us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 16/20\n",
      "21042/21042 [==============================] - 1s 62us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 17/20\n",
      "21042/21042 [==============================] - 1s 62us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 18/20\n",
      "21042/21042 [==============================] - 1s 61us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 19/20\n",
      "21042/21042 [==============================] - 1s 58us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n",
      "Epoch 20/20\n",
      "21042/21042 [==============================] - 1s 59us/step - loss: nan - mean_squared_error: nan - acc: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x53c945e5f8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_total.fit([X_train_cat, X_train_con], Y_train,\n",
    "          epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get test_set from Nic\n",
    "#score_total = model_total.evaluate(  )\n",
    "#score_total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
