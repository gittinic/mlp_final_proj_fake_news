{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# from settings import *\n",
    "# import analyze_cascade\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from random import choices\n",
    "import math\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Input, Dense\n",
    "from keras.layers import concatenate as kerasconc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_file = '/Users/jaspermeijering/Google Drive/a Study/EPA Study Abroad - Carnegie Mellon University/Courses/CMU - 95845 - Applied Analytics The Machine Learning Pipeline/Machine Learning Pipeline Final Project/Data/FalseNews_Code_Data/data/metadata_anon.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read meta data \n",
    "fin = open(metadata_file,'r')\n",
    "lines = fin.readlines()\n",
    "fin.close()\n",
    "cascade_id2metadata={}\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    item = eval(line)\n",
    "    cascade_id2metadata[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptives of dynamic measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>cid</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10703</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>106998</td>\n",
       "      <td>11</td>\n",
       "      <td>25.799399</td>\n",
       "      <td>186.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>23228</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11783</td>\n",
       "      <td>Science/Nature/Tech/Food/Health</td>\n",
       "      <td>106999</td>\n",
       "      <td>9</td>\n",
       "      <td>10.811974</td>\n",
       "      <td>313.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14827</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>2.535338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6504</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107000</td>\n",
       "      <td>13</td>\n",
       "      <td>15.395237</td>\n",
       "      <td>518.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>14129</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>4.019705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5772</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107001</td>\n",
       "      <td>8</td>\n",
       "      <td>3.140842</td>\n",
       "      <td>189.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>9972</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.271008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6041</td>\n",
       "      <td>Viral Photos/Stories/Urban Legends</td>\n",
       "      <td>107002</td>\n",
       "      <td>8</td>\n",
       "      <td>5.160261</td>\n",
       "      <td>174.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9526</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>False</td>\n",
       "      <td>3.115942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   breadth                            category     cid  depth  engangement  \\\n",
       "0    10703  Viral Photos/Stories/Urban Legends  106998     11    25.799399   \n",
       "1    11783     Science/Nature/Tech/Food/Health  106999      9    10.811974   \n",
       "2     6504  Viral Photos/Stories/Urban Legends  107000     13    15.395237   \n",
       "3     5772  Viral Photos/Stories/Urban Legends  107001      8     3.140842   \n",
       "4     6041  Viral Photos/Stories/Urban Legends  107002      8     5.160261   \n",
       "\n",
       "   nfollowees  nfollowers   size veracity verified  virality  \n",
       "0       186.0       672.0  23228    MIXED    False  4.003857  \n",
       "1       313.0       380.0  14827    MIXED    False  2.535338  \n",
       "2       518.0       504.0  14129    MIXED    False  4.019705  \n",
       "3       189.0       228.0   9972    MIXED    False  3.271008  \n",
       "4       174.0       110.0   9526    MIXED    False  3.115942  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get static measures\n",
    "cid = []\n",
    "veracity = []\n",
    "virality = []\n",
    "depth = []\n",
    "breadth = []\n",
    "size = []\n",
    "verified = []\n",
    "nfollowers = []\n",
    "nfollowees = []\n",
    "engagement = []\n",
    "category = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        cid.append(cascade)\n",
    "        veracity.append(metadata['veracity'])\n",
    "        virality.append(metadata['virality'])\n",
    "        depth.append(metadata['depth'])\n",
    "        breadth.append(metadata['max_breadth'])\n",
    "        size.append(metadata['size'])\n",
    "        verified.append(metadata['verified_list'][0])\n",
    "        nfollowers.append(metadata['num_followers_list'][0])\n",
    "        nfollowees.append(metadata['num_followees_list'][0])\n",
    "        engagement.append(metadata['engagement_list'][0])\n",
    "        category.append(metadata['rumor_category'])\n",
    "\n",
    "# Convert to data frame\n",
    "static = pd.DataFrame({'cid': cid,\n",
    "                       'veracity': veracity,\n",
    "                       'virality': virality,\n",
    "                       'depth': depth,\n",
    "                       'breadth': breadth,\n",
    "                       'size': size,\n",
    "                       'verified': verified,\n",
    "                       'nfollowers': nfollowers,\n",
    "                       'nfollowees': nfollowees,\n",
    "                       'engangement': engagement,\n",
    "                       'category': category})\n",
    "\n",
    "# Inspect\n",
    "static.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handel NA's - MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breadth</th>\n",
       "      <th>category</th>\n",
       "      <th>cid</th>\n",
       "      <th>depth</th>\n",
       "      <th>engangement</th>\n",
       "      <th>nfollowees</th>\n",
       "      <th>nfollowers</th>\n",
       "      <th>size</th>\n",
       "      <th>veracity</th>\n",
       "      <th>verified</th>\n",
       "      <th>virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8302</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>54959</td>\n",
       "      <td>1</td>\n",
       "      <td>3.668825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>55670</td>\n",
       "      <td>1</td>\n",
       "      <td>5.714839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>56397</td>\n",
       "      <td>1</td>\n",
       "      <td>121.611547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15985</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>62642</td>\n",
       "      <td>1</td>\n",
       "      <td>7.591549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28168</th>\n",
       "      <td>10</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>74825</td>\n",
       "      <td>2</td>\n",
       "      <td>48.698715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.963636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35759</th>\n",
       "      <td>1503</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>82416</td>\n",
       "      <td>8</td>\n",
       "      <td>13.583922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3764</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>4.329435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>2783</td>\n",
       "      <td>Politics</td>\n",
       "      <td>82521</td>\n",
       "      <td>13</td>\n",
       "      <td>20.989461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7620</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>None</td>\n",
       "      <td>5.078605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38208</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>84865</td>\n",
       "      <td>2</td>\n",
       "      <td>9.067479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38298</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>84955</td>\n",
       "      <td>2</td>\n",
       "      <td>2.618711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38338</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>84995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38349</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85006</td>\n",
       "      <td>2</td>\n",
       "      <td>4.047690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39049</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39123</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85780</td>\n",
       "      <td>1</td>\n",
       "      <td>5.426156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39126</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85783</td>\n",
       "      <td>1</td>\n",
       "      <td>11.714848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39202</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85859</td>\n",
       "      <td>1</td>\n",
       "      <td>3.559450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39241</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85898</td>\n",
       "      <td>1</td>\n",
       "      <td>15.316404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85900</td>\n",
       "      <td>1</td>\n",
       "      <td>6.638796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39259</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85916</td>\n",
       "      <td>1</td>\n",
       "      <td>77.029394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39266</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85923</td>\n",
       "      <td>1</td>\n",
       "      <td>4.631302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39267</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85924</td>\n",
       "      <td>1</td>\n",
       "      <td>9.848708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39285</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85942</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39289</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>85946</td>\n",
       "      <td>1</td>\n",
       "      <td>1.613296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39356</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.870673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39425</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86082</td>\n",
       "      <td>1</td>\n",
       "      <td>56.458365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39429</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86086</td>\n",
       "      <td>1</td>\n",
       "      <td>18.807639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39464</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86121</td>\n",
       "      <td>1</td>\n",
       "      <td>31.830939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39470</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86127</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39491</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86148</td>\n",
       "      <td>1</td>\n",
       "      <td>8.547102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39496</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86153</td>\n",
       "      <td>1</td>\n",
       "      <td>16.658258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39550</th>\n",
       "      <td>3</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>86207</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41468</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.306256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88159</td>\n",
       "      <td>1</td>\n",
       "      <td>50.020738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41507</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88164</td>\n",
       "      <td>1</td>\n",
       "      <td>11.761410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41519</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88176</td>\n",
       "      <td>1</td>\n",
       "      <td>10.880946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41564</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88221</td>\n",
       "      <td>1</td>\n",
       "      <td>123.211692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41577</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88234</td>\n",
       "      <td>1</td>\n",
       "      <td>35.046560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41629</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88286</td>\n",
       "      <td>1</td>\n",
       "      <td>6.005257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88297</td>\n",
       "      <td>1</td>\n",
       "      <td>28.666195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41658</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88315</td>\n",
       "      <td>1</td>\n",
       "      <td>20.469583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41708</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88365</td>\n",
       "      <td>1</td>\n",
       "      <td>2.047021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41749</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88406</td>\n",
       "      <td>1</td>\n",
       "      <td>2.846118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41763</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88420</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41829</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88486</td>\n",
       "      <td>1</td>\n",
       "      <td>4.083975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41830</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88487</td>\n",
       "      <td>1</td>\n",
       "      <td>16.627976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41851</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41860</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.811556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41866</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88523</td>\n",
       "      <td>1</td>\n",
       "      <td>3.444131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41875</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88532</td>\n",
       "      <td>1</td>\n",
       "      <td>8.414021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41879</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88536</td>\n",
       "      <td>1</td>\n",
       "      <td>78.995832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41881</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88538</td>\n",
       "      <td>1</td>\n",
       "      <td>6.740574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41893</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88550</td>\n",
       "      <td>1</td>\n",
       "      <td>4.993709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41924</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88581</td>\n",
       "      <td>1</td>\n",
       "      <td>2.181334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41929</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88586</td>\n",
       "      <td>1</td>\n",
       "      <td>14.724217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41950</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88607</td>\n",
       "      <td>1</td>\n",
       "      <td>2.498213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41965</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88622</td>\n",
       "      <td>1</td>\n",
       "      <td>29.451872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41982</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88654</td>\n",
       "      <td>1</td>\n",
       "      <td>2.540791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42005</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88662</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42027</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88684</td>\n",
       "      <td>1</td>\n",
       "      <td>1.878513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42072</th>\n",
       "      <td>2</td>\n",
       "      <td>War/Terrorism/Shootings</td>\n",
       "      <td>88729</td>\n",
       "      <td>1</td>\n",
       "      <td>7.329452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       breadth                 category    cid  depth  engangement  \\\n",
       "8302         2  War/Terrorism/Shootings  54959      1     3.668825   \n",
       "9013         2  War/Terrorism/Shootings  55670      1     5.714839   \n",
       "9740         2  War/Terrorism/Shootings  56397      1   121.611547   \n",
       "15985        3  War/Terrorism/Shootings  62642      1     7.591549   \n",
       "28168       10  War/Terrorism/Shootings  74825      2    48.698715   \n",
       "35759     1503  War/Terrorism/Shootings  82416      8    13.583922   \n",
       "35864     2783                 Politics  82521     13    20.989461   \n",
       "38208        2  War/Terrorism/Shootings  84865      2     9.067479   \n",
       "38298        2  War/Terrorism/Shootings  84955      2     2.618711   \n",
       "38338        2  War/Terrorism/Shootings  84995      2     0.092596   \n",
       "38349        2  War/Terrorism/Shootings  85006      2     4.047690   \n",
       "39049        3  War/Terrorism/Shootings  85706      1     0.327165   \n",
       "39123        3  War/Terrorism/Shootings  85780      1     5.426156   \n",
       "39126        3  War/Terrorism/Shootings  85783      1    11.714848   \n",
       "39202        3  War/Terrorism/Shootings  85859      1     3.559450   \n",
       "39241        3  War/Terrorism/Shootings  85898      1    15.316404   \n",
       "39243        3  War/Terrorism/Shootings  85900      1     6.638796   \n",
       "39259        3  War/Terrorism/Shootings  85916      1    77.029394   \n",
       "39266        3  War/Terrorism/Shootings  85923      1     4.631302   \n",
       "39267        3  War/Terrorism/Shootings  85924      1     9.848708   \n",
       "39285        3  War/Terrorism/Shootings  85942      1     0.371654   \n",
       "39289        3  War/Terrorism/Shootings  85946      1     1.613296   \n",
       "39356        3  War/Terrorism/Shootings  86013      1     1.870673   \n",
       "39425        3  War/Terrorism/Shootings  86082      1    56.458365   \n",
       "39429        3  War/Terrorism/Shootings  86086      1    18.807639   \n",
       "39464        3  War/Terrorism/Shootings  86121      1    31.830939   \n",
       "39470        3  War/Terrorism/Shootings  86127      1     3.456234   \n",
       "39491        3  War/Terrorism/Shootings  86148      1     8.547102   \n",
       "39496        3  War/Terrorism/Shootings  86153      1    16.658258   \n",
       "39550        3  War/Terrorism/Shootings  86207      1     0.856760   \n",
       "...        ...                      ...    ...    ...          ...   \n",
       "41468        2  War/Terrorism/Shootings  88125      1     0.306256   \n",
       "41502        2  War/Terrorism/Shootings  88159      1    50.020738   \n",
       "41507        2  War/Terrorism/Shootings  88164      1    11.761410   \n",
       "41519        2  War/Terrorism/Shootings  88176      1    10.880946   \n",
       "41564        2  War/Terrorism/Shootings  88221      1   123.211692   \n",
       "41577        2  War/Terrorism/Shootings  88234      1    35.046560   \n",
       "41629        2  War/Terrorism/Shootings  88286      1     6.005257   \n",
       "41640        2  War/Terrorism/Shootings  88297      1    28.666195   \n",
       "41658        2  War/Terrorism/Shootings  88315      1    20.469583   \n",
       "41708        2  War/Terrorism/Shootings  88365      1     2.047021   \n",
       "41749        2  War/Terrorism/Shootings  88406      1     2.846118   \n",
       "41763        2  War/Terrorism/Shootings  88420      1     0.957291   \n",
       "41829        2  War/Terrorism/Shootings  88486      1     4.083975   \n",
       "41830        2  War/Terrorism/Shootings  88487      1    16.627976   \n",
       "41851        2  War/Terrorism/Shootings  88508      1     0.830040   \n",
       "41860        2  War/Terrorism/Shootings  88517      1    20.811556   \n",
       "41866        2  War/Terrorism/Shootings  88523      1     3.444131   \n",
       "41875        2  War/Terrorism/Shootings  88532      1     8.414021   \n",
       "41879        2  War/Terrorism/Shootings  88536      1    78.995832   \n",
       "41881        2  War/Terrorism/Shootings  88538      1     6.740574   \n",
       "41893        2  War/Terrorism/Shootings  88550      1     4.993709   \n",
       "41924        2  War/Terrorism/Shootings  88581      1     2.181334   \n",
       "41929        2  War/Terrorism/Shootings  88586      1    14.724217   \n",
       "41950        2  War/Terrorism/Shootings  88607      1     2.498213   \n",
       "41965        2  War/Terrorism/Shootings  88622      1    29.451872   \n",
       "41982        2  War/Terrorism/Shootings  88639      1     0.414908   \n",
       "41997        2  War/Terrorism/Shootings  88654      1     2.540791   \n",
       "42005        2  War/Terrorism/Shootings  88662      1     0.212568   \n",
       "42027        2  War/Terrorism/Shootings  88684      1     1.878513   \n",
       "42072        2  War/Terrorism/Shootings  88729      1     7.329452   \n",
       "\n",
       "       nfollowees  nfollowers  size veracity verified  virality  \n",
       "8302          NaN         NaN     2    FALSE     None  1.000000  \n",
       "9013          NaN         NaN     2    FALSE     None  1.000000  \n",
       "9740          NaN         NaN     2    FALSE     None  1.000000  \n",
       "15985         NaN         NaN     3    FALSE     None  1.333333  \n",
       "28168         NaN         NaN    11    FALSE     None  1.963636  \n",
       "35759         NaN         NaN  3764    FALSE     None  4.329435  \n",
       "35864         NaN         NaN  7620    FALSE     None  5.078605  \n",
       "38208         NaN         NaN     3     TRUE     None  1.333333  \n",
       "38298         NaN         NaN     3     TRUE     None  1.333333  \n",
       "38338         NaN         NaN     3     TRUE     None  1.333333  \n",
       "38349         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39049         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39123         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39126         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39202         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39241         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39243         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39259         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39266         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39267         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39285         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39289         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39356         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39425         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39429         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39464         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39470         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39491         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39496         NaN         NaN     3     TRUE     None  1.333333  \n",
       "39550         NaN         NaN     3     TRUE     None  1.333333  \n",
       "...           ...         ...   ...      ...      ...       ...  \n",
       "41468         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41502         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41507         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41519         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41564         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41577         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41629         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41640         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41658         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41708         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41749         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41763         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41829         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41830         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41851         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41860         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41866         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41875         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41879         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41881         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41893         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41924         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41929         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41950         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41965         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41982         NaN         NaN     2     TRUE     None  1.000000  \n",
       "41997         NaN         NaN     2     TRUE     None  1.000000  \n",
       "42005         NaN         NaN     2     TRUE     None  1.000000  \n",
       "42027         NaN         NaN     2     TRUE     None  1.000000  \n",
       "42072         NaN         NaN     2     TRUE     None  1.000000  \n",
       "\n",
       "[136 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect\n",
    "static['nfollowers'].isnull().values.sum()\n",
    "static['nfollowees'].isnull().values.sum()\n",
    "static['verified'].isnull().values.sum()\n",
    "\n",
    "# 136 have nan for nfollowers, nfollowees and verified, 135 in 'War/Terrorism/Shootings' and 1 in Politics\n",
    "static[static['verified'].isnull()]['category'].unique()\n",
    "sum(static[static['verified'].isnull()]['category'] == 'War/Terrorism/Shootings')\n",
    "static[static['verified'].isnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out where Nics drops NA's -> undrop them run mice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['breadth', 'category', 'cid', 'depth', 'engangement', 'nfollowees',\n",
       "       'nfollowers', 'size', 'veracity', 'verified', 'virality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.07030000e+04,   1.06998000e+05,   1.10000000e+01, ...,\n",
       "          6.72000000e+02,   2.32280000e+04,   4.00385720e+00],\n",
       "       [  1.17830000e+04,   1.06999000e+05,   9.00000000e+00, ...,\n",
       "          3.80000000e+02,   1.48270000e+04,   2.53533792e+00],\n",
       "       [  6.50400000e+03,   1.07000000e+05,   1.30000000e+01, ...,\n",
       "          5.04000000e+02,   1.41290000e+04,   4.01970546e+00],\n",
       "       ..., \n",
       "       [  2.00000000e+00,   8.87350000e+04,   1.00000000e+00, ...,\n",
       "          4.40000000e+01,   2.00000000e+00,   1.00000000e+00],\n",
       "       [  2.00000000e+00,   8.87360000e+04,   1.00000000e+00, ...,\n",
       "          9.46000000e+02,   2.00000000e+00,   1.00000000e+00],\n",
       "       [  2.00000000e+00,   8.87370000e+04,   1.00000000e+00, ...,\n",
       "          9.46000000e+02,   2.00000000e+00,   1.00000000e+00]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staticx = static.loc[:,['breadth', 'cid', 'depth', 'engangement', 'nfollowees',\n",
    "       'nfollowers', 'size', 'virality']].as_matrix()\n",
    "staticx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MICE] Completing matrix with shape (42081, 8)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.003\n",
      "[MICE] Starting imputation round 2/110, elapsed time 0.020\n",
      "[MICE] Starting imputation round 3/110, elapsed time 0.029\n",
      "[MICE] Starting imputation round 4/110, elapsed time 0.038\n",
      "[MICE] Starting imputation round 5/110, elapsed time 0.046\n",
      "[MICE] Starting imputation round 6/110, elapsed time 0.055\n",
      "[MICE] Starting imputation round 7/110, elapsed time 0.064\n",
      "[MICE] Starting imputation round 8/110, elapsed time 0.074\n",
      "[MICE] Starting imputation round 9/110, elapsed time 0.083\n",
      "[MICE] Starting imputation round 10/110, elapsed time 0.091\n",
      "[MICE] Starting imputation round 11/110, elapsed time 0.100\n",
      "[MICE] Starting imputation round 12/110, elapsed time 0.108\n",
      "[MICE] Starting imputation round 13/110, elapsed time 0.117\n",
      "[MICE] Starting imputation round 14/110, elapsed time 0.126\n",
      "[MICE] Starting imputation round 15/110, elapsed time 0.135\n",
      "[MICE] Starting imputation round 16/110, elapsed time 0.144\n",
      "[MICE] Starting imputation round 17/110, elapsed time 0.153\n",
      "[MICE] Starting imputation round 18/110, elapsed time 0.165\n",
      "[MICE] Starting imputation round 19/110, elapsed time 0.181\n",
      "[MICE] Starting imputation round 20/110, elapsed time 0.194\n",
      "[MICE] Starting imputation round 21/110, elapsed time 0.204\n",
      "[MICE] Starting imputation round 22/110, elapsed time 0.217\n",
      "[MICE] Starting imputation round 23/110, elapsed time 0.228\n",
      "[MICE] Starting imputation round 24/110, elapsed time 0.237\n",
      "[MICE] Starting imputation round 25/110, elapsed time 0.246\n",
      "[MICE] Starting imputation round 26/110, elapsed time 0.254\n",
      "[MICE] Starting imputation round 27/110, elapsed time 0.262\n",
      "[MICE] Starting imputation round 28/110, elapsed time 0.270\n",
      "[MICE] Starting imputation round 29/110, elapsed time 0.278\n",
      "[MICE] Starting imputation round 30/110, elapsed time 0.285\n",
      "[MICE] Starting imputation round 31/110, elapsed time 0.293\n",
      "[MICE] Starting imputation round 32/110, elapsed time 0.301\n",
      "[MICE] Starting imputation round 33/110, elapsed time 0.313\n",
      "[MICE] Starting imputation round 34/110, elapsed time 0.325\n",
      "[MICE] Starting imputation round 35/110, elapsed time 0.338\n",
      "[MICE] Starting imputation round 36/110, elapsed time 0.347\n",
      "[MICE] Starting imputation round 37/110, elapsed time 0.356\n",
      "[MICE] Starting imputation round 38/110, elapsed time 0.364\n",
      "[MICE] Starting imputation round 39/110, elapsed time 0.372\n",
      "[MICE] Starting imputation round 40/110, elapsed time 0.379\n",
      "[MICE] Starting imputation round 41/110, elapsed time 0.387\n",
      "[MICE] Starting imputation round 42/110, elapsed time 0.394\n",
      "[MICE] Starting imputation round 43/110, elapsed time 0.401\n",
      "[MICE] Starting imputation round 44/110, elapsed time 0.409\n",
      "[MICE] Starting imputation round 45/110, elapsed time 0.417\n",
      "[MICE] Starting imputation round 46/110, elapsed time 0.424\n",
      "[MICE] Starting imputation round 47/110, elapsed time 0.432\n",
      "[MICE] Starting imputation round 48/110, elapsed time 0.440\n",
      "[MICE] Starting imputation round 49/110, elapsed time 0.449\n",
      "[MICE] Starting imputation round 50/110, elapsed time 0.458\n",
      "[MICE] Starting imputation round 51/110, elapsed time 0.466\n",
      "[MICE] Starting imputation round 52/110, elapsed time 0.473\n",
      "[MICE] Starting imputation round 53/110, elapsed time 0.481\n",
      "[MICE] Starting imputation round 54/110, elapsed time 0.488\n",
      "[MICE] Starting imputation round 55/110, elapsed time 0.495\n",
      "[MICE] Starting imputation round 56/110, elapsed time 0.502\n",
      "[MICE] Starting imputation round 57/110, elapsed time 0.509\n",
      "[MICE] Starting imputation round 58/110, elapsed time 0.516\n",
      "[MICE] Starting imputation round 59/110, elapsed time 0.523\n",
      "[MICE] Starting imputation round 60/110, elapsed time 0.530\n",
      "[MICE] Starting imputation round 61/110, elapsed time 0.537\n",
      "[MICE] Starting imputation round 62/110, elapsed time 0.544\n",
      "[MICE] Starting imputation round 63/110, elapsed time 0.551\n",
      "[MICE] Starting imputation round 64/110, elapsed time 0.558\n",
      "[MICE] Starting imputation round 65/110, elapsed time 0.565\n",
      "[MICE] Starting imputation round 66/110, elapsed time 0.571\n",
      "[MICE] Starting imputation round 67/110, elapsed time 0.578\n",
      "[MICE] Starting imputation round 68/110, elapsed time 0.585\n",
      "[MICE] Starting imputation round 69/110, elapsed time 0.592\n",
      "[MICE] Starting imputation round 70/110, elapsed time 0.599\n",
      "[MICE] Starting imputation round 71/110, elapsed time 0.606\n",
      "[MICE] Starting imputation round 72/110, elapsed time 0.613\n",
      "[MICE] Starting imputation round 73/110, elapsed time 0.620\n",
      "[MICE] Starting imputation round 74/110, elapsed time 0.629\n",
      "[MICE] Starting imputation round 75/110, elapsed time 0.636\n",
      "[MICE] Starting imputation round 76/110, elapsed time 0.644\n",
      "[MICE] Starting imputation round 77/110, elapsed time 0.653\n",
      "[MICE] Starting imputation round 78/110, elapsed time 0.662\n",
      "[MICE] Starting imputation round 79/110, elapsed time 0.670\n",
      "[MICE] Starting imputation round 80/110, elapsed time 0.678\n",
      "[MICE] Starting imputation round 81/110, elapsed time 0.686\n",
      "[MICE] Starting imputation round 82/110, elapsed time 0.693\n",
      "[MICE] Starting imputation round 83/110, elapsed time 0.700\n",
      "[MICE] Starting imputation round 84/110, elapsed time 0.707\n",
      "[MICE] Starting imputation round 85/110, elapsed time 0.715\n",
      "[MICE] Starting imputation round 86/110, elapsed time 0.721\n",
      "[MICE] Starting imputation round 87/110, elapsed time 0.729\n",
      "[MICE] Starting imputation round 88/110, elapsed time 0.737\n",
      "[MICE] Starting imputation round 89/110, elapsed time 0.745\n",
      "[MICE] Starting imputation round 90/110, elapsed time 0.753\n",
      "[MICE] Starting imputation round 91/110, elapsed time 0.760\n",
      "[MICE] Starting imputation round 92/110, elapsed time 0.768\n",
      "[MICE] Starting imputation round 93/110, elapsed time 0.776\n",
      "[MICE] Starting imputation round 94/110, elapsed time 0.783\n",
      "[MICE] Starting imputation round 95/110, elapsed time 0.790\n",
      "[MICE] Starting imputation round 96/110, elapsed time 0.798\n",
      "[MICE] Starting imputation round 97/110, elapsed time 0.805\n",
      "[MICE] Starting imputation round 98/110, elapsed time 0.812\n",
      "[MICE] Starting imputation round 99/110, elapsed time 0.820\n",
      "[MICE] Starting imputation round 100/110, elapsed time 0.828\n",
      "[MICE] Starting imputation round 101/110, elapsed time 0.836\n",
      "[MICE] Starting imputation round 102/110, elapsed time 0.844\n",
      "[MICE] Starting imputation round 103/110, elapsed time 0.852\n",
      "[MICE] Starting imputation round 104/110, elapsed time 0.861\n",
      "[MICE] Starting imputation round 105/110, elapsed time 0.871\n",
      "[MICE] Starting imputation round 106/110, elapsed time 0.880\n",
      "[MICE] Starting imputation round 107/110, elapsed time 0.889\n",
      "[MICE] Starting imputation round 108/110, elapsed time 0.898\n",
      "[MICE] Starting imputation round 109/110, elapsed time 0.905\n",
      "[MICE] Starting imputation round 110/110, elapsed time 0.914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.07030000e+04,   1.06998000e+05,   1.10000000e+01, ...,\n",
       "          6.72000000e+02,   2.32280000e+04,   4.00385720e+00],\n",
       "       [  1.17830000e+04,   1.06999000e+05,   9.00000000e+00, ...,\n",
       "          3.80000000e+02,   1.48270000e+04,   2.53533792e+00],\n",
       "       [  6.50400000e+03,   1.07000000e+05,   1.30000000e+01, ...,\n",
       "          5.04000000e+02,   1.41290000e+04,   4.01970546e+00],\n",
       "       ..., \n",
       "       [  2.00000000e+00,   8.87350000e+04,   1.00000000e+00, ...,\n",
       "          4.40000000e+01,   2.00000000e+00,   1.00000000e+00],\n",
       "       [  2.00000000e+00,   8.87360000e+04,   1.00000000e+00, ...,\n",
       "          9.46000000e+02,   2.00000000e+00,   1.00000000e+00],\n",
       "       [  2.00000000e+00,   8.87370000e+04,   1.00000000e+00, ...,\n",
       "          9.46000000e+02,   2.00000000e+00,   1.00000000e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fancyimpute # install pip install fancyimpute\n",
    "mddd = fancyimpute.MICE().complete(staticx)\n",
    "mddd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP HERE - Nothing to see here anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_depth2time = []\n",
    "len_num_followees_list = []\n",
    "len_depth2uu = []\n",
    "len_uu2time = []\n",
    "len_depth2breadth = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None: \n",
    "        len_depth2time.append(len(metadata['depth2time'].keys()))\n",
    "        len_num_followees_list.append(len(metadata['num_followees_list']))\n",
    "        len_depth2uu.append(len(metadata['depth2uu'].keys()))\n",
    "        len_uu2time.append(len(metadata['uu2time'].keys()))\n",
    "        len_depth2breadth.append(len(metadata['depth2breadth'].keys()))\n",
    "    \n",
    "# Convert to data frame\n",
    "dynamic_len = pd.DataFrame({'depth2time ': len_depth2time, \n",
    "                           'num_followees_list': len_num_followees_list, \n",
    "                           'depth2uu': len_depth2uu, \n",
    "                           'uu2time': len_uu2time, \n",
    "                           'depth2breadth': len_depth2breadth})\n",
    "\n",
    "# # Get summary\n",
    "dynamic_len.describe(percentiles = [0.25, 0.5, 0.75, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to get expression of each item in a dictionary entry\n",
    "def get_expression_list(entry):\n",
    "    expression = []\n",
    "    for i in entry.keys():\n",
    "        expression.append(float(entry[i]))\n",
    "    return expression\n",
    "\n",
    "# Convert y to classification\n",
    "def veracity_to_categorical(v):\n",
    "    if v == 'FALSE':\n",
    "        vbin = [1,0,0]\n",
    "    elif v == 'MIXED':\n",
    "        vbin = [0,1,0]\n",
    "    elif v == 'TRUE':\n",
    "        vbin = [0,0,1]\n",
    "    else:\n",
    "        vbin = None\n",
    "    return vbin\n",
    "\n",
    "# Get data in list format\n",
    "data = []\n",
    "for cascade,metadata in cascade_id2metadata.items():\n",
    "    if metadata['virality'] is not None:       \n",
    "        # Get depth\n",
    "        depth2time = get_expression_list(metadata['depth2time'])\n",
    "        depth2uu = get_expression_list(metadata['depth2uu'])\n",
    "        depth2breadth = get_expression_list(metadata['depth2breadth']) \n",
    "        veracity = veracity_to_categorical(metadata['veracity'])\n",
    "        data_id = []\n",
    "        for time, uu, breadth in zip(depth2time, depth2uu, depth2breadth):\n",
    "            data_t = [cascade, \n",
    "                      veracity,\n",
    "                      time, uu, breadth]\n",
    "            data_id.append(data_t)\n",
    "        data.extend([data_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: Create training and test set\n",
    "def split_list(lst, train_size): # train_size is a proportion\n",
    "    split = len(lst) * train_size\n",
    "    if split.is_integer():\n",
    "        split = int(split)\n",
    "        return lst[:split], lst[split:]\n",
    "    else:\n",
    "        split = math.floor(split) + 1\n",
    "        return lst[:split], lst[split:]\n",
    "    \n",
    "# Function: Padding for groups of equal batches\n",
    "def padding(lst, bsize):\n",
    "    if len(lst) % bsize != 0:\n",
    "        psize = bsize - (len(lst) % 5)\n",
    "        samples = choices(lst, k=psize)\n",
    "        lst.extend(samples)\n",
    "    return lst\n",
    "\n",
    "# Get sublist\n",
    "def get_sublist(list_in_list, start, stop):\n",
    "    x = []\n",
    "    for lst in list_in_list:\n",
    "        x_id = []\n",
    "        for sublist in lst:\n",
    "            if stop is None:\n",
    "                x_id.append(sublist[start:])\n",
    "            elif start is None:\n",
    "                x_id.append(sublist[:stop])\n",
    "            else:\n",
    "                x_id.append(sublist[start:stop])\n",
    "        x.extend([x_id])\n",
    "    return x\n",
    "\n",
    "# Separate id, x and y\n",
    "def separate(list_in_list):\n",
    "    cid = []\n",
    "    y = []\n",
    "    for lst in list_in_list:\n",
    "        cid.append(lst[0][0]) # only one id is needed\n",
    "        # The following code would assume target replication in the model\n",
    "#         veracity_id = []\n",
    "#         for sublist in lst:\n",
    "#             veracity_id.extend([sublist[1]])\n",
    "#         veracity.append(veracity_id)\n",
    "        y.append(lst[0][1])\n",
    "    x = get_sublist(list_in_list,2,None)\n",
    "    return cid, y, x\n",
    "\n",
    "# # Group by sequence length and append to have batches of 5 for both training and test\n",
    "data.sort(key=len)   # Randomly reshuffle before? random.shuffle(...)\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "cid_train = []\n",
    "cid_test = []\n",
    "for k, g in groupby(data, len):\n",
    "    group = list(g)\n",
    "    if len(group) > 2: # This omits too small groups\n",
    "        shuffle(group)\n",
    "        # Create train and test bucket\n",
    "        train_group, test_group = split_list(group, 0.5)\n",
    "        # Padd for equal batch size\n",
    "        train_group_padded = padding(train_group, 5)\n",
    "        test_group_padded = padding(test_group, 5)\n",
    "        # Separate list\n",
    "        cid_train_group, y_train_group, x_train_group = separate(train_group)\n",
    "        cid_test_group, y_test_group, x_test_group = separate(test_group)\n",
    "        # Append:  convert y and x into numpy arrays for nn models\n",
    "        x_train.append(np.array(x_train_group))\n",
    "        x_test.append(np.array(x_test_group))\n",
    "        y_train.append(np.array(y_train_group))\n",
    "        y_test.append(np.array(y_test_group))\n",
    "        cid_train.append(cid_train_group)\n",
    "        cid_test.append(cid_test_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to standardize the list\n",
    "def standardization(lst, index, mean, std):\n",
    "    for array3d in lst:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                vector[index] = (vector[index] - mean) / std\n",
    "    return lst\n",
    "\n",
    "# Function to compute mean and std of variable and then standardizes this variable in list\n",
    "def standardize_data(a_list, b_list, index):\n",
    "    var = []\n",
    "    # Compute mean and std from train data variable\n",
    "    for array3d in a_list:\n",
    "        for array2d in array3d:\n",
    "            for vector in array2d:\n",
    "                var.append(vector[index])\n",
    "    var = np.array(var)\n",
    "    var_mean = var.mean()\n",
    "    var_std = var.std()\n",
    "    # Standardize a\n",
    "    a_list_std = standardization(a_list, index, var_mean, var_std)\n",
    "    b_list_std = standardization(b_list, index, var_mean, var_std)\n",
    "    return a_list_std, b_list_std\n",
    "\n",
    "# Standardize all variables\n",
    "def standardize_all(a_list, b_list):\n",
    "    length = len(a_list[0][0][0])\n",
    "    indices = list(range(length))\n",
    "    for i in indices:\n",
    "        std_a, std_b = standardize_data(a_list, b_list, i)\n",
    "    return std_a, std_b\n",
    "\n",
    "x_train, x_test = standardize_all(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM train data descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group size and sequence length\n",
    "i = 1\n",
    "for g in x_train:\n",
    "    print('Group: ', i, ' ', 'Observations: ', len(g), ' ' 'Sequence length', len(g[0]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to classification\n",
    "def reverse_veracity_to_categorical(vbin):\n",
    "    if vbin[0] == 1:\n",
    "        v = 'FALSE'\n",
    "    elif vbin[1] == 1:\n",
    "        v = 'MIXED'\n",
    "    elif vbin[2] == 1:\n",
    "        v = 'TRUE'\n",
    "    return v\n",
    "\n",
    "# Outcome distribution\n",
    "i = 1\n",
    "for g in y_train:\n",
    "    ver = []\n",
    "    for y in g:\n",
    "        ver.append(reverse_veracity_to_categorical(y))\n",
    "    print('Group: ', i, Counter(ver))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome distribution test overall\n",
    "ver = []\n",
    "for g in y_test:\n",
    "    for y in g:\n",
    "        ver.append(reverse_veracity_to_categorical(y))\n",
    "print('Group: ', Counter(ver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM for depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (None, 3),  return_sequences = False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and get train predictions\n",
    "train_pred = []\n",
    "test_pred = []\n",
    "for X,Y,Z in zip(x_train, y_train, x_test):\n",
    "    hist = model.fit(X, Y, epochs=2, batch_size=5)\n",
    "    pred1 = model.predict(X, batch_size=5)\n",
    "    pred2 = model.predict(Z, batch_size=5)\n",
    "    train_pred.append(pred1)\n",
    "    test_pred.append(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert predictions to data frame with ID\n",
    "def pred_to_df(ids, pred, var_name, train):\n",
    "    # Create data frame of predictions\n",
    "    n = len(pred[0][0])\n",
    "    cols = ['cid']\n",
    "    cols.extend([var_name + str(i) for i in range(n)])\n",
    "    init = 0\n",
    "    for id_gr,p_gr in zip(ids,pred):\n",
    "        for i,p in zip(id_gr, p_gr):\n",
    "            if init == 0:\n",
    "                matrix = [np.append([i],p)]\n",
    "                init = 1\n",
    "            else:\n",
    "                matrix = np.concatenate((matrix, [np.append([i],p)]), axis=0)\n",
    "    df = pd.DataFrame(matrix, columns=cols)\n",
    "    # Make id column integer\n",
    "    df.cid = df.cid.astype(int)\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates('cid')\n",
    "    # Combine train and test predictions and input ID\n",
    "    df.insert(1, 'train', train)\n",
    "    return df\n",
    "\n",
    "# Get train and test predictions\n",
    "ydepth = pred_to_df(cid_train, train_pred, 'ydepth', True)\n",
    "y_test_test = pred_to_df(cid_test, test_pred, 'ydepth', False)\n",
    "# Combine\n",
    "ydepth = ydepth.append(y_test_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM for users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comb = pd.merge(static, ydepth, how='left', on='cid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make x variables categorical with integer values\n",
    "def x_in_df_to_int(df, x):\n",
    "    df[x].fillna('Unknown')\n",
    "    df[x] = df[x].astype('category')\n",
    "    num = list(range(len(df[x].cat.categories)))\n",
    "    df[x] = df[x].cat.rename_categories(num)\n",
    "    df[x] = df[x].astype('int')\n",
    "    return df\n",
    "\n",
    "df_comb = x_in_df_to_int(df_comb, 'verified')\n",
    "df_comb = x_in_df_to_int(df_comb, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['virality'].isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NAs: Recall a few buckets were too small for LSTM --> obs removed --> resulting in NAs with merge --> drop\n",
    "df_comb = df_comb.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change format of y\n",
    "def var_to_binary_in_df(df, var, fct):\n",
    "    array = np.array([fct(df[var][0])])\n",
    "    for i in df[var][1:]:\n",
    "        array = np.concatenate((array, [fct(i)]), axis=0)\n",
    "    df[var] = array.tolist()\n",
    "    return df\n",
    "\n",
    "df_comb = var_to_binary_in_df(df_comb, 'veracity', veracity_to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training and test\n",
    "all_vars = list(df_comb.columns.values)\n",
    "cat_vars = ['category', 'verified']\n",
    "cont_vars = list(set(all_vars) - set(cat_vars) - set(['cid', 'veracity', 'train']))\n",
    "X_train_cat  = df_comb.loc[df_comb[\"train\"], cat_vars]\n",
    "X_test_cat  = df_comb.loc[df_comb[\"train\"], cat_vars]\n",
    "X_train_con  = df_comb.loc[df_comb[\"train\"], cont_vars]\n",
    "X_test_con  = df_comb.loc[df_comb[\"train\"], cont_vars]\n",
    "Y_train = df_comb.loc[df_comb[\"train\"], ['veracity']]\n",
    "Y_test = df_comb.loc[df_comb[\"train\"], ['veracity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make categorical X to binary matrix\n",
    "def x_cat_binmatrix(X):\n",
    "    Xbin = pd.DataFrame(to_categorical(X.iloc[:,0]))\n",
    "    X_ = pd.DataFrame(data=X.iloc[:,~0])\n",
    "    for x in X_:\n",
    "        Xbin = np.concatenate((Xbin, to_categorical(X_[x])), axis=1)\n",
    "    return Xbin\n",
    "\n",
    "X_train_cat = x_cat_binmatrix(X_train_cat)\n",
    "X_test_cat = x_cat_binmatrix(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize data by train mean and standard dev.\n",
    "def stdx(x, mean, sd):\n",
    "    return (x - mean) / sd\n",
    "\n",
    "def std_train_test(df_train, df_test):\n",
    "    for x_train, x_test in zip(df_train, df_test):\n",
    "        mean = df_train[x_train].mean()\n",
    "        sd = df_train[x_train].std()\n",
    "        df_train[x_train] = stdx(df_train[x_train], mean, sd)\n",
    "        df_test[x_test] = stdx(df_test[x_test], mean, sd)\n",
    "    return df_train, df_test\n",
    "\n",
    "X_train_con, X_test_con = std_train_test(X_train_con, X_test_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change datastructue df -> matrix (already done for categorical) \n",
    "X_train_con  = X_train_con.as_matrix()\n",
    "X_test_con = X_test_con.as_matrix()\n",
    "Y_train = Y_train.as_matrix()\n",
    "Y_test = Y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert lists in Y to arrays\n",
    "def lists_in_array_to_arrays(narray):\n",
    "    matrix = np.array([np.asarray(narray[0][0])])\n",
    "    for lst in narray[1:]:\n",
    "        matrix = np.concatenate((matrix, [np.asarray(lst[0])]), axis=0)\n",
    "    return matrix\n",
    "\n",
    "Y_train = lists_in_array_to_arrays(Y_train)\n",
    "Y_test = lists_in_array_to_arrays(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(X_train_cat.shape[1],), name='Categorial_input')\n",
    "con_input = Input(shape=(X_train_con.shape[1],), name='Continous_input')\n",
    "\n",
    "x = kerasconc([cat_input, con_input])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(3, activation='softmax', name='main_output')(x) \n",
    "model_total = Model(inputs=[cat_input, con_input], outputs=[main_output])\n",
    "model_total.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['mse','accuracy'])\n",
    "model_total.fit([X_train_cat, X_train_con], \n",
    "                Y_train,\n",
    "                epochs=10, \n",
    "                batch_size=24)\n",
    "model_total.predict([X_test_cat, X_test_con],\n",
    "                   batch_size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "ypred_con = model_total.predict([X_train_cat,X_train_con],batch_size = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_train[:, i], ypred_con[:,i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_train.ravel(), ypred_con.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "n_classes = 3\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot parameters\n",
    "lw = 1\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[2], tpr[2], color = 'aqua', lw=lw,\n",
    "            label='ROC curve of class True (area = {1:0.2f})'\n",
    "             ''.format(2, roc_auc[2]))\n",
    "plt.plot(fpr[0], tpr[0], color= 'darkorange', lw=lw,\n",
    "            label='ROC curve of class False (area = {1:0.2f})'\n",
    "             ''.format(0, roc_auc[0]))\n",
    "plt.plot(fpr[1], tpr[1], color= 'cornflowerblue', lw=lw,\n",
    "            label='ROC curve of class Mixed (area = {1:0.2f})' #check whether coding is correct\n",
    "             ''.format(1, roc_auc[1]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve True, False and Mixed news based on tweet cascades')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
